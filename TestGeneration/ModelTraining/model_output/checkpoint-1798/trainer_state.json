{
  "best_global_step": 1798,
  "best_metric": 0.34065884351730347,
  "best_model_checkpoint": "./model_output/checkpoint-1798",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1798,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0055617352614015575,
      "grad_norm": 2.5525827407836914,
      "learning_rate": 4.9937430478309235e-05,
      "loss": 2.5411,
      "step": 10
    },
    {
      "epoch": 0.011123470522803115,
      "grad_norm": 1.3268426656723022,
      "learning_rate": 4.9867908787541716e-05,
      "loss": 1.3443,
      "step": 20
    },
    {
      "epoch": 0.01668520578420467,
      "grad_norm": 0.8901060223579407,
      "learning_rate": 4.97983870967742e-05,
      "loss": 0.8849,
      "step": 30
    },
    {
      "epoch": 0.02224694104560623,
      "grad_norm": 0.7148659229278564,
      "learning_rate": 4.972886540600668e-05,
      "loss": 0.9508,
      "step": 40
    },
    {
      "epoch": 0.027808676307007785,
      "grad_norm": 0.9565550684928894,
      "learning_rate": 4.965934371523916e-05,
      "loss": 0.7667,
      "step": 50
    },
    {
      "epoch": 0.03337041156840934,
      "grad_norm": 0.6821409463882446,
      "learning_rate": 4.958982202447164e-05,
      "loss": 0.8245,
      "step": 60
    },
    {
      "epoch": 0.0389321468298109,
      "grad_norm": 0.751246988773346,
      "learning_rate": 4.9520300333704114e-05,
      "loss": 0.6898,
      "step": 70
    },
    {
      "epoch": 0.04449388209121246,
      "grad_norm": 1.2306151390075684,
      "learning_rate": 4.9450778642936595e-05,
      "loss": 0.8993,
      "step": 80
    },
    {
      "epoch": 0.05005561735261402,
      "grad_norm": 0.8846468329429626,
      "learning_rate": 4.938125695216908e-05,
      "loss": 0.8112,
      "step": 90
    },
    {
      "epoch": 0.05561735261401557,
      "grad_norm": 1.423006296157837,
      "learning_rate": 4.931173526140156e-05,
      "loss": 0.813,
      "step": 100
    },
    {
      "epoch": 0.06117908787541713,
      "grad_norm": 1.172096610069275,
      "learning_rate": 4.924221357063404e-05,
      "loss": 0.6418,
      "step": 110
    },
    {
      "epoch": 0.06674082313681869,
      "grad_norm": 1.1444743871688843,
      "learning_rate": 4.9172691879866526e-05,
      "loss": 0.5648,
      "step": 120
    },
    {
      "epoch": 0.07230255839822025,
      "grad_norm": 1.1594178676605225,
      "learning_rate": 4.9103170189099e-05,
      "loss": 0.7546,
      "step": 130
    },
    {
      "epoch": 0.0778642936596218,
      "grad_norm": 1.100389003753662,
      "learning_rate": 4.903364849833148e-05,
      "loss": 0.5728,
      "step": 140
    },
    {
      "epoch": 0.08342602892102335,
      "grad_norm": 1.101913332939148,
      "learning_rate": 4.896412680756396e-05,
      "loss": 0.6871,
      "step": 150
    },
    {
      "epoch": 0.08898776418242492,
      "grad_norm": 5.8635029792785645,
      "learning_rate": 4.889460511679644e-05,
      "loss": 0.6608,
      "step": 160
    },
    {
      "epoch": 0.09454949944382647,
      "grad_norm": 0.7511581182479858,
      "learning_rate": 4.8825083426028924e-05,
      "loss": 0.595,
      "step": 170
    },
    {
      "epoch": 0.10011123470522804,
      "grad_norm": 1.0363221168518066,
      "learning_rate": 4.8755561735261405e-05,
      "loss": 0.6003,
      "step": 180
    },
    {
      "epoch": 0.10567296996662959,
      "grad_norm": 0.815268874168396,
      "learning_rate": 4.8686040044493886e-05,
      "loss": 0.6413,
      "step": 190
    },
    {
      "epoch": 0.11123470522803114,
      "grad_norm": 0.7144020795822144,
      "learning_rate": 4.861651835372637e-05,
      "loss": 0.6068,
      "step": 200
    },
    {
      "epoch": 0.1167964404894327,
      "grad_norm": 0.8381993174552917,
      "learning_rate": 4.854699666295884e-05,
      "loss": 0.6796,
      "step": 210
    },
    {
      "epoch": 0.12235817575083426,
      "grad_norm": 1.1710529327392578,
      "learning_rate": 4.847747497219133e-05,
      "loss": 0.7142,
      "step": 220
    },
    {
      "epoch": 0.12791991101223582,
      "grad_norm": 0.5955579876899719,
      "learning_rate": 4.840795328142381e-05,
      "loss": 0.4454,
      "step": 230
    },
    {
      "epoch": 0.13348164627363737,
      "grad_norm": 0.8910718560218811,
      "learning_rate": 4.8338431590656284e-05,
      "loss": 0.6267,
      "step": 240
    },
    {
      "epoch": 0.13904338153503892,
      "grad_norm": 0.5491893291473389,
      "learning_rate": 4.826890989988877e-05,
      "loss": 0.6276,
      "step": 250
    },
    {
      "epoch": 0.1446051167964405,
      "grad_norm": 1.3676902055740356,
      "learning_rate": 4.819938820912125e-05,
      "loss": 0.61,
      "step": 260
    },
    {
      "epoch": 0.15016685205784205,
      "grad_norm": 1.4296607971191406,
      "learning_rate": 4.8129866518353727e-05,
      "loss": 0.5965,
      "step": 270
    },
    {
      "epoch": 0.1557285873192436,
      "grad_norm": 0.5384398102760315,
      "learning_rate": 4.806034482758621e-05,
      "loss": 0.4753,
      "step": 280
    },
    {
      "epoch": 0.16129032258064516,
      "grad_norm": 1.2348922491073608,
      "learning_rate": 4.799082313681869e-05,
      "loss": 0.5502,
      "step": 290
    },
    {
      "epoch": 0.1668520578420467,
      "grad_norm": 0.6758724451065063,
      "learning_rate": 4.792130144605117e-05,
      "loss": 0.489,
      "step": 300
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 0.5294970870018005,
      "learning_rate": 4.785177975528365e-05,
      "loss": 0.6417,
      "step": 310
    },
    {
      "epoch": 0.17797552836484984,
      "grad_norm": 0.41510841250419617,
      "learning_rate": 4.778225806451613e-05,
      "loss": 0.4415,
      "step": 320
    },
    {
      "epoch": 0.1835372636262514,
      "grad_norm": 1.0183379650115967,
      "learning_rate": 4.771273637374861e-05,
      "loss": 0.5701,
      "step": 330
    },
    {
      "epoch": 0.18909899888765294,
      "grad_norm": 0.41732579469680786,
      "learning_rate": 4.764321468298109e-05,
      "loss": 0.5946,
      "step": 340
    },
    {
      "epoch": 0.1946607341490545,
      "grad_norm": 1.4333125352859497,
      "learning_rate": 4.7573692992213574e-05,
      "loss": 0.5739,
      "step": 350
    },
    {
      "epoch": 0.20022246941045607,
      "grad_norm": 0.7246432900428772,
      "learning_rate": 4.7504171301446055e-05,
      "loss": 0.6378,
      "step": 360
    },
    {
      "epoch": 0.20578420467185762,
      "grad_norm": 0.7695886492729187,
      "learning_rate": 4.7434649610678536e-05,
      "loss": 0.4991,
      "step": 370
    },
    {
      "epoch": 0.21134593993325917,
      "grad_norm": 0.6453182101249695,
      "learning_rate": 4.736512791991101e-05,
      "loss": 0.481,
      "step": 380
    },
    {
      "epoch": 0.21690767519466073,
      "grad_norm": 0.5107723474502563,
      "learning_rate": 4.72956062291435e-05,
      "loss": 0.4822,
      "step": 390
    },
    {
      "epoch": 0.22246941045606228,
      "grad_norm": 1.1564799547195435,
      "learning_rate": 4.722608453837597e-05,
      "loss": 0.4509,
      "step": 400
    },
    {
      "epoch": 0.22803114571746386,
      "grad_norm": 0.57452791929245,
      "learning_rate": 4.715656284760845e-05,
      "loss": 0.5468,
      "step": 410
    },
    {
      "epoch": 0.2335928809788654,
      "grad_norm": 0.4877876341342926,
      "learning_rate": 4.708704115684094e-05,
      "loss": 0.5601,
      "step": 420
    },
    {
      "epoch": 0.23915461624026696,
      "grad_norm": 1.2673227787017822,
      "learning_rate": 4.7017519466073415e-05,
      "loss": 0.5881,
      "step": 430
    },
    {
      "epoch": 0.2447163515016685,
      "grad_norm": 1.1010905504226685,
      "learning_rate": 4.6947997775305896e-05,
      "loss": 0.6815,
      "step": 440
    },
    {
      "epoch": 0.25027808676307006,
      "grad_norm": 1.3056578636169434,
      "learning_rate": 4.6878476084538384e-05,
      "loss": 0.4804,
      "step": 450
    },
    {
      "epoch": 0.25583982202447164,
      "grad_norm": 0.7745890617370605,
      "learning_rate": 4.680895439377086e-05,
      "loss": 0.5771,
      "step": 460
    },
    {
      "epoch": 0.26140155728587317,
      "grad_norm": 1.0737452507019043,
      "learning_rate": 4.673943270300334e-05,
      "loss": 0.5105,
      "step": 470
    },
    {
      "epoch": 0.26696329254727474,
      "grad_norm": 0.7220446467399597,
      "learning_rate": 4.666991101223582e-05,
      "loss": 0.5294,
      "step": 480
    },
    {
      "epoch": 0.2725250278086763,
      "grad_norm": 0.7519826292991638,
      "learning_rate": 4.66003893214683e-05,
      "loss": 0.4721,
      "step": 490
    },
    {
      "epoch": 0.27808676307007785,
      "grad_norm": 0.9228230714797974,
      "learning_rate": 4.653086763070078e-05,
      "loss": 0.7005,
      "step": 500
    },
    {
      "epoch": 0.2836484983314794,
      "grad_norm": 0.818547785282135,
      "learning_rate": 4.646134593993326e-05,
      "loss": 0.635,
      "step": 510
    },
    {
      "epoch": 0.289210233592881,
      "grad_norm": 0.8597416281700134,
      "learning_rate": 4.6391824249165744e-05,
      "loss": 0.5921,
      "step": 520
    },
    {
      "epoch": 0.29477196885428253,
      "grad_norm": 1.319675087928772,
      "learning_rate": 4.6322302558398225e-05,
      "loss": 0.5063,
      "step": 530
    },
    {
      "epoch": 0.3003337041156841,
      "grad_norm": 0.5941510200500488,
      "learning_rate": 4.62527808676307e-05,
      "loss": 0.5013,
      "step": 540
    },
    {
      "epoch": 0.30589543937708563,
      "grad_norm": 0.8028301000595093,
      "learning_rate": 4.6183259176863186e-05,
      "loss": 0.4303,
      "step": 550
    },
    {
      "epoch": 0.3114571746384872,
      "grad_norm": 0.6426131129264832,
      "learning_rate": 4.611373748609567e-05,
      "loss": 0.6085,
      "step": 560
    },
    {
      "epoch": 0.3170189098998888,
      "grad_norm": 0.47726669907569885,
      "learning_rate": 4.604421579532814e-05,
      "loss": 0.3715,
      "step": 570
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 0.5873124003410339,
      "learning_rate": 4.597469410456062e-05,
      "loss": 0.483,
      "step": 580
    },
    {
      "epoch": 0.3281423804226919,
      "grad_norm": 0.7739619612693787,
      "learning_rate": 4.590517241379311e-05,
      "loss": 0.638,
      "step": 590
    },
    {
      "epoch": 0.3337041156840934,
      "grad_norm": 0.3978739380836487,
      "learning_rate": 4.5835650723025584e-05,
      "loss": 0.517,
      "step": 600
    },
    {
      "epoch": 0.339265850945495,
      "grad_norm": 0.8331751823425293,
      "learning_rate": 4.5766129032258065e-05,
      "loss": 0.5766,
      "step": 610
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 0.7002637386322021,
      "learning_rate": 4.5696607341490546e-05,
      "loss": 0.4511,
      "step": 620
    },
    {
      "epoch": 0.3503893214682981,
      "grad_norm": 0.7994442582130432,
      "learning_rate": 4.562708565072303e-05,
      "loss": 0.5056,
      "step": 630
    },
    {
      "epoch": 0.3559510567296997,
      "grad_norm": 0.6874408721923828,
      "learning_rate": 4.555756395995551e-05,
      "loss": 0.4127,
      "step": 640
    },
    {
      "epoch": 0.3615127919911012,
      "grad_norm": 0.5121737122535706,
      "learning_rate": 4.548804226918799e-05,
      "loss": 0.5597,
      "step": 650
    },
    {
      "epoch": 0.3670745272525028,
      "grad_norm": 0.6439671516418457,
      "learning_rate": 4.541852057842047e-05,
      "loss": 0.4209,
      "step": 660
    },
    {
      "epoch": 0.37263626251390436,
      "grad_norm": 0.8372392058372498,
      "learning_rate": 4.534899888765295e-05,
      "loss": 0.4785,
      "step": 670
    },
    {
      "epoch": 0.3781979977753059,
      "grad_norm": 0.3934169411659241,
      "learning_rate": 4.5279477196885425e-05,
      "loss": 0.4603,
      "step": 680
    },
    {
      "epoch": 0.38375973303670746,
      "grad_norm": 0.4571261405944824,
      "learning_rate": 4.520995550611791e-05,
      "loss": 0.402,
      "step": 690
    },
    {
      "epoch": 0.389321468298109,
      "grad_norm": 0.5831238031387329,
      "learning_rate": 4.5140433815350394e-05,
      "loss": 0.4903,
      "step": 700
    },
    {
      "epoch": 0.39488320355951056,
      "grad_norm": 1.0447627305984497,
      "learning_rate": 4.507091212458287e-05,
      "loss": 0.4689,
      "step": 710
    },
    {
      "epoch": 0.40044493882091214,
      "grad_norm": 0.9712090492248535,
      "learning_rate": 4.5001390433815356e-05,
      "loss": 0.5081,
      "step": 720
    },
    {
      "epoch": 0.40600667408231367,
      "grad_norm": 0.797478437423706,
      "learning_rate": 4.493186874304784e-05,
      "loss": 0.4668,
      "step": 730
    },
    {
      "epoch": 0.41156840934371525,
      "grad_norm": 0.34340789914131165,
      "learning_rate": 4.486234705228031e-05,
      "loss": 0.4834,
      "step": 740
    },
    {
      "epoch": 0.41713014460511677,
      "grad_norm": 0.8734432458877563,
      "learning_rate": 4.47928253615128e-05,
      "loss": 0.4784,
      "step": 750
    },
    {
      "epoch": 0.42269187986651835,
      "grad_norm": 0.5256807208061218,
      "learning_rate": 4.472330367074527e-05,
      "loss": 0.4363,
      "step": 760
    },
    {
      "epoch": 0.42825361512791993,
      "grad_norm": 0.5640223622322083,
      "learning_rate": 4.4653781979977754e-05,
      "loss": 0.4608,
      "step": 770
    },
    {
      "epoch": 0.43381535038932145,
      "grad_norm": 0.8311137557029724,
      "learning_rate": 4.4584260289210235e-05,
      "loss": 0.513,
      "step": 780
    },
    {
      "epoch": 0.43937708565072303,
      "grad_norm": 0.6450435519218445,
      "learning_rate": 4.4514738598442716e-05,
      "loss": 0.4227,
      "step": 790
    },
    {
      "epoch": 0.44493882091212456,
      "grad_norm": 0.9171372652053833,
      "learning_rate": 4.44452169076752e-05,
      "loss": 0.5237,
      "step": 800
    },
    {
      "epoch": 0.45050055617352613,
      "grad_norm": 0.8862090706825256,
      "learning_rate": 4.437569521690768e-05,
      "loss": 0.5567,
      "step": 810
    },
    {
      "epoch": 0.4560622914349277,
      "grad_norm": 0.7405511736869812,
      "learning_rate": 4.430617352614016e-05,
      "loss": 0.4165,
      "step": 820
    },
    {
      "epoch": 0.46162402669632924,
      "grad_norm": 0.7511187791824341,
      "learning_rate": 4.423665183537264e-05,
      "loss": 0.4756,
      "step": 830
    },
    {
      "epoch": 0.4671857619577308,
      "grad_norm": 0.47134438157081604,
      "learning_rate": 4.416713014460512e-05,
      "loss": 0.4286,
      "step": 840
    },
    {
      "epoch": 0.4727474972191324,
      "grad_norm": 0.7970263957977295,
      "learning_rate": 4.40976084538376e-05,
      "loss": 0.4611,
      "step": 850
    },
    {
      "epoch": 0.4783092324805339,
      "grad_norm": 0.5984987020492554,
      "learning_rate": 4.402808676307008e-05,
      "loss": 0.4396,
      "step": 860
    },
    {
      "epoch": 0.4838709677419355,
      "grad_norm": 0.9741320013999939,
      "learning_rate": 4.395856507230256e-05,
      "loss": 0.5482,
      "step": 870
    },
    {
      "epoch": 0.489432703003337,
      "grad_norm": 0.8839993476867676,
      "learning_rate": 4.388904338153504e-05,
      "loss": 0.4778,
      "step": 880
    },
    {
      "epoch": 0.4949944382647386,
      "grad_norm": 0.695946216583252,
      "learning_rate": 4.3819521690767525e-05,
      "loss": 0.5128,
      "step": 890
    },
    {
      "epoch": 0.5005561735261401,
      "grad_norm": 1.3090813159942627,
      "learning_rate": 4.375e-05,
      "loss": 0.4636,
      "step": 900
    },
    {
      "epoch": 0.5061179087875417,
      "grad_norm": 0.8040421605110168,
      "learning_rate": 4.368047830923248e-05,
      "loss": 0.3835,
      "step": 910
    },
    {
      "epoch": 0.5116796440489433,
      "grad_norm": 0.549232006072998,
      "learning_rate": 4.361095661846497e-05,
      "loss": 0.4891,
      "step": 920
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 0.45676493644714355,
      "learning_rate": 4.354143492769744e-05,
      "loss": 0.4579,
      "step": 930
    },
    {
      "epoch": 0.5228031145717463,
      "grad_norm": 0.6675621867179871,
      "learning_rate": 4.347191323692992e-05,
      "loss": 0.4197,
      "step": 940
    },
    {
      "epoch": 0.5283648498331479,
      "grad_norm": 0.9498982429504395,
      "learning_rate": 4.3402391546162404e-05,
      "loss": 0.6546,
      "step": 950
    },
    {
      "epoch": 0.5339265850945495,
      "grad_norm": 0.45047032833099365,
      "learning_rate": 4.3332869855394885e-05,
      "loss": 0.5212,
      "step": 960
    },
    {
      "epoch": 0.5394883203559511,
      "grad_norm": 0.5908936858177185,
      "learning_rate": 4.3263348164627366e-05,
      "loss": 0.4393,
      "step": 970
    },
    {
      "epoch": 0.5450500556173526,
      "grad_norm": 0.605823278427124,
      "learning_rate": 4.319382647385985e-05,
      "loss": 0.4102,
      "step": 980
    },
    {
      "epoch": 0.5506117908787542,
      "grad_norm": 0.6224651336669922,
      "learning_rate": 4.312430478309233e-05,
      "loss": 0.4823,
      "step": 990
    },
    {
      "epoch": 0.5561735261401557,
      "grad_norm": 0.7430524826049805,
      "learning_rate": 4.305478309232481e-05,
      "loss": 0.4396,
      "step": 1000
    },
    {
      "epoch": 0.5617352614015573,
      "grad_norm": 0.4521581530570984,
      "learning_rate": 4.298526140155728e-05,
      "loss": 0.3757,
      "step": 1010
    },
    {
      "epoch": 0.5672969966629589,
      "grad_norm": 0.7062059640884399,
      "learning_rate": 4.291573971078977e-05,
      "loss": 0.464,
      "step": 1020
    },
    {
      "epoch": 0.5728587319243604,
      "grad_norm": 0.5695302486419678,
      "learning_rate": 4.284621802002225e-05,
      "loss": 0.4379,
      "step": 1030
    },
    {
      "epoch": 0.578420467185762,
      "grad_norm": 0.8680985569953918,
      "learning_rate": 4.2776696329254726e-05,
      "loss": 0.4664,
      "step": 1040
    },
    {
      "epoch": 0.5839822024471635,
      "grad_norm": 0.5428459644317627,
      "learning_rate": 4.270717463848721e-05,
      "loss": 0.4331,
      "step": 1050
    },
    {
      "epoch": 0.5895439377085651,
      "grad_norm": 0.6196666955947876,
      "learning_rate": 4.2637652947719695e-05,
      "loss": 0.3346,
      "step": 1060
    },
    {
      "epoch": 0.5951056729699666,
      "grad_norm": 0.8636741638183594,
      "learning_rate": 4.256813125695217e-05,
      "loss": 0.4499,
      "step": 1070
    },
    {
      "epoch": 0.6006674082313682,
      "grad_norm": 0.7357936501502991,
      "learning_rate": 4.249860956618465e-05,
      "loss": 0.4014,
      "step": 1080
    },
    {
      "epoch": 0.6062291434927698,
      "grad_norm": 0.43654438853263855,
      "learning_rate": 4.242908787541713e-05,
      "loss": 0.4103,
      "step": 1090
    },
    {
      "epoch": 0.6117908787541713,
      "grad_norm": 1.0056612491607666,
      "learning_rate": 4.235956618464961e-05,
      "loss": 0.448,
      "step": 1100
    },
    {
      "epoch": 0.6173526140155728,
      "grad_norm": 0.5290952324867249,
      "learning_rate": 4.229004449388209e-05,
      "loss": 0.3511,
      "step": 1110
    },
    {
      "epoch": 0.6229143492769744,
      "grad_norm": 0.5175420045852661,
      "learning_rate": 4.2220522803114574e-05,
      "loss": 0.4338,
      "step": 1120
    },
    {
      "epoch": 0.628476084538376,
      "grad_norm": 0.6629083156585693,
      "learning_rate": 4.2151001112347055e-05,
      "loss": 0.3824,
      "step": 1130
    },
    {
      "epoch": 0.6340378197997776,
      "grad_norm": 0.5251221656799316,
      "learning_rate": 4.2081479421579536e-05,
      "loss": 0.3979,
      "step": 1140
    },
    {
      "epoch": 0.639599555061179,
      "grad_norm": 0.6854979991912842,
      "learning_rate": 4.201195773081201e-05,
      "loss": 0.4287,
      "step": 1150
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 0.585934042930603,
      "learning_rate": 4.19424360400445e-05,
      "loss": 0.3968,
      "step": 1160
    },
    {
      "epoch": 0.6507230255839822,
      "grad_norm": 0.3926808834075928,
      "learning_rate": 4.187291434927698e-05,
      "loss": 0.3617,
      "step": 1170
    },
    {
      "epoch": 0.6562847608453838,
      "grad_norm": 0.6477160453796387,
      "learning_rate": 4.180339265850945e-05,
      "loss": 0.3854,
      "step": 1180
    },
    {
      "epoch": 0.6618464961067854,
      "grad_norm": 0.432401567697525,
      "learning_rate": 4.173387096774194e-05,
      "loss": 0.559,
      "step": 1190
    },
    {
      "epoch": 0.6674082313681868,
      "grad_norm": 0.4107978045940399,
      "learning_rate": 4.166434927697442e-05,
      "loss": 0.454,
      "step": 1200
    },
    {
      "epoch": 0.6729699666295884,
      "grad_norm": 0.6200776100158691,
      "learning_rate": 4.1594827586206896e-05,
      "loss": 0.3531,
      "step": 1210
    },
    {
      "epoch": 0.67853170189099,
      "grad_norm": 0.533763587474823,
      "learning_rate": 4.152530589543938e-05,
      "loss": 0.4468,
      "step": 1220
    },
    {
      "epoch": 0.6840934371523916,
      "grad_norm": 1.2759897708892822,
      "learning_rate": 4.145578420467186e-05,
      "loss": 0.3744,
      "step": 1230
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.7593809366226196,
      "learning_rate": 4.138626251390434e-05,
      "loss": 0.3181,
      "step": 1240
    },
    {
      "epoch": 0.6952169076751946,
      "grad_norm": 0.7876800894737244,
      "learning_rate": 4.131674082313682e-05,
      "loss": 0.4989,
      "step": 1250
    },
    {
      "epoch": 0.7007786429365962,
      "grad_norm": 0.8353077173233032,
      "learning_rate": 4.12472191323693e-05,
      "loss": 0.347,
      "step": 1260
    },
    {
      "epoch": 0.7063403781979978,
      "grad_norm": 0.38471782207489014,
      "learning_rate": 4.117769744160178e-05,
      "loss": 0.3238,
      "step": 1270
    },
    {
      "epoch": 0.7119021134593994,
      "grad_norm": 0.4690661132335663,
      "learning_rate": 4.110817575083426e-05,
      "loss": 0.4294,
      "step": 1280
    },
    {
      "epoch": 0.7174638487208009,
      "grad_norm": 0.42152100801467896,
      "learning_rate": 4.103865406006674e-05,
      "loss": 0.5408,
      "step": 1290
    },
    {
      "epoch": 0.7230255839822024,
      "grad_norm": 0.6533157229423523,
      "learning_rate": 4.0969132369299224e-05,
      "loss": 0.384,
      "step": 1300
    },
    {
      "epoch": 0.728587319243604,
      "grad_norm": 0.6049360036849976,
      "learning_rate": 4.0899610678531705e-05,
      "loss": 0.5527,
      "step": 1310
    },
    {
      "epoch": 0.7341490545050056,
      "grad_norm": 1.0990878343582153,
      "learning_rate": 4.0830088987764186e-05,
      "loss": 0.368,
      "step": 1320
    },
    {
      "epoch": 0.7397107897664071,
      "grad_norm": 0.4053933322429657,
      "learning_rate": 4.076056729699667e-05,
      "loss": 0.2853,
      "step": 1330
    },
    {
      "epoch": 0.7452725250278087,
      "grad_norm": 0.5772730112075806,
      "learning_rate": 4.069104560622914e-05,
      "loss": 0.5624,
      "step": 1340
    },
    {
      "epoch": 0.7508342602892102,
      "grad_norm": 0.4764140844345093,
      "learning_rate": 4.062152391546162e-05,
      "loss": 0.343,
      "step": 1350
    },
    {
      "epoch": 0.7563959955506118,
      "grad_norm": 0.5199870467185974,
      "learning_rate": 4.055200222469411e-05,
      "loss": 0.4261,
      "step": 1360
    },
    {
      "epoch": 0.7619577308120133,
      "grad_norm": 0.5221707820892334,
      "learning_rate": 4.0482480533926584e-05,
      "loss": 0.3701,
      "step": 1370
    },
    {
      "epoch": 0.7675194660734149,
      "grad_norm": 0.4399644732475281,
      "learning_rate": 4.0412958843159065e-05,
      "loss": 0.3542,
      "step": 1380
    },
    {
      "epoch": 0.7730812013348165,
      "grad_norm": 0.48110535740852356,
      "learning_rate": 4.034343715239155e-05,
      "loss": 0.5134,
      "step": 1390
    },
    {
      "epoch": 0.778642936596218,
      "grad_norm": 0.6386606097221375,
      "learning_rate": 4.027391546162403e-05,
      "loss": 0.3548,
      "step": 1400
    },
    {
      "epoch": 0.7842046718576196,
      "grad_norm": 0.7605119347572327,
      "learning_rate": 4.020439377085651e-05,
      "loss": 0.4856,
      "step": 1410
    },
    {
      "epoch": 0.7897664071190211,
      "grad_norm": 1.1893503665924072,
      "learning_rate": 4.013487208008899e-05,
      "loss": 0.3321,
      "step": 1420
    },
    {
      "epoch": 0.7953281423804227,
      "grad_norm": 0.46310171484947205,
      "learning_rate": 4.006535038932147e-05,
      "loss": 0.3384,
      "step": 1430
    },
    {
      "epoch": 0.8008898776418243,
      "grad_norm": 0.870482861995697,
      "learning_rate": 3.999582869855395e-05,
      "loss": 0.4825,
      "step": 1440
    },
    {
      "epoch": 0.8064516129032258,
      "grad_norm": 0.48402249813079834,
      "learning_rate": 3.992630700778643e-05,
      "loss": 0.38,
      "step": 1450
    },
    {
      "epoch": 0.8120133481646273,
      "grad_norm": 0.523638904094696,
      "learning_rate": 3.985678531701891e-05,
      "loss": 0.3355,
      "step": 1460
    },
    {
      "epoch": 0.8175750834260289,
      "grad_norm": 0.4753722548484802,
      "learning_rate": 3.9787263626251394e-05,
      "loss": 0.3404,
      "step": 1470
    },
    {
      "epoch": 0.8231368186874305,
      "grad_norm": 0.4069725275039673,
      "learning_rate": 3.971774193548387e-05,
      "loss": 0.4111,
      "step": 1480
    },
    {
      "epoch": 0.8286985539488321,
      "grad_norm": 0.5116335153579712,
      "learning_rate": 3.9648220244716356e-05,
      "loss": 0.3481,
      "step": 1490
    },
    {
      "epoch": 0.8342602892102335,
      "grad_norm": 0.426998496055603,
      "learning_rate": 3.9578698553948837e-05,
      "loss": 0.4016,
      "step": 1500
    },
    {
      "epoch": 0.8398220244716351,
      "grad_norm": 0.7460212707519531,
      "learning_rate": 3.950917686318131e-05,
      "loss": 0.4432,
      "step": 1510
    },
    {
      "epoch": 0.8453837597330367,
      "grad_norm": 0.559238851070404,
      "learning_rate": 3.94396551724138e-05,
      "loss": 0.2723,
      "step": 1520
    },
    {
      "epoch": 0.8509454949944383,
      "grad_norm": 0.42031338810920715,
      "learning_rate": 3.937013348164628e-05,
      "loss": 0.3508,
      "step": 1530
    },
    {
      "epoch": 0.8565072302558399,
      "grad_norm": 0.5390011072158813,
      "learning_rate": 3.9300611790878754e-05,
      "loss": 0.3895,
      "step": 1540
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 0.684197723865509,
      "learning_rate": 3.9231090100111234e-05,
      "loss": 0.4652,
      "step": 1550
    },
    {
      "epoch": 0.8676307007786429,
      "grad_norm": 0.48811376094818115,
      "learning_rate": 3.9161568409343715e-05,
      "loss": 0.4384,
      "step": 1560
    },
    {
      "epoch": 0.8731924360400445,
      "grad_norm": 0.8045117259025574,
      "learning_rate": 3.9092046718576196e-05,
      "loss": 0.4223,
      "step": 1570
    },
    {
      "epoch": 0.8787541713014461,
      "grad_norm": 0.6008856892585754,
      "learning_rate": 3.902252502780868e-05,
      "loss": 0.4092,
      "step": 1580
    },
    {
      "epoch": 0.8843159065628476,
      "grad_norm": 0.6629645824432373,
      "learning_rate": 3.895300333704116e-05,
      "loss": 0.4329,
      "step": 1590
    },
    {
      "epoch": 0.8898776418242491,
      "grad_norm": 0.8826934099197388,
      "learning_rate": 3.888348164627364e-05,
      "loss": 0.4784,
      "step": 1600
    },
    {
      "epoch": 0.8954393770856507,
      "grad_norm": 0.5994570255279541,
      "learning_rate": 3.881395995550612e-05,
      "loss": 0.4477,
      "step": 1610
    },
    {
      "epoch": 0.9010011123470523,
      "grad_norm": 0.5502285957336426,
      "learning_rate": 3.87444382647386e-05,
      "loss": 0.3886,
      "step": 1620
    },
    {
      "epoch": 0.9065628476084538,
      "grad_norm": 0.4776727557182312,
      "learning_rate": 3.867491657397108e-05,
      "loss": 0.4154,
      "step": 1630
    },
    {
      "epoch": 0.9121245828698554,
      "grad_norm": 0.5284346342086792,
      "learning_rate": 3.860539488320356e-05,
      "loss": 0.2822,
      "step": 1640
    },
    {
      "epoch": 0.917686318131257,
      "grad_norm": 0.5803051590919495,
      "learning_rate": 3.853587319243604e-05,
      "loss": 0.3412,
      "step": 1650
    },
    {
      "epoch": 0.9232480533926585,
      "grad_norm": 0.42913445830345154,
      "learning_rate": 3.8466351501668525e-05,
      "loss": 0.3405,
      "step": 1660
    },
    {
      "epoch": 0.92880978865406,
      "grad_norm": 0.5831618905067444,
      "learning_rate": 3.8396829810901006e-05,
      "loss": 0.3626,
      "step": 1670
    },
    {
      "epoch": 0.9343715239154616,
      "grad_norm": 0.4179552495479584,
      "learning_rate": 3.832730812013348e-05,
      "loss": 0.3543,
      "step": 1680
    },
    {
      "epoch": 0.9399332591768632,
      "grad_norm": 0.800932765007019,
      "learning_rate": 3.825778642936597e-05,
      "loss": 0.3532,
      "step": 1690
    },
    {
      "epoch": 0.9454949944382648,
      "grad_norm": 0.595123827457428,
      "learning_rate": 3.818826473859844e-05,
      "loss": 0.4134,
      "step": 1700
    },
    {
      "epoch": 0.9510567296996663,
      "grad_norm": 0.5647664070129395,
      "learning_rate": 3.811874304783092e-05,
      "loss": 0.3146,
      "step": 1710
    },
    {
      "epoch": 0.9566184649610678,
      "grad_norm": 0.4878097474575043,
      "learning_rate": 3.804922135706341e-05,
      "loss": 0.4309,
      "step": 1720
    },
    {
      "epoch": 0.9621802002224694,
      "grad_norm": 0.4822239577770233,
      "learning_rate": 3.7979699666295885e-05,
      "loss": 0.3235,
      "step": 1730
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 0.447329044342041,
      "learning_rate": 3.7910177975528366e-05,
      "loss": 0.3705,
      "step": 1740
    },
    {
      "epoch": 0.9733036707452726,
      "grad_norm": 0.5515149235725403,
      "learning_rate": 3.784065628476085e-05,
      "loss": 0.4426,
      "step": 1750
    },
    {
      "epoch": 0.978865406006674,
      "grad_norm": 0.5133271813392639,
      "learning_rate": 3.777113459399333e-05,
      "loss": 0.3548,
      "step": 1760
    },
    {
      "epoch": 0.9844271412680756,
      "grad_norm": 0.5711859464645386,
      "learning_rate": 3.770161290322581e-05,
      "loss": 0.3608,
      "step": 1770
    },
    {
      "epoch": 0.9899888765294772,
      "grad_norm": 0.7628951668739319,
      "learning_rate": 3.763209121245829e-05,
      "loss": 0.422,
      "step": 1780
    },
    {
      "epoch": 0.9955506117908788,
      "grad_norm": 0.7162138223648071,
      "learning_rate": 3.756256952169077e-05,
      "loss": 0.319,
      "step": 1790
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.34065884351730347,
      "eval_runtime": 7.6853,
      "eval_samples_per_second": 208.059,
      "eval_steps_per_second": 26.024,
      "step": 1798
    }
  ],
  "logging_steps": 10,
  "max_steps": 7192,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 486655282642944.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
