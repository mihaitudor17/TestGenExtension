{
  "best_global_step": 7192,
  "best_metric": 0.2771552503108978,
  "best_model_checkpoint": "./model_output/checkpoint-7192",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 7192,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0055617352614015575,
      "grad_norm": 2.5525827407836914,
      "learning_rate": 4.9937430478309235e-05,
      "loss": 2.5411,
      "step": 10
    },
    {
      "epoch": 0.011123470522803115,
      "grad_norm": 1.3268426656723022,
      "learning_rate": 4.9867908787541716e-05,
      "loss": 1.3443,
      "step": 20
    },
    {
      "epoch": 0.01668520578420467,
      "grad_norm": 0.8901060223579407,
      "learning_rate": 4.97983870967742e-05,
      "loss": 0.8849,
      "step": 30
    },
    {
      "epoch": 0.02224694104560623,
      "grad_norm": 0.7148659229278564,
      "learning_rate": 4.972886540600668e-05,
      "loss": 0.9508,
      "step": 40
    },
    {
      "epoch": 0.027808676307007785,
      "grad_norm": 0.9565550684928894,
      "learning_rate": 4.965934371523916e-05,
      "loss": 0.7667,
      "step": 50
    },
    {
      "epoch": 0.03337041156840934,
      "grad_norm": 0.6821409463882446,
      "learning_rate": 4.958982202447164e-05,
      "loss": 0.8245,
      "step": 60
    },
    {
      "epoch": 0.0389321468298109,
      "grad_norm": 0.751246988773346,
      "learning_rate": 4.9520300333704114e-05,
      "loss": 0.6898,
      "step": 70
    },
    {
      "epoch": 0.04449388209121246,
      "grad_norm": 1.2306151390075684,
      "learning_rate": 4.9450778642936595e-05,
      "loss": 0.8993,
      "step": 80
    },
    {
      "epoch": 0.05005561735261402,
      "grad_norm": 0.8846468329429626,
      "learning_rate": 4.938125695216908e-05,
      "loss": 0.8112,
      "step": 90
    },
    {
      "epoch": 0.05561735261401557,
      "grad_norm": 1.423006296157837,
      "learning_rate": 4.931173526140156e-05,
      "loss": 0.813,
      "step": 100
    },
    {
      "epoch": 0.06117908787541713,
      "grad_norm": 1.172096610069275,
      "learning_rate": 4.924221357063404e-05,
      "loss": 0.6418,
      "step": 110
    },
    {
      "epoch": 0.06674082313681869,
      "grad_norm": 1.1444743871688843,
      "learning_rate": 4.9172691879866526e-05,
      "loss": 0.5648,
      "step": 120
    },
    {
      "epoch": 0.07230255839822025,
      "grad_norm": 1.1594178676605225,
      "learning_rate": 4.9103170189099e-05,
      "loss": 0.7546,
      "step": 130
    },
    {
      "epoch": 0.0778642936596218,
      "grad_norm": 1.100389003753662,
      "learning_rate": 4.903364849833148e-05,
      "loss": 0.5728,
      "step": 140
    },
    {
      "epoch": 0.08342602892102335,
      "grad_norm": 1.101913332939148,
      "learning_rate": 4.896412680756396e-05,
      "loss": 0.6871,
      "step": 150
    },
    {
      "epoch": 0.08898776418242492,
      "grad_norm": 5.8635029792785645,
      "learning_rate": 4.889460511679644e-05,
      "loss": 0.6608,
      "step": 160
    },
    {
      "epoch": 0.09454949944382647,
      "grad_norm": 0.7511581182479858,
      "learning_rate": 4.8825083426028924e-05,
      "loss": 0.595,
      "step": 170
    },
    {
      "epoch": 0.10011123470522804,
      "grad_norm": 1.0363221168518066,
      "learning_rate": 4.8755561735261405e-05,
      "loss": 0.6003,
      "step": 180
    },
    {
      "epoch": 0.10567296996662959,
      "grad_norm": 0.815268874168396,
      "learning_rate": 4.8686040044493886e-05,
      "loss": 0.6413,
      "step": 190
    },
    {
      "epoch": 0.11123470522803114,
      "grad_norm": 0.7144020795822144,
      "learning_rate": 4.861651835372637e-05,
      "loss": 0.6068,
      "step": 200
    },
    {
      "epoch": 0.1167964404894327,
      "grad_norm": 0.8381993174552917,
      "learning_rate": 4.854699666295884e-05,
      "loss": 0.6796,
      "step": 210
    },
    {
      "epoch": 0.12235817575083426,
      "grad_norm": 1.1710529327392578,
      "learning_rate": 4.847747497219133e-05,
      "loss": 0.7142,
      "step": 220
    },
    {
      "epoch": 0.12791991101223582,
      "grad_norm": 0.5955579876899719,
      "learning_rate": 4.840795328142381e-05,
      "loss": 0.4454,
      "step": 230
    },
    {
      "epoch": 0.13348164627363737,
      "grad_norm": 0.8910718560218811,
      "learning_rate": 4.8338431590656284e-05,
      "loss": 0.6267,
      "step": 240
    },
    {
      "epoch": 0.13904338153503892,
      "grad_norm": 0.5491893291473389,
      "learning_rate": 4.826890989988877e-05,
      "loss": 0.6276,
      "step": 250
    },
    {
      "epoch": 0.1446051167964405,
      "grad_norm": 1.3676902055740356,
      "learning_rate": 4.819938820912125e-05,
      "loss": 0.61,
      "step": 260
    },
    {
      "epoch": 0.15016685205784205,
      "grad_norm": 1.4296607971191406,
      "learning_rate": 4.8129866518353727e-05,
      "loss": 0.5965,
      "step": 270
    },
    {
      "epoch": 0.1557285873192436,
      "grad_norm": 0.5384398102760315,
      "learning_rate": 4.806034482758621e-05,
      "loss": 0.4753,
      "step": 280
    },
    {
      "epoch": 0.16129032258064516,
      "grad_norm": 1.2348922491073608,
      "learning_rate": 4.799082313681869e-05,
      "loss": 0.5502,
      "step": 290
    },
    {
      "epoch": 0.1668520578420467,
      "grad_norm": 0.6758724451065063,
      "learning_rate": 4.792130144605117e-05,
      "loss": 0.489,
      "step": 300
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 0.5294970870018005,
      "learning_rate": 4.785177975528365e-05,
      "loss": 0.6417,
      "step": 310
    },
    {
      "epoch": 0.17797552836484984,
      "grad_norm": 0.41510841250419617,
      "learning_rate": 4.778225806451613e-05,
      "loss": 0.4415,
      "step": 320
    },
    {
      "epoch": 0.1835372636262514,
      "grad_norm": 1.0183379650115967,
      "learning_rate": 4.771273637374861e-05,
      "loss": 0.5701,
      "step": 330
    },
    {
      "epoch": 0.18909899888765294,
      "grad_norm": 0.41732579469680786,
      "learning_rate": 4.764321468298109e-05,
      "loss": 0.5946,
      "step": 340
    },
    {
      "epoch": 0.1946607341490545,
      "grad_norm": 1.4333125352859497,
      "learning_rate": 4.7573692992213574e-05,
      "loss": 0.5739,
      "step": 350
    },
    {
      "epoch": 0.20022246941045607,
      "grad_norm": 0.7246432900428772,
      "learning_rate": 4.7504171301446055e-05,
      "loss": 0.6378,
      "step": 360
    },
    {
      "epoch": 0.20578420467185762,
      "grad_norm": 0.7695886492729187,
      "learning_rate": 4.7434649610678536e-05,
      "loss": 0.4991,
      "step": 370
    },
    {
      "epoch": 0.21134593993325917,
      "grad_norm": 0.6453182101249695,
      "learning_rate": 4.736512791991101e-05,
      "loss": 0.481,
      "step": 380
    },
    {
      "epoch": 0.21690767519466073,
      "grad_norm": 0.5107723474502563,
      "learning_rate": 4.72956062291435e-05,
      "loss": 0.4822,
      "step": 390
    },
    {
      "epoch": 0.22246941045606228,
      "grad_norm": 1.1564799547195435,
      "learning_rate": 4.722608453837597e-05,
      "loss": 0.4509,
      "step": 400
    },
    {
      "epoch": 0.22803114571746386,
      "grad_norm": 0.57452791929245,
      "learning_rate": 4.715656284760845e-05,
      "loss": 0.5468,
      "step": 410
    },
    {
      "epoch": 0.2335928809788654,
      "grad_norm": 0.4877876341342926,
      "learning_rate": 4.708704115684094e-05,
      "loss": 0.5601,
      "step": 420
    },
    {
      "epoch": 0.23915461624026696,
      "grad_norm": 1.2673227787017822,
      "learning_rate": 4.7017519466073415e-05,
      "loss": 0.5881,
      "step": 430
    },
    {
      "epoch": 0.2447163515016685,
      "grad_norm": 1.1010905504226685,
      "learning_rate": 4.6947997775305896e-05,
      "loss": 0.6815,
      "step": 440
    },
    {
      "epoch": 0.25027808676307006,
      "grad_norm": 1.3056578636169434,
      "learning_rate": 4.6878476084538384e-05,
      "loss": 0.4804,
      "step": 450
    },
    {
      "epoch": 0.25583982202447164,
      "grad_norm": 0.7745890617370605,
      "learning_rate": 4.680895439377086e-05,
      "loss": 0.5771,
      "step": 460
    },
    {
      "epoch": 0.26140155728587317,
      "grad_norm": 1.0737452507019043,
      "learning_rate": 4.673943270300334e-05,
      "loss": 0.5105,
      "step": 470
    },
    {
      "epoch": 0.26696329254727474,
      "grad_norm": 0.7220446467399597,
      "learning_rate": 4.666991101223582e-05,
      "loss": 0.5294,
      "step": 480
    },
    {
      "epoch": 0.2725250278086763,
      "grad_norm": 0.7519826292991638,
      "learning_rate": 4.66003893214683e-05,
      "loss": 0.4721,
      "step": 490
    },
    {
      "epoch": 0.27808676307007785,
      "grad_norm": 0.9228230714797974,
      "learning_rate": 4.653086763070078e-05,
      "loss": 0.7005,
      "step": 500
    },
    {
      "epoch": 0.2836484983314794,
      "grad_norm": 0.818547785282135,
      "learning_rate": 4.646134593993326e-05,
      "loss": 0.635,
      "step": 510
    },
    {
      "epoch": 0.289210233592881,
      "grad_norm": 0.8597416281700134,
      "learning_rate": 4.6391824249165744e-05,
      "loss": 0.5921,
      "step": 520
    },
    {
      "epoch": 0.29477196885428253,
      "grad_norm": 1.319675087928772,
      "learning_rate": 4.6322302558398225e-05,
      "loss": 0.5063,
      "step": 530
    },
    {
      "epoch": 0.3003337041156841,
      "grad_norm": 0.5941510200500488,
      "learning_rate": 4.62527808676307e-05,
      "loss": 0.5013,
      "step": 540
    },
    {
      "epoch": 0.30589543937708563,
      "grad_norm": 0.8028301000595093,
      "learning_rate": 4.6183259176863186e-05,
      "loss": 0.4303,
      "step": 550
    },
    {
      "epoch": 0.3114571746384872,
      "grad_norm": 0.6426131129264832,
      "learning_rate": 4.611373748609567e-05,
      "loss": 0.6085,
      "step": 560
    },
    {
      "epoch": 0.3170189098998888,
      "grad_norm": 0.47726669907569885,
      "learning_rate": 4.604421579532814e-05,
      "loss": 0.3715,
      "step": 570
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 0.5873124003410339,
      "learning_rate": 4.597469410456062e-05,
      "loss": 0.483,
      "step": 580
    },
    {
      "epoch": 0.3281423804226919,
      "grad_norm": 0.7739619612693787,
      "learning_rate": 4.590517241379311e-05,
      "loss": 0.638,
      "step": 590
    },
    {
      "epoch": 0.3337041156840934,
      "grad_norm": 0.3978739380836487,
      "learning_rate": 4.5835650723025584e-05,
      "loss": 0.517,
      "step": 600
    },
    {
      "epoch": 0.339265850945495,
      "grad_norm": 0.8331751823425293,
      "learning_rate": 4.5766129032258065e-05,
      "loss": 0.5766,
      "step": 610
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 0.7002637386322021,
      "learning_rate": 4.5696607341490546e-05,
      "loss": 0.4511,
      "step": 620
    },
    {
      "epoch": 0.3503893214682981,
      "grad_norm": 0.7994442582130432,
      "learning_rate": 4.562708565072303e-05,
      "loss": 0.5056,
      "step": 630
    },
    {
      "epoch": 0.3559510567296997,
      "grad_norm": 0.6874408721923828,
      "learning_rate": 4.555756395995551e-05,
      "loss": 0.4127,
      "step": 640
    },
    {
      "epoch": 0.3615127919911012,
      "grad_norm": 0.5121737122535706,
      "learning_rate": 4.548804226918799e-05,
      "loss": 0.5597,
      "step": 650
    },
    {
      "epoch": 0.3670745272525028,
      "grad_norm": 0.6439671516418457,
      "learning_rate": 4.541852057842047e-05,
      "loss": 0.4209,
      "step": 660
    },
    {
      "epoch": 0.37263626251390436,
      "grad_norm": 0.8372392058372498,
      "learning_rate": 4.534899888765295e-05,
      "loss": 0.4785,
      "step": 670
    },
    {
      "epoch": 0.3781979977753059,
      "grad_norm": 0.3934169411659241,
      "learning_rate": 4.5279477196885425e-05,
      "loss": 0.4603,
      "step": 680
    },
    {
      "epoch": 0.38375973303670746,
      "grad_norm": 0.4571261405944824,
      "learning_rate": 4.520995550611791e-05,
      "loss": 0.402,
      "step": 690
    },
    {
      "epoch": 0.389321468298109,
      "grad_norm": 0.5831238031387329,
      "learning_rate": 4.5140433815350394e-05,
      "loss": 0.4903,
      "step": 700
    },
    {
      "epoch": 0.39488320355951056,
      "grad_norm": 1.0447627305984497,
      "learning_rate": 4.507091212458287e-05,
      "loss": 0.4689,
      "step": 710
    },
    {
      "epoch": 0.40044493882091214,
      "grad_norm": 0.9712090492248535,
      "learning_rate": 4.5001390433815356e-05,
      "loss": 0.5081,
      "step": 720
    },
    {
      "epoch": 0.40600667408231367,
      "grad_norm": 0.797478437423706,
      "learning_rate": 4.493186874304784e-05,
      "loss": 0.4668,
      "step": 730
    },
    {
      "epoch": 0.41156840934371525,
      "grad_norm": 0.34340789914131165,
      "learning_rate": 4.486234705228031e-05,
      "loss": 0.4834,
      "step": 740
    },
    {
      "epoch": 0.41713014460511677,
      "grad_norm": 0.8734432458877563,
      "learning_rate": 4.47928253615128e-05,
      "loss": 0.4784,
      "step": 750
    },
    {
      "epoch": 0.42269187986651835,
      "grad_norm": 0.5256807208061218,
      "learning_rate": 4.472330367074527e-05,
      "loss": 0.4363,
      "step": 760
    },
    {
      "epoch": 0.42825361512791993,
      "grad_norm": 0.5640223622322083,
      "learning_rate": 4.4653781979977754e-05,
      "loss": 0.4608,
      "step": 770
    },
    {
      "epoch": 0.43381535038932145,
      "grad_norm": 0.8311137557029724,
      "learning_rate": 4.4584260289210235e-05,
      "loss": 0.513,
      "step": 780
    },
    {
      "epoch": 0.43937708565072303,
      "grad_norm": 0.6450435519218445,
      "learning_rate": 4.4514738598442716e-05,
      "loss": 0.4227,
      "step": 790
    },
    {
      "epoch": 0.44493882091212456,
      "grad_norm": 0.9171372652053833,
      "learning_rate": 4.44452169076752e-05,
      "loss": 0.5237,
      "step": 800
    },
    {
      "epoch": 0.45050055617352613,
      "grad_norm": 0.8862090706825256,
      "learning_rate": 4.437569521690768e-05,
      "loss": 0.5567,
      "step": 810
    },
    {
      "epoch": 0.4560622914349277,
      "grad_norm": 0.7405511736869812,
      "learning_rate": 4.430617352614016e-05,
      "loss": 0.4165,
      "step": 820
    },
    {
      "epoch": 0.46162402669632924,
      "grad_norm": 0.7511187791824341,
      "learning_rate": 4.423665183537264e-05,
      "loss": 0.4756,
      "step": 830
    },
    {
      "epoch": 0.4671857619577308,
      "grad_norm": 0.47134438157081604,
      "learning_rate": 4.416713014460512e-05,
      "loss": 0.4286,
      "step": 840
    },
    {
      "epoch": 0.4727474972191324,
      "grad_norm": 0.7970263957977295,
      "learning_rate": 4.40976084538376e-05,
      "loss": 0.4611,
      "step": 850
    },
    {
      "epoch": 0.4783092324805339,
      "grad_norm": 0.5984987020492554,
      "learning_rate": 4.402808676307008e-05,
      "loss": 0.4396,
      "step": 860
    },
    {
      "epoch": 0.4838709677419355,
      "grad_norm": 0.9741320013999939,
      "learning_rate": 4.395856507230256e-05,
      "loss": 0.5482,
      "step": 870
    },
    {
      "epoch": 0.489432703003337,
      "grad_norm": 0.8839993476867676,
      "learning_rate": 4.388904338153504e-05,
      "loss": 0.4778,
      "step": 880
    },
    {
      "epoch": 0.4949944382647386,
      "grad_norm": 0.695946216583252,
      "learning_rate": 4.3819521690767525e-05,
      "loss": 0.5128,
      "step": 890
    },
    {
      "epoch": 0.5005561735261401,
      "grad_norm": 1.3090813159942627,
      "learning_rate": 4.375e-05,
      "loss": 0.4636,
      "step": 900
    },
    {
      "epoch": 0.5061179087875417,
      "grad_norm": 0.8040421605110168,
      "learning_rate": 4.368047830923248e-05,
      "loss": 0.3835,
      "step": 910
    },
    {
      "epoch": 0.5116796440489433,
      "grad_norm": 0.549232006072998,
      "learning_rate": 4.361095661846497e-05,
      "loss": 0.4891,
      "step": 920
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 0.45676493644714355,
      "learning_rate": 4.354143492769744e-05,
      "loss": 0.4579,
      "step": 930
    },
    {
      "epoch": 0.5228031145717463,
      "grad_norm": 0.6675621867179871,
      "learning_rate": 4.347191323692992e-05,
      "loss": 0.4197,
      "step": 940
    },
    {
      "epoch": 0.5283648498331479,
      "grad_norm": 0.9498982429504395,
      "learning_rate": 4.3402391546162404e-05,
      "loss": 0.6546,
      "step": 950
    },
    {
      "epoch": 0.5339265850945495,
      "grad_norm": 0.45047032833099365,
      "learning_rate": 4.3332869855394885e-05,
      "loss": 0.5212,
      "step": 960
    },
    {
      "epoch": 0.5394883203559511,
      "grad_norm": 0.5908936858177185,
      "learning_rate": 4.3263348164627366e-05,
      "loss": 0.4393,
      "step": 970
    },
    {
      "epoch": 0.5450500556173526,
      "grad_norm": 0.605823278427124,
      "learning_rate": 4.319382647385985e-05,
      "loss": 0.4102,
      "step": 980
    },
    {
      "epoch": 0.5506117908787542,
      "grad_norm": 0.6224651336669922,
      "learning_rate": 4.312430478309233e-05,
      "loss": 0.4823,
      "step": 990
    },
    {
      "epoch": 0.5561735261401557,
      "grad_norm": 0.7430524826049805,
      "learning_rate": 4.305478309232481e-05,
      "loss": 0.4396,
      "step": 1000
    },
    {
      "epoch": 0.5617352614015573,
      "grad_norm": 0.4521581530570984,
      "learning_rate": 4.298526140155728e-05,
      "loss": 0.3757,
      "step": 1010
    },
    {
      "epoch": 0.5672969966629589,
      "grad_norm": 0.7062059640884399,
      "learning_rate": 4.291573971078977e-05,
      "loss": 0.464,
      "step": 1020
    },
    {
      "epoch": 0.5728587319243604,
      "grad_norm": 0.5695302486419678,
      "learning_rate": 4.284621802002225e-05,
      "loss": 0.4379,
      "step": 1030
    },
    {
      "epoch": 0.578420467185762,
      "grad_norm": 0.8680985569953918,
      "learning_rate": 4.2776696329254726e-05,
      "loss": 0.4664,
      "step": 1040
    },
    {
      "epoch": 0.5839822024471635,
      "grad_norm": 0.5428459644317627,
      "learning_rate": 4.270717463848721e-05,
      "loss": 0.4331,
      "step": 1050
    },
    {
      "epoch": 0.5895439377085651,
      "grad_norm": 0.6196666955947876,
      "learning_rate": 4.2637652947719695e-05,
      "loss": 0.3346,
      "step": 1060
    },
    {
      "epoch": 0.5951056729699666,
      "grad_norm": 0.8636741638183594,
      "learning_rate": 4.256813125695217e-05,
      "loss": 0.4499,
      "step": 1070
    },
    {
      "epoch": 0.6006674082313682,
      "grad_norm": 0.7357936501502991,
      "learning_rate": 4.249860956618465e-05,
      "loss": 0.4014,
      "step": 1080
    },
    {
      "epoch": 0.6062291434927698,
      "grad_norm": 0.43654438853263855,
      "learning_rate": 4.242908787541713e-05,
      "loss": 0.4103,
      "step": 1090
    },
    {
      "epoch": 0.6117908787541713,
      "grad_norm": 1.0056612491607666,
      "learning_rate": 4.235956618464961e-05,
      "loss": 0.448,
      "step": 1100
    },
    {
      "epoch": 0.6173526140155728,
      "grad_norm": 0.5290952324867249,
      "learning_rate": 4.229004449388209e-05,
      "loss": 0.3511,
      "step": 1110
    },
    {
      "epoch": 0.6229143492769744,
      "grad_norm": 0.5175420045852661,
      "learning_rate": 4.2220522803114574e-05,
      "loss": 0.4338,
      "step": 1120
    },
    {
      "epoch": 0.628476084538376,
      "grad_norm": 0.6629083156585693,
      "learning_rate": 4.2151001112347055e-05,
      "loss": 0.3824,
      "step": 1130
    },
    {
      "epoch": 0.6340378197997776,
      "grad_norm": 0.5251221656799316,
      "learning_rate": 4.2081479421579536e-05,
      "loss": 0.3979,
      "step": 1140
    },
    {
      "epoch": 0.639599555061179,
      "grad_norm": 0.6854979991912842,
      "learning_rate": 4.201195773081201e-05,
      "loss": 0.4287,
      "step": 1150
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 0.585934042930603,
      "learning_rate": 4.19424360400445e-05,
      "loss": 0.3968,
      "step": 1160
    },
    {
      "epoch": 0.6507230255839822,
      "grad_norm": 0.3926808834075928,
      "learning_rate": 4.187291434927698e-05,
      "loss": 0.3617,
      "step": 1170
    },
    {
      "epoch": 0.6562847608453838,
      "grad_norm": 0.6477160453796387,
      "learning_rate": 4.180339265850945e-05,
      "loss": 0.3854,
      "step": 1180
    },
    {
      "epoch": 0.6618464961067854,
      "grad_norm": 0.432401567697525,
      "learning_rate": 4.173387096774194e-05,
      "loss": 0.559,
      "step": 1190
    },
    {
      "epoch": 0.6674082313681868,
      "grad_norm": 0.4107978045940399,
      "learning_rate": 4.166434927697442e-05,
      "loss": 0.454,
      "step": 1200
    },
    {
      "epoch": 0.6729699666295884,
      "grad_norm": 0.6200776100158691,
      "learning_rate": 4.1594827586206896e-05,
      "loss": 0.3531,
      "step": 1210
    },
    {
      "epoch": 0.67853170189099,
      "grad_norm": 0.533763587474823,
      "learning_rate": 4.152530589543938e-05,
      "loss": 0.4468,
      "step": 1220
    },
    {
      "epoch": 0.6840934371523916,
      "grad_norm": 1.2759897708892822,
      "learning_rate": 4.145578420467186e-05,
      "loss": 0.3744,
      "step": 1230
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.7593809366226196,
      "learning_rate": 4.138626251390434e-05,
      "loss": 0.3181,
      "step": 1240
    },
    {
      "epoch": 0.6952169076751946,
      "grad_norm": 0.7876800894737244,
      "learning_rate": 4.131674082313682e-05,
      "loss": 0.4989,
      "step": 1250
    },
    {
      "epoch": 0.7007786429365962,
      "grad_norm": 0.8353077173233032,
      "learning_rate": 4.12472191323693e-05,
      "loss": 0.347,
      "step": 1260
    },
    {
      "epoch": 0.7063403781979978,
      "grad_norm": 0.38471782207489014,
      "learning_rate": 4.117769744160178e-05,
      "loss": 0.3238,
      "step": 1270
    },
    {
      "epoch": 0.7119021134593994,
      "grad_norm": 0.4690661132335663,
      "learning_rate": 4.110817575083426e-05,
      "loss": 0.4294,
      "step": 1280
    },
    {
      "epoch": 0.7174638487208009,
      "grad_norm": 0.42152100801467896,
      "learning_rate": 4.103865406006674e-05,
      "loss": 0.5408,
      "step": 1290
    },
    {
      "epoch": 0.7230255839822024,
      "grad_norm": 0.6533157229423523,
      "learning_rate": 4.0969132369299224e-05,
      "loss": 0.384,
      "step": 1300
    },
    {
      "epoch": 0.728587319243604,
      "grad_norm": 0.6049360036849976,
      "learning_rate": 4.0899610678531705e-05,
      "loss": 0.5527,
      "step": 1310
    },
    {
      "epoch": 0.7341490545050056,
      "grad_norm": 1.0990878343582153,
      "learning_rate": 4.0830088987764186e-05,
      "loss": 0.368,
      "step": 1320
    },
    {
      "epoch": 0.7397107897664071,
      "grad_norm": 0.4053933322429657,
      "learning_rate": 4.076056729699667e-05,
      "loss": 0.2853,
      "step": 1330
    },
    {
      "epoch": 0.7452725250278087,
      "grad_norm": 0.5772730112075806,
      "learning_rate": 4.069104560622914e-05,
      "loss": 0.5624,
      "step": 1340
    },
    {
      "epoch": 0.7508342602892102,
      "grad_norm": 0.4764140844345093,
      "learning_rate": 4.062152391546162e-05,
      "loss": 0.343,
      "step": 1350
    },
    {
      "epoch": 0.7563959955506118,
      "grad_norm": 0.5199870467185974,
      "learning_rate": 4.055200222469411e-05,
      "loss": 0.4261,
      "step": 1360
    },
    {
      "epoch": 0.7619577308120133,
      "grad_norm": 0.5221707820892334,
      "learning_rate": 4.0482480533926584e-05,
      "loss": 0.3701,
      "step": 1370
    },
    {
      "epoch": 0.7675194660734149,
      "grad_norm": 0.4399644732475281,
      "learning_rate": 4.0412958843159065e-05,
      "loss": 0.3542,
      "step": 1380
    },
    {
      "epoch": 0.7730812013348165,
      "grad_norm": 0.48110535740852356,
      "learning_rate": 4.034343715239155e-05,
      "loss": 0.5134,
      "step": 1390
    },
    {
      "epoch": 0.778642936596218,
      "grad_norm": 0.6386606097221375,
      "learning_rate": 4.027391546162403e-05,
      "loss": 0.3548,
      "step": 1400
    },
    {
      "epoch": 0.7842046718576196,
      "grad_norm": 0.7605119347572327,
      "learning_rate": 4.020439377085651e-05,
      "loss": 0.4856,
      "step": 1410
    },
    {
      "epoch": 0.7897664071190211,
      "grad_norm": 1.1893503665924072,
      "learning_rate": 4.013487208008899e-05,
      "loss": 0.3321,
      "step": 1420
    },
    {
      "epoch": 0.7953281423804227,
      "grad_norm": 0.46310171484947205,
      "learning_rate": 4.006535038932147e-05,
      "loss": 0.3384,
      "step": 1430
    },
    {
      "epoch": 0.8008898776418243,
      "grad_norm": 0.870482861995697,
      "learning_rate": 3.999582869855395e-05,
      "loss": 0.4825,
      "step": 1440
    },
    {
      "epoch": 0.8064516129032258,
      "grad_norm": 0.48402249813079834,
      "learning_rate": 3.992630700778643e-05,
      "loss": 0.38,
      "step": 1450
    },
    {
      "epoch": 0.8120133481646273,
      "grad_norm": 0.523638904094696,
      "learning_rate": 3.985678531701891e-05,
      "loss": 0.3355,
      "step": 1460
    },
    {
      "epoch": 0.8175750834260289,
      "grad_norm": 0.4753722548484802,
      "learning_rate": 3.9787263626251394e-05,
      "loss": 0.3404,
      "step": 1470
    },
    {
      "epoch": 0.8231368186874305,
      "grad_norm": 0.4069725275039673,
      "learning_rate": 3.971774193548387e-05,
      "loss": 0.4111,
      "step": 1480
    },
    {
      "epoch": 0.8286985539488321,
      "grad_norm": 0.5116335153579712,
      "learning_rate": 3.9648220244716356e-05,
      "loss": 0.3481,
      "step": 1490
    },
    {
      "epoch": 0.8342602892102335,
      "grad_norm": 0.426998496055603,
      "learning_rate": 3.9578698553948837e-05,
      "loss": 0.4016,
      "step": 1500
    },
    {
      "epoch": 0.8398220244716351,
      "grad_norm": 0.7460212707519531,
      "learning_rate": 3.950917686318131e-05,
      "loss": 0.4432,
      "step": 1510
    },
    {
      "epoch": 0.8453837597330367,
      "grad_norm": 0.559238851070404,
      "learning_rate": 3.94396551724138e-05,
      "loss": 0.2723,
      "step": 1520
    },
    {
      "epoch": 0.8509454949944383,
      "grad_norm": 0.42031338810920715,
      "learning_rate": 3.937013348164628e-05,
      "loss": 0.3508,
      "step": 1530
    },
    {
      "epoch": 0.8565072302558399,
      "grad_norm": 0.5390011072158813,
      "learning_rate": 3.9300611790878754e-05,
      "loss": 0.3895,
      "step": 1540
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 0.684197723865509,
      "learning_rate": 3.9231090100111234e-05,
      "loss": 0.4652,
      "step": 1550
    },
    {
      "epoch": 0.8676307007786429,
      "grad_norm": 0.48811376094818115,
      "learning_rate": 3.9161568409343715e-05,
      "loss": 0.4384,
      "step": 1560
    },
    {
      "epoch": 0.8731924360400445,
      "grad_norm": 0.8045117259025574,
      "learning_rate": 3.9092046718576196e-05,
      "loss": 0.4223,
      "step": 1570
    },
    {
      "epoch": 0.8787541713014461,
      "grad_norm": 0.6008856892585754,
      "learning_rate": 3.902252502780868e-05,
      "loss": 0.4092,
      "step": 1580
    },
    {
      "epoch": 0.8843159065628476,
      "grad_norm": 0.6629645824432373,
      "learning_rate": 3.895300333704116e-05,
      "loss": 0.4329,
      "step": 1590
    },
    {
      "epoch": 0.8898776418242491,
      "grad_norm": 0.8826934099197388,
      "learning_rate": 3.888348164627364e-05,
      "loss": 0.4784,
      "step": 1600
    },
    {
      "epoch": 0.8954393770856507,
      "grad_norm": 0.5994570255279541,
      "learning_rate": 3.881395995550612e-05,
      "loss": 0.4477,
      "step": 1610
    },
    {
      "epoch": 0.9010011123470523,
      "grad_norm": 0.5502285957336426,
      "learning_rate": 3.87444382647386e-05,
      "loss": 0.3886,
      "step": 1620
    },
    {
      "epoch": 0.9065628476084538,
      "grad_norm": 0.4776727557182312,
      "learning_rate": 3.867491657397108e-05,
      "loss": 0.4154,
      "step": 1630
    },
    {
      "epoch": 0.9121245828698554,
      "grad_norm": 0.5284346342086792,
      "learning_rate": 3.860539488320356e-05,
      "loss": 0.2822,
      "step": 1640
    },
    {
      "epoch": 0.917686318131257,
      "grad_norm": 0.5803051590919495,
      "learning_rate": 3.853587319243604e-05,
      "loss": 0.3412,
      "step": 1650
    },
    {
      "epoch": 0.9232480533926585,
      "grad_norm": 0.42913445830345154,
      "learning_rate": 3.8466351501668525e-05,
      "loss": 0.3405,
      "step": 1660
    },
    {
      "epoch": 0.92880978865406,
      "grad_norm": 0.5831618905067444,
      "learning_rate": 3.8396829810901006e-05,
      "loss": 0.3626,
      "step": 1670
    },
    {
      "epoch": 0.9343715239154616,
      "grad_norm": 0.4179552495479584,
      "learning_rate": 3.832730812013348e-05,
      "loss": 0.3543,
      "step": 1680
    },
    {
      "epoch": 0.9399332591768632,
      "grad_norm": 0.800932765007019,
      "learning_rate": 3.825778642936597e-05,
      "loss": 0.3532,
      "step": 1690
    },
    {
      "epoch": 0.9454949944382648,
      "grad_norm": 0.595123827457428,
      "learning_rate": 3.818826473859844e-05,
      "loss": 0.4134,
      "step": 1700
    },
    {
      "epoch": 0.9510567296996663,
      "grad_norm": 0.5647664070129395,
      "learning_rate": 3.811874304783092e-05,
      "loss": 0.3146,
      "step": 1710
    },
    {
      "epoch": 0.9566184649610678,
      "grad_norm": 0.4878097474575043,
      "learning_rate": 3.804922135706341e-05,
      "loss": 0.4309,
      "step": 1720
    },
    {
      "epoch": 0.9621802002224694,
      "grad_norm": 0.4822239577770233,
      "learning_rate": 3.7979699666295885e-05,
      "loss": 0.3235,
      "step": 1730
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 0.447329044342041,
      "learning_rate": 3.7910177975528366e-05,
      "loss": 0.3705,
      "step": 1740
    },
    {
      "epoch": 0.9733036707452726,
      "grad_norm": 0.5515149235725403,
      "learning_rate": 3.784065628476085e-05,
      "loss": 0.4426,
      "step": 1750
    },
    {
      "epoch": 0.978865406006674,
      "grad_norm": 0.5133271813392639,
      "learning_rate": 3.777113459399333e-05,
      "loss": 0.3548,
      "step": 1760
    },
    {
      "epoch": 0.9844271412680756,
      "grad_norm": 0.5711859464645386,
      "learning_rate": 3.770161290322581e-05,
      "loss": 0.3608,
      "step": 1770
    },
    {
      "epoch": 0.9899888765294772,
      "grad_norm": 0.7628951668739319,
      "learning_rate": 3.763209121245829e-05,
      "loss": 0.422,
      "step": 1780
    },
    {
      "epoch": 0.9955506117908788,
      "grad_norm": 0.7162138223648071,
      "learning_rate": 3.756256952169077e-05,
      "loss": 0.319,
      "step": 1790
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.34065884351730347,
      "eval_runtime": 7.6853,
      "eval_samples_per_second": 208.059,
      "eval_steps_per_second": 26.024,
      "step": 1798
    },
    {
      "epoch": 1.0011123470522802,
      "grad_norm": 0.3152831494808197,
      "learning_rate": 3.749304783092325e-05,
      "loss": 0.4161,
      "step": 1800
    },
    {
      "epoch": 1.006674082313682,
      "grad_norm": 0.5285692811012268,
      "learning_rate": 3.7423526140155726e-05,
      "loss": 0.3954,
      "step": 1810
    },
    {
      "epoch": 1.0122358175750834,
      "grad_norm": 0.9164868593215942,
      "learning_rate": 3.7354004449388213e-05,
      "loss": 0.4168,
      "step": 1820
    },
    {
      "epoch": 1.0177975528364849,
      "grad_norm": 0.63432377576828,
      "learning_rate": 3.7284482758620694e-05,
      "loss": 0.3651,
      "step": 1830
    },
    {
      "epoch": 1.0233592880978866,
      "grad_norm": 0.5960706472396851,
      "learning_rate": 3.721496106785317e-05,
      "loss": 0.3149,
      "step": 1840
    },
    {
      "epoch": 1.028921023359288,
      "grad_norm": 0.9236274361610413,
      "learning_rate": 3.714543937708565e-05,
      "loss": 0.4841,
      "step": 1850
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 0.8874687552452087,
      "learning_rate": 3.707591768631814e-05,
      "loss": 0.3007,
      "step": 1860
    },
    {
      "epoch": 1.0400444938820912,
      "grad_norm": 0.6550981402397156,
      "learning_rate": 3.700639599555061e-05,
      "loss": 0.3826,
      "step": 1870
    },
    {
      "epoch": 1.0456062291434929,
      "grad_norm": 0.6283860206604004,
      "learning_rate": 3.693687430478309e-05,
      "loss": 0.4589,
      "step": 1880
    },
    {
      "epoch": 1.0511679644048944,
      "grad_norm": 0.8383861780166626,
      "learning_rate": 3.6867352614015573e-05,
      "loss": 0.3929,
      "step": 1890
    },
    {
      "epoch": 1.0567296996662958,
      "grad_norm": 1.0551563501358032,
      "learning_rate": 3.6797830923248054e-05,
      "loss": 0.3366,
      "step": 1900
    },
    {
      "epoch": 1.0622914349276975,
      "grad_norm": 0.7981504201889038,
      "learning_rate": 3.6728309232480535e-05,
      "loss": 0.3839,
      "step": 1910
    },
    {
      "epoch": 1.067853170189099,
      "grad_norm": 0.6106035113334656,
      "learning_rate": 3.6658787541713016e-05,
      "loss": 0.3997,
      "step": 1920
    },
    {
      "epoch": 1.0734149054505004,
      "grad_norm": 0.6412799954414368,
      "learning_rate": 3.65892658509455e-05,
      "loss": 0.381,
      "step": 1930
    },
    {
      "epoch": 1.0789766407119021,
      "grad_norm": 0.5730671286582947,
      "learning_rate": 3.651974416017798e-05,
      "loss": 0.417,
      "step": 1940
    },
    {
      "epoch": 1.0845383759733036,
      "grad_norm": 0.803517758846283,
      "learning_rate": 3.645022246941045e-05,
      "loss": 0.3497,
      "step": 1950
    },
    {
      "epoch": 1.0901001112347053,
      "grad_norm": 0.8822663426399231,
      "learning_rate": 3.638070077864294e-05,
      "loss": 0.4765,
      "step": 1960
    },
    {
      "epoch": 1.0956618464961068,
      "grad_norm": 0.6745765209197998,
      "learning_rate": 3.631117908787542e-05,
      "loss": 0.3745,
      "step": 1970
    },
    {
      "epoch": 1.1012235817575085,
      "grad_norm": 0.5872057676315308,
      "learning_rate": 3.6241657397107895e-05,
      "loss": 0.2802,
      "step": 1980
    },
    {
      "epoch": 1.10678531701891,
      "grad_norm": 0.982037365436554,
      "learning_rate": 3.617213570634038e-05,
      "loss": 0.388,
      "step": 1990
    },
    {
      "epoch": 1.1123470522803114,
      "grad_norm": 0.4529235363006592,
      "learning_rate": 3.6102614015572864e-05,
      "loss": 0.3992,
      "step": 2000
    },
    {
      "epoch": 1.117908787541713,
      "grad_norm": 0.4494197368621826,
      "learning_rate": 3.603309232480534e-05,
      "loss": 0.3173,
      "step": 2010
    },
    {
      "epoch": 1.1234705228031145,
      "grad_norm": 0.6014623045921326,
      "learning_rate": 3.5963570634037826e-05,
      "loss": 0.3475,
      "step": 2020
    },
    {
      "epoch": 1.129032258064516,
      "grad_norm": 0.41498851776123047,
      "learning_rate": 3.58940489432703e-05,
      "loss": 0.2972,
      "step": 2030
    },
    {
      "epoch": 1.1345939933259177,
      "grad_norm": 0.577235758304596,
      "learning_rate": 3.582452725250278e-05,
      "loss": 0.3038,
      "step": 2040
    },
    {
      "epoch": 1.1401557285873192,
      "grad_norm": 0.4034533202648163,
      "learning_rate": 3.575500556173526e-05,
      "loss": 0.4181,
      "step": 2050
    },
    {
      "epoch": 1.1457174638487209,
      "grad_norm": 0.6050820350646973,
      "learning_rate": 3.568548387096774e-05,
      "loss": 0.3584,
      "step": 2060
    },
    {
      "epoch": 1.1512791991101223,
      "grad_norm": 0.44698765873908997,
      "learning_rate": 3.5615962180200224e-05,
      "loss": 0.4012,
      "step": 2070
    },
    {
      "epoch": 1.156840934371524,
      "grad_norm": 0.3616802990436554,
      "learning_rate": 3.5546440489432705e-05,
      "loss": 0.3678,
      "step": 2080
    },
    {
      "epoch": 1.1624026696329255,
      "grad_norm": 0.3789844512939453,
      "learning_rate": 3.5476918798665186e-05,
      "loss": 0.2801,
      "step": 2090
    },
    {
      "epoch": 1.167964404894327,
      "grad_norm": 0.8003667593002319,
      "learning_rate": 3.540739710789767e-05,
      "loss": 0.241,
      "step": 2100
    },
    {
      "epoch": 1.1735261401557286,
      "grad_norm": 0.6376257538795471,
      "learning_rate": 3.533787541713015e-05,
      "loss": 0.3275,
      "step": 2110
    },
    {
      "epoch": 1.1790878754171301,
      "grad_norm": 0.3614793121814728,
      "learning_rate": 3.526835372636263e-05,
      "loss": 0.3582,
      "step": 2120
    },
    {
      "epoch": 1.1846496106785316,
      "grad_norm": 0.572265625,
      "learning_rate": 3.519883203559511e-05,
      "loss": 0.2917,
      "step": 2130
    },
    {
      "epoch": 1.1902113459399333,
      "grad_norm": 0.8907924294471741,
      "learning_rate": 3.512931034482759e-05,
      "loss": 0.4099,
      "step": 2140
    },
    {
      "epoch": 1.1957730812013347,
      "grad_norm": 0.6072726845741272,
      "learning_rate": 3.5059788654060065e-05,
      "loss": 0.2666,
      "step": 2150
    },
    {
      "epoch": 1.2013348164627364,
      "grad_norm": 0.6031574010848999,
      "learning_rate": 3.499026696329255e-05,
      "loss": 0.3088,
      "step": 2160
    },
    {
      "epoch": 1.206896551724138,
      "grad_norm": 0.4473423659801483,
      "learning_rate": 3.4920745272525027e-05,
      "loss": 0.3831,
      "step": 2170
    },
    {
      "epoch": 1.2124582869855396,
      "grad_norm": 0.5695571303367615,
      "learning_rate": 3.485122358175751e-05,
      "loss": 0.288,
      "step": 2180
    },
    {
      "epoch": 1.218020022246941,
      "grad_norm": 0.6912129521369934,
      "learning_rate": 3.4781701890989995e-05,
      "loss": 0.326,
      "step": 2190
    },
    {
      "epoch": 1.2235817575083425,
      "grad_norm": 0.7395942211151123,
      "learning_rate": 3.471218020022247e-05,
      "loss": 0.4397,
      "step": 2200
    },
    {
      "epoch": 1.2291434927697442,
      "grad_norm": 0.6862102746963501,
      "learning_rate": 3.464265850945495e-05,
      "loss": 0.3818,
      "step": 2210
    },
    {
      "epoch": 1.2347052280311457,
      "grad_norm": 0.524557888507843,
      "learning_rate": 3.457313681868743e-05,
      "loss": 0.3173,
      "step": 2220
    },
    {
      "epoch": 1.2402669632925472,
      "grad_norm": 0.6976358890533447,
      "learning_rate": 3.450361512791991e-05,
      "loss": 0.4165,
      "step": 2230
    },
    {
      "epoch": 1.2458286985539488,
      "grad_norm": 0.44882142543792725,
      "learning_rate": 3.443409343715239e-05,
      "loss": 0.2917,
      "step": 2240
    },
    {
      "epoch": 1.2513904338153503,
      "grad_norm": 0.4772804081439972,
      "learning_rate": 3.4364571746384874e-05,
      "loss": 0.3517,
      "step": 2250
    },
    {
      "epoch": 1.256952169076752,
      "grad_norm": 0.7102514505386353,
      "learning_rate": 3.4295050055617355e-05,
      "loss": 0.4052,
      "step": 2260
    },
    {
      "epoch": 1.2625139043381535,
      "grad_norm": 0.393222451210022,
      "learning_rate": 3.4225528364849836e-05,
      "loss": 0.3578,
      "step": 2270
    },
    {
      "epoch": 1.2680756395995552,
      "grad_norm": 0.3036554157733917,
      "learning_rate": 3.415600667408232e-05,
      "loss": 0.3486,
      "step": 2280
    },
    {
      "epoch": 1.2736373748609566,
      "grad_norm": 0.6243816614151001,
      "learning_rate": 3.40864849833148e-05,
      "loss": 0.324,
      "step": 2290
    },
    {
      "epoch": 1.279199110122358,
      "grad_norm": 0.33007171750068665,
      "learning_rate": 3.401696329254728e-05,
      "loss": 0.3627,
      "step": 2300
    },
    {
      "epoch": 1.2847608453837598,
      "grad_norm": 0.35035109519958496,
      "learning_rate": 3.394744160177975e-05,
      "loss": 0.3132,
      "step": 2310
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 0.41482552886009216,
      "learning_rate": 3.3877919911012234e-05,
      "loss": 0.3897,
      "step": 2320
    },
    {
      "epoch": 1.2958843159065627,
      "grad_norm": 0.5588271617889404,
      "learning_rate": 3.380839822024472e-05,
      "loss": 0.3899,
      "step": 2330
    },
    {
      "epoch": 1.3014460511679644,
      "grad_norm": 0.40364983677864075,
      "learning_rate": 3.3738876529477196e-05,
      "loss": 0.3965,
      "step": 2340
    },
    {
      "epoch": 1.3070077864293659,
      "grad_norm": 0.6026041507720947,
      "learning_rate": 3.366935483870968e-05,
      "loss": 0.3615,
      "step": 2350
    },
    {
      "epoch": 1.3125695216907676,
      "grad_norm": 0.6745402216911316,
      "learning_rate": 3.359983314794216e-05,
      "loss": 0.3087,
      "step": 2360
    },
    {
      "epoch": 1.318131256952169,
      "grad_norm": 0.3921054005622864,
      "learning_rate": 3.353031145717464e-05,
      "loss": 0.2911,
      "step": 2370
    },
    {
      "epoch": 1.3236929922135707,
      "grad_norm": 0.7617361545562744,
      "learning_rate": 3.346078976640712e-05,
      "loss": 0.3487,
      "step": 2380
    },
    {
      "epoch": 1.3292547274749722,
      "grad_norm": 0.47120195627212524,
      "learning_rate": 3.33912680756396e-05,
      "loss": 0.3686,
      "step": 2390
    },
    {
      "epoch": 1.3348164627363737,
      "grad_norm": 0.5236061215400696,
      "learning_rate": 3.332174638487208e-05,
      "loss": 0.3555,
      "step": 2400
    },
    {
      "epoch": 1.3403781979977754,
      "grad_norm": 0.6016117930412292,
      "learning_rate": 3.325222469410456e-05,
      "loss": 0.3196,
      "step": 2410
    },
    {
      "epoch": 1.3459399332591768,
      "grad_norm": 0.6376500725746155,
      "learning_rate": 3.318270300333704e-05,
      "loss": 0.3451,
      "step": 2420
    },
    {
      "epoch": 1.3515016685205783,
      "grad_norm": 0.4058801233768463,
      "learning_rate": 3.3113181312569525e-05,
      "loss": 0.2847,
      "step": 2430
    },
    {
      "epoch": 1.35706340378198,
      "grad_norm": 0.40464186668395996,
      "learning_rate": 3.3043659621802006e-05,
      "loss": 0.2935,
      "step": 2440
    },
    {
      "epoch": 1.3626251390433817,
      "grad_norm": 0.4858924448490143,
      "learning_rate": 3.297413793103448e-05,
      "loss": 0.406,
      "step": 2450
    },
    {
      "epoch": 1.3681868743047831,
      "grad_norm": 0.8338244557380676,
      "learning_rate": 3.290461624026697e-05,
      "loss": 0.2927,
      "step": 2460
    },
    {
      "epoch": 1.3737486095661846,
      "grad_norm": 0.7640155553817749,
      "learning_rate": 3.283509454949945e-05,
      "loss": 0.4795,
      "step": 2470
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 0.533825159072876,
      "learning_rate": 3.276557285873192e-05,
      "loss": 0.356,
      "step": 2480
    },
    {
      "epoch": 1.3848720800889878,
      "grad_norm": 0.48709729313850403,
      "learning_rate": 3.269605116796441e-05,
      "loss": 0.4171,
      "step": 2490
    },
    {
      "epoch": 1.3904338153503892,
      "grad_norm": 0.2889058291912079,
      "learning_rate": 3.2626529477196885e-05,
      "loss": 0.3633,
      "step": 2500
    },
    {
      "epoch": 1.395995550611791,
      "grad_norm": 0.7104504108428955,
      "learning_rate": 3.2557007786429365e-05,
      "loss": 0.341,
      "step": 2510
    },
    {
      "epoch": 1.4015572858731924,
      "grad_norm": 0.8131512403488159,
      "learning_rate": 3.2487486095661846e-05,
      "loss": 0.4012,
      "step": 2520
    },
    {
      "epoch": 1.4071190211345939,
      "grad_norm": 0.35165491700172424,
      "learning_rate": 3.241796440489433e-05,
      "loss": 0.3257,
      "step": 2530
    },
    {
      "epoch": 1.4126807563959956,
      "grad_norm": 0.44587668776512146,
      "learning_rate": 3.234844271412681e-05,
      "loss": 0.346,
      "step": 2540
    },
    {
      "epoch": 1.4182424916573972,
      "grad_norm": 0.6354359984397888,
      "learning_rate": 3.227892102335929e-05,
      "loss": 0.4188,
      "step": 2550
    },
    {
      "epoch": 1.4238042269187987,
      "grad_norm": 0.5301926136016846,
      "learning_rate": 3.220939933259177e-05,
      "loss": 0.3883,
      "step": 2560
    },
    {
      "epoch": 1.4293659621802002,
      "grad_norm": 0.69133460521698,
      "learning_rate": 3.213987764182425e-05,
      "loss": 0.3932,
      "step": 2570
    },
    {
      "epoch": 1.4349276974416019,
      "grad_norm": 1.0092809200286865,
      "learning_rate": 3.207035595105673e-05,
      "loss": 0.492,
      "step": 2580
    },
    {
      "epoch": 1.4404894327030033,
      "grad_norm": 0.564856231212616,
      "learning_rate": 3.200083426028921e-05,
      "loss": 0.371,
      "step": 2590
    },
    {
      "epoch": 1.4460511679644048,
      "grad_norm": 0.7629205584526062,
      "learning_rate": 3.1931312569521694e-05,
      "loss": 0.4738,
      "step": 2600
    },
    {
      "epoch": 1.4516129032258065,
      "grad_norm": 0.48135605454444885,
      "learning_rate": 3.1861790878754175e-05,
      "loss": 0.3513,
      "step": 2610
    },
    {
      "epoch": 1.457174638487208,
      "grad_norm": 0.5569141507148743,
      "learning_rate": 3.179226918798665e-05,
      "loss": 0.3002,
      "step": 2620
    },
    {
      "epoch": 1.4627363737486094,
      "grad_norm": 0.5808118581771851,
      "learning_rate": 3.172274749721914e-05,
      "loss": 0.2567,
      "step": 2630
    },
    {
      "epoch": 1.4682981090100111,
      "grad_norm": 0.5520724654197693,
      "learning_rate": 3.165322580645161e-05,
      "loss": 0.2849,
      "step": 2640
    },
    {
      "epoch": 1.4738598442714128,
      "grad_norm": 0.37701037526130676,
      "learning_rate": 3.158370411568409e-05,
      "loss": 0.3746,
      "step": 2650
    },
    {
      "epoch": 1.4794215795328143,
      "grad_norm": 1.0480073690414429,
      "learning_rate": 3.151418242491658e-05,
      "loss": 0.3043,
      "step": 2660
    },
    {
      "epoch": 1.4849833147942157,
      "grad_norm": 0.5904709100723267,
      "learning_rate": 3.1444660734149054e-05,
      "loss": 0.3577,
      "step": 2670
    },
    {
      "epoch": 1.4905450500556174,
      "grad_norm": 0.3596796691417694,
      "learning_rate": 3.1375139043381535e-05,
      "loss": 0.3323,
      "step": 2680
    },
    {
      "epoch": 1.496106785317019,
      "grad_norm": 0.4109443128108978,
      "learning_rate": 3.130561735261402e-05,
      "loss": 0.499,
      "step": 2690
    },
    {
      "epoch": 1.5016685205784204,
      "grad_norm": 0.3976174592971802,
      "learning_rate": 3.12360956618465e-05,
      "loss": 0.3153,
      "step": 2700
    },
    {
      "epoch": 1.507230255839822,
      "grad_norm": 0.3997154235839844,
      "learning_rate": 3.116657397107898e-05,
      "loss": 0.2872,
      "step": 2710
    },
    {
      "epoch": 1.5127919911012235,
      "grad_norm": 0.5338411927223206,
      "learning_rate": 3.109705228031146e-05,
      "loss": 0.4963,
      "step": 2720
    },
    {
      "epoch": 1.518353726362625,
      "grad_norm": 0.6368888020515442,
      "learning_rate": 3.102753058954394e-05,
      "loss": 0.3712,
      "step": 2730
    },
    {
      "epoch": 1.5239154616240267,
      "grad_norm": 1.5893088579177856,
      "learning_rate": 3.095800889877642e-05,
      "loss": 0.2777,
      "step": 2740
    },
    {
      "epoch": 1.5294771968854284,
      "grad_norm": 0.5849891901016235,
      "learning_rate": 3.08884872080089e-05,
      "loss": 0.313,
      "step": 2750
    },
    {
      "epoch": 1.5350389321468298,
      "grad_norm": 0.6830759048461914,
      "learning_rate": 3.081896551724138e-05,
      "loss": 0.4036,
      "step": 2760
    },
    {
      "epoch": 1.5406006674082313,
      "grad_norm": 0.34332314133644104,
      "learning_rate": 3.0749443826473864e-05,
      "loss": 0.3531,
      "step": 2770
    },
    {
      "epoch": 1.546162402669633,
      "grad_norm": 0.7611711025238037,
      "learning_rate": 3.067992213570634e-05,
      "loss": 0.2823,
      "step": 2780
    },
    {
      "epoch": 1.5517241379310345,
      "grad_norm": 0.3790748715400696,
      "learning_rate": 3.0610400444938825e-05,
      "loss": 0.2849,
      "step": 2790
    },
    {
      "epoch": 1.557285873192436,
      "grad_norm": 0.5655596852302551,
      "learning_rate": 3.0540878754171306e-05,
      "loss": 0.354,
      "step": 2800
    },
    {
      "epoch": 1.5628476084538376,
      "grad_norm": 0.8359744548797607,
      "learning_rate": 3.0471357063403784e-05,
      "loss": 0.3293,
      "step": 2810
    },
    {
      "epoch": 1.568409343715239,
      "grad_norm": 0.5426874160766602,
      "learning_rate": 3.040183537263626e-05,
      "loss": 0.3668,
      "step": 2820
    },
    {
      "epoch": 1.5739710789766406,
      "grad_norm": 0.2711050510406494,
      "learning_rate": 3.0332313681868746e-05,
      "loss": 0.3628,
      "step": 2830
    },
    {
      "epoch": 1.5795328142380423,
      "grad_norm": 0.3454471230506897,
      "learning_rate": 3.0262791991101223e-05,
      "loss": 0.2907,
      "step": 2840
    },
    {
      "epoch": 1.585094549499444,
      "grad_norm": 0.49028587341308594,
      "learning_rate": 3.0193270300333704e-05,
      "loss": 0.3103,
      "step": 2850
    },
    {
      "epoch": 1.5906562847608454,
      "grad_norm": 0.4229199290275574,
      "learning_rate": 3.012374860956619e-05,
      "loss": 0.296,
      "step": 2860
    },
    {
      "epoch": 1.5962180200222469,
      "grad_norm": 0.4542057514190674,
      "learning_rate": 3.0054226918798666e-05,
      "loss": 0.3294,
      "step": 2870
    },
    {
      "epoch": 1.6017797552836486,
      "grad_norm": 0.8058445453643799,
      "learning_rate": 2.9984705228031147e-05,
      "loss": 0.3785,
      "step": 2880
    },
    {
      "epoch": 1.60734149054505,
      "grad_norm": 0.6703454852104187,
      "learning_rate": 2.991518353726363e-05,
      "loss": 0.3457,
      "step": 2890
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 0.5811227560043335,
      "learning_rate": 2.984566184649611e-05,
      "loss": 0.3917,
      "step": 2900
    },
    {
      "epoch": 1.6184649610678532,
      "grad_norm": 0.5366581082344055,
      "learning_rate": 2.9776140155728587e-05,
      "loss": 0.299,
      "step": 2910
    },
    {
      "epoch": 1.624026696329255,
      "grad_norm": 0.6845455169677734,
      "learning_rate": 2.9706618464961068e-05,
      "loss": 0.3418,
      "step": 2920
    },
    {
      "epoch": 1.6295884315906561,
      "grad_norm": 0.5612801313400269,
      "learning_rate": 2.9637096774193552e-05,
      "loss": 0.2921,
      "step": 2930
    },
    {
      "epoch": 1.6351501668520578,
      "grad_norm": 0.43656107783317566,
      "learning_rate": 2.956757508342603e-05,
      "loss": 0.2693,
      "step": 2940
    },
    {
      "epoch": 1.6407119021134595,
      "grad_norm": 0.5949623584747314,
      "learning_rate": 2.949805339265851e-05,
      "loss": 0.3849,
      "step": 2950
    },
    {
      "epoch": 1.646273637374861,
      "grad_norm": 0.3570050895214081,
      "learning_rate": 2.9428531701890995e-05,
      "loss": 0.2882,
      "step": 2960
    },
    {
      "epoch": 1.6518353726362625,
      "grad_norm": 0.4204273819923401,
      "learning_rate": 2.9359010011123472e-05,
      "loss": 0.2676,
      "step": 2970
    },
    {
      "epoch": 1.6573971078976641,
      "grad_norm": 0.5754076242446899,
      "learning_rate": 2.928948832035595e-05,
      "loss": 0.3416,
      "step": 2980
    },
    {
      "epoch": 1.6629588431590656,
      "grad_norm": 0.3936227560043335,
      "learning_rate": 2.9219966629588434e-05,
      "loss": 0.4703,
      "step": 2990
    },
    {
      "epoch": 1.668520578420467,
      "grad_norm": 0.7272403836250305,
      "learning_rate": 2.9150444938820915e-05,
      "loss": 0.3196,
      "step": 3000
    },
    {
      "epoch": 1.6740823136818688,
      "grad_norm": 0.4378470480442047,
      "learning_rate": 2.9080923248053393e-05,
      "loss": 0.312,
      "step": 3010
    },
    {
      "epoch": 1.6796440489432705,
      "grad_norm": 0.5083019733428955,
      "learning_rate": 2.9011401557285874e-05,
      "loss": 0.2874,
      "step": 3020
    },
    {
      "epoch": 1.6852057842046717,
      "grad_norm": 0.5261993408203125,
      "learning_rate": 2.8941879866518358e-05,
      "loss": 0.3562,
      "step": 3030
    },
    {
      "epoch": 1.6907675194660734,
      "grad_norm": 0.8859739899635315,
      "learning_rate": 2.8872358175750836e-05,
      "loss": 0.4371,
      "step": 3040
    },
    {
      "epoch": 1.696329254727475,
      "grad_norm": 0.595503568649292,
      "learning_rate": 2.8802836484983313e-05,
      "loss": 0.3551,
      "step": 3050
    },
    {
      "epoch": 1.7018909899888766,
      "grad_norm": 0.3198617100715637,
      "learning_rate": 2.8733314794215798e-05,
      "loss": 0.3182,
      "step": 3060
    },
    {
      "epoch": 1.707452725250278,
      "grad_norm": 1.0404884815216064,
      "learning_rate": 2.866379310344828e-05,
      "loss": 0.3296,
      "step": 3070
    },
    {
      "epoch": 1.7130144605116797,
      "grad_norm": 0.5870556235313416,
      "learning_rate": 2.8594271412680756e-05,
      "loss": 0.3185,
      "step": 3080
    },
    {
      "epoch": 1.7185761957730812,
      "grad_norm": 0.6898844242095947,
      "learning_rate": 2.852474972191324e-05,
      "loss": 0.3762,
      "step": 3090
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 0.5614362359046936,
      "learning_rate": 2.845522803114572e-05,
      "loss": 0.3774,
      "step": 3100
    },
    {
      "epoch": 1.7296996662958843,
      "grad_norm": 0.47699281573295593,
      "learning_rate": 2.83857063403782e-05,
      "loss": 0.3878,
      "step": 3110
    },
    {
      "epoch": 1.735261401557286,
      "grad_norm": 0.6860998868942261,
      "learning_rate": 2.8316184649610677e-05,
      "loss": 0.3354,
      "step": 3120
    },
    {
      "epoch": 1.7408231368186873,
      "grad_norm": 0.5167838335037231,
      "learning_rate": 2.824666295884316e-05,
      "loss": 0.2984,
      "step": 3130
    },
    {
      "epoch": 1.746384872080089,
      "grad_norm": 0.3473338484764099,
      "learning_rate": 2.8177141268075642e-05,
      "loss": 0.3516,
      "step": 3140
    },
    {
      "epoch": 1.7519466073414907,
      "grad_norm": 0.7091608047485352,
      "learning_rate": 2.810761957730812e-05,
      "loss": 0.4513,
      "step": 3150
    },
    {
      "epoch": 1.7575083426028921,
      "grad_norm": 0.5218719244003296,
      "learning_rate": 2.8038097886540604e-05,
      "loss": 0.2852,
      "step": 3160
    },
    {
      "epoch": 1.7630700778642936,
      "grad_norm": 0.7740529179573059,
      "learning_rate": 2.796857619577308e-05,
      "loss": 0.3502,
      "step": 3170
    },
    {
      "epoch": 1.7686318131256953,
      "grad_norm": 0.34125959873199463,
      "learning_rate": 2.7899054505005562e-05,
      "loss": 0.3585,
      "step": 3180
    },
    {
      "epoch": 1.7741935483870968,
      "grad_norm": 0.38549554347991943,
      "learning_rate": 2.7829532814238047e-05,
      "loss": 0.2974,
      "step": 3190
    },
    {
      "epoch": 1.7797552836484982,
      "grad_norm": 0.37255534529685974,
      "learning_rate": 2.7760011123470524e-05,
      "loss": 0.3731,
      "step": 3200
    },
    {
      "epoch": 1.7853170189099,
      "grad_norm": 0.47675544023513794,
      "learning_rate": 2.7690489432703005e-05,
      "loss": 0.289,
      "step": 3210
    },
    {
      "epoch": 1.7908787541713016,
      "grad_norm": 0.7112951278686523,
      "learning_rate": 2.7620967741935483e-05,
      "loss": 0.3208,
      "step": 3220
    },
    {
      "epoch": 1.7964404894327028,
      "grad_norm": 1.1930683851242065,
      "learning_rate": 2.7551446051167967e-05,
      "loss": 0.3504,
      "step": 3230
    },
    {
      "epoch": 1.8020022246941045,
      "grad_norm": 0.9438698887825012,
      "learning_rate": 2.7481924360400445e-05,
      "loss": 0.3711,
      "step": 3240
    },
    {
      "epoch": 1.8075639599555062,
      "grad_norm": 0.3544275462627411,
      "learning_rate": 2.7412402669632926e-05,
      "loss": 0.2646,
      "step": 3250
    },
    {
      "epoch": 1.8131256952169077,
      "grad_norm": 0.30399367213249207,
      "learning_rate": 2.734288097886541e-05,
      "loss": 0.2751,
      "step": 3260
    },
    {
      "epoch": 1.8186874304783092,
      "grad_norm": 0.8758026957511902,
      "learning_rate": 2.7273359288097888e-05,
      "loss": 0.3327,
      "step": 3270
    },
    {
      "epoch": 1.8242491657397109,
      "grad_norm": 0.4002193510532379,
      "learning_rate": 2.720383759733037e-05,
      "loss": 0.37,
      "step": 3280
    },
    {
      "epoch": 1.8298109010011123,
      "grad_norm": 0.6157843470573425,
      "learning_rate": 2.7134315906562853e-05,
      "loss": 0.3288,
      "step": 3290
    },
    {
      "epoch": 1.8353726362625138,
      "grad_norm": 0.5924289226531982,
      "learning_rate": 2.706479421579533e-05,
      "loss": 0.3195,
      "step": 3300
    },
    {
      "epoch": 1.8409343715239155,
      "grad_norm": 0.7921398282051086,
      "learning_rate": 2.6995272525027808e-05,
      "loss": 0.3276,
      "step": 3310
    },
    {
      "epoch": 1.8464961067853172,
      "grad_norm": 0.639105498790741,
      "learning_rate": 2.692575083426029e-05,
      "loss": 0.307,
      "step": 3320
    },
    {
      "epoch": 1.8520578420467184,
      "grad_norm": 0.6746053695678711,
      "learning_rate": 2.6856229143492773e-05,
      "loss": 0.4802,
      "step": 3330
    },
    {
      "epoch": 1.85761957730812,
      "grad_norm": 0.4960697889328003,
      "learning_rate": 2.678670745272525e-05,
      "loss": 0.3632,
      "step": 3340
    },
    {
      "epoch": 1.8631813125695218,
      "grad_norm": 0.8588107824325562,
      "learning_rate": 2.6717185761957732e-05,
      "loss": 0.3601,
      "step": 3350
    },
    {
      "epoch": 1.8687430478309233,
      "grad_norm": 0.9333287477493286,
      "learning_rate": 2.6647664071190216e-05,
      "loss": 0.2629,
      "step": 3360
    },
    {
      "epoch": 1.8743047830923247,
      "grad_norm": 0.4237709641456604,
      "learning_rate": 2.6578142380422694e-05,
      "loss": 0.3564,
      "step": 3370
    },
    {
      "epoch": 1.8798665183537264,
      "grad_norm": 0.671065628528595,
      "learning_rate": 2.650862068965517e-05,
      "loss": 0.3696,
      "step": 3380
    },
    {
      "epoch": 1.885428253615128,
      "grad_norm": 0.5028329491615295,
      "learning_rate": 2.6439098998887656e-05,
      "loss": 0.2869,
      "step": 3390
    },
    {
      "epoch": 1.8909899888765294,
      "grad_norm": 0.29001474380493164,
      "learning_rate": 2.6369577308120137e-05,
      "loss": 0.2817,
      "step": 3400
    },
    {
      "epoch": 1.896551724137931,
      "grad_norm": 0.4172781705856323,
      "learning_rate": 2.6300055617352614e-05,
      "loss": 0.3024,
      "step": 3410
    },
    {
      "epoch": 1.9021134593993327,
      "grad_norm": 0.9998671412467957,
      "learning_rate": 2.6230533926585095e-05,
      "loss": 0.4043,
      "step": 3420
    },
    {
      "epoch": 1.907675194660734,
      "grad_norm": 0.709958016872406,
      "learning_rate": 2.616101223581758e-05,
      "loss": 0.301,
      "step": 3430
    },
    {
      "epoch": 1.9132369299221357,
      "grad_norm": 0.4176965355873108,
      "learning_rate": 2.6091490545050057e-05,
      "loss": 0.3399,
      "step": 3440
    },
    {
      "epoch": 1.9187986651835374,
      "grad_norm": 0.6549745202064514,
      "learning_rate": 2.6021968854282535e-05,
      "loss": 0.2794,
      "step": 3450
    },
    {
      "epoch": 1.9243604004449388,
      "grad_norm": 0.7516363263130188,
      "learning_rate": 2.595244716351502e-05,
      "loss": 0.3745,
      "step": 3460
    },
    {
      "epoch": 1.9299221357063403,
      "grad_norm": 0.6071031093597412,
      "learning_rate": 2.58829254727475e-05,
      "loss": 0.4011,
      "step": 3470
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 0.2907317280769348,
      "learning_rate": 2.5813403781979977e-05,
      "loss": 0.4021,
      "step": 3480
    },
    {
      "epoch": 1.9410456062291435,
      "grad_norm": 0.583739161491394,
      "learning_rate": 2.574388209121246e-05,
      "loss": 0.2971,
      "step": 3490
    },
    {
      "epoch": 1.946607341490545,
      "grad_norm": 0.42933163046836853,
      "learning_rate": 2.5674360400444943e-05,
      "loss": 0.2566,
      "step": 3500
    },
    {
      "epoch": 1.9521690767519466,
      "grad_norm": 0.6476158499717712,
      "learning_rate": 2.560483870967742e-05,
      "loss": 0.3472,
      "step": 3510
    },
    {
      "epoch": 1.9577308120133483,
      "grad_norm": 0.4184496998786926,
      "learning_rate": 2.5535317018909898e-05,
      "loss": 0.2828,
      "step": 3520
    },
    {
      "epoch": 1.9632925472747496,
      "grad_norm": 0.3980056345462799,
      "learning_rate": 2.5465795328142382e-05,
      "loss": 0.3426,
      "step": 3530
    },
    {
      "epoch": 1.9688542825361512,
      "grad_norm": 0.21375124156475067,
      "learning_rate": 2.5396273637374863e-05,
      "loss": 0.3176,
      "step": 3540
    },
    {
      "epoch": 1.974416017797553,
      "grad_norm": 0.3574640154838562,
      "learning_rate": 2.532675194660734e-05,
      "loss": 0.3878,
      "step": 3550
    },
    {
      "epoch": 1.9799777530589544,
      "grad_norm": 0.5985122919082642,
      "learning_rate": 2.5257230255839825e-05,
      "loss": 0.3084,
      "step": 3560
    },
    {
      "epoch": 1.9855394883203559,
      "grad_norm": 0.48497113585472107,
      "learning_rate": 2.5187708565072306e-05,
      "loss": 0.3725,
      "step": 3570
    },
    {
      "epoch": 1.9911012235817576,
      "grad_norm": 0.9051966667175293,
      "learning_rate": 2.5118186874304784e-05,
      "loss": 0.358,
      "step": 3580
    },
    {
      "epoch": 1.996662958843159,
      "grad_norm": 0.8758151531219482,
      "learning_rate": 2.504866518353726e-05,
      "loss": 0.3333,
      "step": 3590
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.3001479506492615,
      "eval_runtime": 7.7046,
      "eval_samples_per_second": 207.539,
      "eval_steps_per_second": 25.959,
      "step": 3596
    },
    {
      "epoch": 2.0022246941045605,
      "grad_norm": 0.6426864862442017,
      "learning_rate": 2.4979143492769745e-05,
      "loss": 0.3466,
      "step": 3600
    },
    {
      "epoch": 2.007786429365962,
      "grad_norm": 0.8300288915634155,
      "learning_rate": 2.4909621802002226e-05,
      "loss": 0.3236,
      "step": 3610
    },
    {
      "epoch": 2.013348164627364,
      "grad_norm": 0.44273531436920166,
      "learning_rate": 2.4840100111234707e-05,
      "loss": 0.335,
      "step": 3620
    },
    {
      "epoch": 2.018909899888765,
      "grad_norm": 0.5229731202125549,
      "learning_rate": 2.4770578420467185e-05,
      "loss": 0.4186,
      "step": 3630
    },
    {
      "epoch": 2.024471635150167,
      "grad_norm": 0.6653401255607605,
      "learning_rate": 2.4701056729699666e-05,
      "loss": 0.3421,
      "step": 3640
    },
    {
      "epoch": 2.0300333704115685,
      "grad_norm": 0.5527741312980652,
      "learning_rate": 2.463153503893215e-05,
      "loss": 0.3905,
      "step": 3650
    },
    {
      "epoch": 2.0355951056729698,
      "grad_norm": 0.5683847665786743,
      "learning_rate": 2.4562013348164628e-05,
      "loss": 0.2568,
      "step": 3660
    },
    {
      "epoch": 2.0411568409343714,
      "grad_norm": 4.595888614654541,
      "learning_rate": 2.449249165739711e-05,
      "loss": 0.2765,
      "step": 3670
    },
    {
      "epoch": 2.046718576195773,
      "grad_norm": 0.2707754969596863,
      "learning_rate": 2.442296996662959e-05,
      "loss": 0.3487,
      "step": 3680
    },
    {
      "epoch": 2.052280311457175,
      "grad_norm": 0.4408576488494873,
      "learning_rate": 2.435344827586207e-05,
      "loss": 0.3351,
      "step": 3690
    },
    {
      "epoch": 2.057842046718576,
      "grad_norm": 0.398936003446579,
      "learning_rate": 2.428392658509455e-05,
      "loss": 0.2783,
      "step": 3700
    },
    {
      "epoch": 2.0634037819799778,
      "grad_norm": 0.819828450679779,
      "learning_rate": 2.421440489432703e-05,
      "loss": 0.355,
      "step": 3710
    },
    {
      "epoch": 2.0689655172413794,
      "grad_norm": 0.45636942982673645,
      "learning_rate": 2.4144883203559514e-05,
      "loss": 0.3121,
      "step": 3720
    },
    {
      "epoch": 2.0745272525027807,
      "grad_norm": 0.7449896931648254,
      "learning_rate": 2.407536151279199e-05,
      "loss": 0.3055,
      "step": 3730
    },
    {
      "epoch": 2.0800889877641824,
      "grad_norm": 0.9685530066490173,
      "learning_rate": 2.4005839822024472e-05,
      "loss": 0.3455,
      "step": 3740
    },
    {
      "epoch": 2.085650723025584,
      "grad_norm": 0.5758125185966492,
      "learning_rate": 2.3936318131256953e-05,
      "loss": 0.3158,
      "step": 3750
    },
    {
      "epoch": 2.0912124582869858,
      "grad_norm": 0.3191172778606415,
      "learning_rate": 2.3866796440489434e-05,
      "loss": 0.4647,
      "step": 3760
    },
    {
      "epoch": 2.096774193548387,
      "grad_norm": 0.32496920228004456,
      "learning_rate": 2.3797274749721915e-05,
      "loss": 0.2947,
      "step": 3770
    },
    {
      "epoch": 2.1023359288097887,
      "grad_norm": 0.39209622144699097,
      "learning_rate": 2.3727753058954393e-05,
      "loss": 0.3397,
      "step": 3780
    },
    {
      "epoch": 2.1078976640711904,
      "grad_norm": 0.27365535497665405,
      "learning_rate": 2.3658231368186877e-05,
      "loss": 0.3232,
      "step": 3790
    },
    {
      "epoch": 2.1134593993325916,
      "grad_norm": 0.5946815013885498,
      "learning_rate": 2.3588709677419358e-05,
      "loss": 0.2929,
      "step": 3800
    },
    {
      "epoch": 2.1190211345939933,
      "grad_norm": 0.6622063517570496,
      "learning_rate": 2.3519187986651835e-05,
      "loss": 0.3294,
      "step": 3810
    },
    {
      "epoch": 2.124582869855395,
      "grad_norm": 0.6683008670806885,
      "learning_rate": 2.3449666295884316e-05,
      "loss": 0.3157,
      "step": 3820
    },
    {
      "epoch": 2.1301446051167963,
      "grad_norm": 0.8008916974067688,
      "learning_rate": 2.3380144605116797e-05,
      "loss": 0.3229,
      "step": 3830
    },
    {
      "epoch": 2.135706340378198,
      "grad_norm": 0.7372466921806335,
      "learning_rate": 2.3310622914349278e-05,
      "loss": 0.3357,
      "step": 3840
    },
    {
      "epoch": 2.1412680756395996,
      "grad_norm": 0.2754894196987152,
      "learning_rate": 2.324110122358176e-05,
      "loss": 0.2588,
      "step": 3850
    },
    {
      "epoch": 2.146829810901001,
      "grad_norm": 0.5775771737098694,
      "learning_rate": 2.317157953281424e-05,
      "loss": 0.3164,
      "step": 3860
    },
    {
      "epoch": 2.1523915461624026,
      "grad_norm": 0.5953291654586792,
      "learning_rate": 2.310205784204672e-05,
      "loss": 0.3459,
      "step": 3870
    },
    {
      "epoch": 2.1579532814238043,
      "grad_norm": 0.5312125086784363,
      "learning_rate": 2.30325361512792e-05,
      "loss": 0.2395,
      "step": 3880
    },
    {
      "epoch": 2.163515016685206,
      "grad_norm": 0.46691593527793884,
      "learning_rate": 2.296301446051168e-05,
      "loss": 0.3171,
      "step": 3890
    },
    {
      "epoch": 2.169076751946607,
      "grad_norm": 0.4366777539253235,
      "learning_rate": 2.2893492769744164e-05,
      "loss": 0.2695,
      "step": 3900
    },
    {
      "epoch": 2.174638487208009,
      "grad_norm": 0.4623553156852722,
      "learning_rate": 2.282397107897664e-05,
      "loss": 0.3249,
      "step": 3910
    },
    {
      "epoch": 2.1802002224694106,
      "grad_norm": 0.3942757248878479,
      "learning_rate": 2.2754449388209122e-05,
      "loss": 0.2498,
      "step": 3920
    },
    {
      "epoch": 2.185761957730812,
      "grad_norm": 0.5110245943069458,
      "learning_rate": 2.2684927697441603e-05,
      "loss": 0.3135,
      "step": 3930
    },
    {
      "epoch": 2.1913236929922135,
      "grad_norm": 0.6148985028266907,
      "learning_rate": 2.2615406006674084e-05,
      "loss": 0.3501,
      "step": 3940
    },
    {
      "epoch": 2.196885428253615,
      "grad_norm": 1.1356173753738403,
      "learning_rate": 2.2545884315906565e-05,
      "loss": 0.3381,
      "step": 3950
    },
    {
      "epoch": 2.202447163515017,
      "grad_norm": 0.4834163784980774,
      "learning_rate": 2.2476362625139043e-05,
      "loss": 0.329,
      "step": 3960
    },
    {
      "epoch": 2.208008898776418,
      "grad_norm": 0.5093231201171875,
      "learning_rate": 2.2406840934371527e-05,
      "loss": 0.3576,
      "step": 3970
    },
    {
      "epoch": 2.21357063403782,
      "grad_norm": 0.49705952405929565,
      "learning_rate": 2.2337319243604005e-05,
      "loss": 0.304,
      "step": 3980
    },
    {
      "epoch": 2.2191323692992215,
      "grad_norm": 1.040899634361267,
      "learning_rate": 2.2267797552836486e-05,
      "loss": 0.3188,
      "step": 3990
    },
    {
      "epoch": 2.2246941045606228,
      "grad_norm": 0.7397428154945374,
      "learning_rate": 2.2198275862068967e-05,
      "loss": 0.319,
      "step": 4000
    },
    {
      "epoch": 2.2302558398220245,
      "grad_norm": 0.4724307656288147,
      "learning_rate": 2.2128754171301448e-05,
      "loss": 0.3371,
      "step": 4010
    },
    {
      "epoch": 2.235817575083426,
      "grad_norm": 0.3367435932159424,
      "learning_rate": 2.205923248053393e-05,
      "loss": 0.2699,
      "step": 4020
    },
    {
      "epoch": 2.2413793103448274,
      "grad_norm": 0.7490898966789246,
      "learning_rate": 2.1989710789766406e-05,
      "loss": 0.3307,
      "step": 4030
    },
    {
      "epoch": 2.246941045606229,
      "grad_norm": 1.0069215297698975,
      "learning_rate": 2.192018909899889e-05,
      "loss": 0.4295,
      "step": 4040
    },
    {
      "epoch": 2.252502780867631,
      "grad_norm": 0.5538630485534668,
      "learning_rate": 2.185066740823137e-05,
      "loss": 0.3513,
      "step": 4050
    },
    {
      "epoch": 2.258064516129032,
      "grad_norm": 0.4177139401435852,
      "learning_rate": 2.178114571746385e-05,
      "loss": 0.3267,
      "step": 4060
    },
    {
      "epoch": 2.2636262513904337,
      "grad_norm": 0.8460400104522705,
      "learning_rate": 2.171162402669633e-05,
      "loss": 0.285,
      "step": 4070
    },
    {
      "epoch": 2.2691879866518354,
      "grad_norm": 0.8787168860435486,
      "learning_rate": 2.164210233592881e-05,
      "loss": 0.3031,
      "step": 4080
    },
    {
      "epoch": 2.274749721913237,
      "grad_norm": 0.32680168747901917,
      "learning_rate": 2.1572580645161292e-05,
      "loss": 0.2645,
      "step": 4090
    },
    {
      "epoch": 2.2803114571746383,
      "grad_norm": 0.41234710812568665,
      "learning_rate": 2.1503058954393773e-05,
      "loss": 0.2362,
      "step": 4100
    },
    {
      "epoch": 2.28587319243604,
      "grad_norm": 0.6681631803512573,
      "learning_rate": 2.143353726362625e-05,
      "loss": 0.2595,
      "step": 4110
    },
    {
      "epoch": 2.2914349276974417,
      "grad_norm": 0.35648176074028015,
      "learning_rate": 2.1364015572858735e-05,
      "loss": 0.301,
      "step": 4120
    },
    {
      "epoch": 2.296996662958843,
      "grad_norm": 0.5534762740135193,
      "learning_rate": 2.1294493882091212e-05,
      "loss": 0.3237,
      "step": 4130
    },
    {
      "epoch": 2.3025583982202447,
      "grad_norm": 0.5062904357910156,
      "learning_rate": 2.1224972191323693e-05,
      "loss": 0.2716,
      "step": 4140
    },
    {
      "epoch": 2.3081201334816464,
      "grad_norm": 1.1572777032852173,
      "learning_rate": 2.1155450500556174e-05,
      "loss": 0.2812,
      "step": 4150
    },
    {
      "epoch": 2.313681868743048,
      "grad_norm": 1.0198198556900024,
      "learning_rate": 2.1085928809788655e-05,
      "loss": 0.3804,
      "step": 4160
    },
    {
      "epoch": 2.3192436040044493,
      "grad_norm": 0.5522705316543579,
      "learning_rate": 2.1016407119021136e-05,
      "loss": 0.2509,
      "step": 4170
    },
    {
      "epoch": 2.324805339265851,
      "grad_norm": 0.7297583222389221,
      "learning_rate": 2.0946885428253614e-05,
      "loss": 0.3804,
      "step": 4180
    },
    {
      "epoch": 2.3303670745272527,
      "grad_norm": 0.8392539024353027,
      "learning_rate": 2.0877363737486098e-05,
      "loss": 0.3092,
      "step": 4190
    },
    {
      "epoch": 2.335928809788654,
      "grad_norm": 0.5082746744155884,
      "learning_rate": 2.0807842046718576e-05,
      "loss": 0.2838,
      "step": 4200
    },
    {
      "epoch": 2.3414905450500556,
      "grad_norm": 0.48488834500312805,
      "learning_rate": 2.0738320355951057e-05,
      "loss": 0.3087,
      "step": 4210
    },
    {
      "epoch": 2.3470522803114573,
      "grad_norm": 0.4901962876319885,
      "learning_rate": 2.0668798665183538e-05,
      "loss": 0.2552,
      "step": 4220
    },
    {
      "epoch": 2.3526140155728585,
      "grad_norm": 0.7023879289627075,
      "learning_rate": 2.059927697441602e-05,
      "loss": 0.3027,
      "step": 4230
    },
    {
      "epoch": 2.3581757508342602,
      "grad_norm": 0.604929506778717,
      "learning_rate": 2.05297552836485e-05,
      "loss": 0.2588,
      "step": 4240
    },
    {
      "epoch": 2.363737486095662,
      "grad_norm": 0.4917423725128174,
      "learning_rate": 2.0460233592880977e-05,
      "loss": 0.2601,
      "step": 4250
    },
    {
      "epoch": 2.369299221357063,
      "grad_norm": 0.6946473717689514,
      "learning_rate": 2.039071190211346e-05,
      "loss": 0.4018,
      "step": 4260
    },
    {
      "epoch": 2.374860956618465,
      "grad_norm": 0.4116312563419342,
      "learning_rate": 2.0321190211345942e-05,
      "loss": 0.3011,
      "step": 4270
    },
    {
      "epoch": 2.3804226918798665,
      "grad_norm": 0.47112172842025757,
      "learning_rate": 2.025166852057842e-05,
      "loss": 0.2501,
      "step": 4280
    },
    {
      "epoch": 2.3859844271412682,
      "grad_norm": 0.5727344751358032,
      "learning_rate": 2.01821468298109e-05,
      "loss": 0.3169,
      "step": 4290
    },
    {
      "epoch": 2.3915461624026695,
      "grad_norm": 0.7693657279014587,
      "learning_rate": 2.0112625139043382e-05,
      "loss": 0.3488,
      "step": 4300
    },
    {
      "epoch": 2.397107897664071,
      "grad_norm": 0.38695111870765686,
      "learning_rate": 2.0043103448275863e-05,
      "loss": 0.3094,
      "step": 4310
    },
    {
      "epoch": 2.402669632925473,
      "grad_norm": 0.7286058068275452,
      "learning_rate": 1.9973581757508344e-05,
      "loss": 0.2833,
      "step": 4320
    },
    {
      "epoch": 2.408231368186874,
      "grad_norm": 0.6556054353713989,
      "learning_rate": 1.9904060066740825e-05,
      "loss": 0.3007,
      "step": 4330
    },
    {
      "epoch": 2.413793103448276,
      "grad_norm": 0.642466127872467,
      "learning_rate": 1.9834538375973306e-05,
      "loss": 0.4387,
      "step": 4340
    },
    {
      "epoch": 2.4193548387096775,
      "grad_norm": 0.7383702993392944,
      "learning_rate": 1.9765016685205783e-05,
      "loss": 0.196,
      "step": 4350
    },
    {
      "epoch": 2.424916573971079,
      "grad_norm": 0.733686625957489,
      "learning_rate": 1.9695494994438264e-05,
      "loss": 0.3848,
      "step": 4360
    },
    {
      "epoch": 2.4304783092324804,
      "grad_norm": 0.6555696725845337,
      "learning_rate": 1.962597330367075e-05,
      "loss": 0.3931,
      "step": 4370
    },
    {
      "epoch": 2.436040044493882,
      "grad_norm": 0.6620770692825317,
      "learning_rate": 1.9556451612903226e-05,
      "loss": 0.3428,
      "step": 4380
    },
    {
      "epoch": 2.441601779755284,
      "grad_norm": 0.47766125202178955,
      "learning_rate": 1.9486929922135707e-05,
      "loss": 0.3061,
      "step": 4390
    },
    {
      "epoch": 2.447163515016685,
      "grad_norm": 0.681170642375946,
      "learning_rate": 1.9417408231368188e-05,
      "loss": 0.3255,
      "step": 4400
    },
    {
      "epoch": 2.4527252502780867,
      "grad_norm": 0.49299904704093933,
      "learning_rate": 1.934788654060067e-05,
      "loss": 0.3001,
      "step": 4410
    },
    {
      "epoch": 2.4582869855394884,
      "grad_norm": 0.4519398808479309,
      "learning_rate": 1.927836484983315e-05,
      "loss": 0.3683,
      "step": 4420
    },
    {
      "epoch": 2.4638487208008897,
      "grad_norm": 0.4086664021015167,
      "learning_rate": 1.9208843159065627e-05,
      "loss": 0.3104,
      "step": 4430
    },
    {
      "epoch": 2.4694104560622914,
      "grad_norm": 0.4901845157146454,
      "learning_rate": 1.9139321468298112e-05,
      "loss": 0.3287,
      "step": 4440
    },
    {
      "epoch": 2.474972191323693,
      "grad_norm": 0.3062547743320465,
      "learning_rate": 1.906979977753059e-05,
      "loss": 0.2525,
      "step": 4450
    },
    {
      "epoch": 2.4805339265850943,
      "grad_norm": 0.5988015532493591,
      "learning_rate": 1.900027808676307e-05,
      "loss": 0.3609,
      "step": 4460
    },
    {
      "epoch": 2.486095661846496,
      "grad_norm": 0.5314655303955078,
      "learning_rate": 1.893075639599555e-05,
      "loss": 0.3308,
      "step": 4470
    },
    {
      "epoch": 2.4916573971078977,
      "grad_norm": 0.7419012784957886,
      "learning_rate": 1.8861234705228032e-05,
      "loss": 0.4244,
      "step": 4480
    },
    {
      "epoch": 2.4972191323692994,
      "grad_norm": 0.43781721591949463,
      "learning_rate": 1.8791713014460513e-05,
      "loss": 0.2481,
      "step": 4490
    },
    {
      "epoch": 2.5027808676307006,
      "grad_norm": 0.38503777980804443,
      "learning_rate": 1.872219132369299e-05,
      "loss": 0.3681,
      "step": 4500
    },
    {
      "epoch": 2.5083426028921023,
      "grad_norm": 0.3987833857536316,
      "learning_rate": 1.8652669632925475e-05,
      "loss": 0.3501,
      "step": 4510
    },
    {
      "epoch": 2.513904338153504,
      "grad_norm": 0.6406720280647278,
      "learning_rate": 1.8583147942157956e-05,
      "loss": 0.3171,
      "step": 4520
    },
    {
      "epoch": 2.5194660734149057,
      "grad_norm": 0.9439599514007568,
      "learning_rate": 1.8513626251390434e-05,
      "loss": 0.3433,
      "step": 4530
    },
    {
      "epoch": 2.525027808676307,
      "grad_norm": 0.6006582975387573,
      "learning_rate": 1.8444104560622915e-05,
      "loss": 0.3054,
      "step": 4540
    },
    {
      "epoch": 2.5305895439377086,
      "grad_norm": 0.8181480765342712,
      "learning_rate": 1.8374582869855396e-05,
      "loss": 0.2868,
      "step": 4550
    },
    {
      "epoch": 2.5361512791991103,
      "grad_norm": 0.7991973161697388,
      "learning_rate": 1.8305061179087876e-05,
      "loss": 0.3216,
      "step": 4560
    },
    {
      "epoch": 2.5417130144605116,
      "grad_norm": 0.5830488801002502,
      "learning_rate": 1.8235539488320357e-05,
      "loss": 0.3234,
      "step": 4570
    },
    {
      "epoch": 2.5472747497219133,
      "grad_norm": 0.39266663789749146,
      "learning_rate": 1.816601779755284e-05,
      "loss": 0.3118,
      "step": 4580
    },
    {
      "epoch": 2.552836484983315,
      "grad_norm": 0.4133169651031494,
      "learning_rate": 1.809649610678532e-05,
      "loss": 0.3097,
      "step": 4590
    },
    {
      "epoch": 2.558398220244716,
      "grad_norm": 0.4285762310028076,
      "learning_rate": 1.8026974416017797e-05,
      "loss": 0.3196,
      "step": 4600
    },
    {
      "epoch": 2.563959955506118,
      "grad_norm": 0.46405598521232605,
      "learning_rate": 1.7957452725250278e-05,
      "loss": 0.2903,
      "step": 4610
    },
    {
      "epoch": 2.5695216907675196,
      "grad_norm": 0.5253127813339233,
      "learning_rate": 1.7887931034482762e-05,
      "loss": 0.2794,
      "step": 4620
    },
    {
      "epoch": 2.575083426028921,
      "grad_norm": 0.4552799165248871,
      "learning_rate": 1.781840934371524e-05,
      "loss": 0.2781,
      "step": 4630
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 0.7348924279212952,
      "learning_rate": 1.774888765294772e-05,
      "loss": 0.2618,
      "step": 4640
    },
    {
      "epoch": 2.586206896551724,
      "grad_norm": 0.42786672711372375,
      "learning_rate": 1.7679365962180198e-05,
      "loss": 0.2165,
      "step": 4650
    },
    {
      "epoch": 2.5917686318131254,
      "grad_norm": 0.4507499933242798,
      "learning_rate": 1.7609844271412683e-05,
      "loss": 0.3167,
      "step": 4660
    },
    {
      "epoch": 2.597330367074527,
      "grad_norm": 0.48672419786453247,
      "learning_rate": 1.7540322580645164e-05,
      "loss": 0.3496,
      "step": 4670
    },
    {
      "epoch": 2.602892102335929,
      "grad_norm": 0.7627747654914856,
      "learning_rate": 1.747080088987764e-05,
      "loss": 0.3829,
      "step": 4680
    },
    {
      "epoch": 2.6084538375973305,
      "grad_norm": 0.4812559485435486,
      "learning_rate": 1.7401279199110122e-05,
      "loss": 0.3125,
      "step": 4690
    },
    {
      "epoch": 2.6140155728587318,
      "grad_norm": 0.4079558849334717,
      "learning_rate": 1.7331757508342603e-05,
      "loss": 0.213,
      "step": 4700
    },
    {
      "epoch": 2.6195773081201335,
      "grad_norm": 0.5509042739868164,
      "learning_rate": 1.7262235817575084e-05,
      "loss": 0.4108,
      "step": 4710
    },
    {
      "epoch": 2.625139043381535,
      "grad_norm": 0.5636488795280457,
      "learning_rate": 1.7192714126807565e-05,
      "loss": 0.313,
      "step": 4720
    },
    {
      "epoch": 2.630700778642937,
      "grad_norm": 0.38230064511299133,
      "learning_rate": 1.7123192436040046e-05,
      "loss": 0.3092,
      "step": 4730
    },
    {
      "epoch": 2.636262513904338,
      "grad_norm": 0.4457800090312958,
      "learning_rate": 1.7053670745272527e-05,
      "loss": 0.2883,
      "step": 4740
    },
    {
      "epoch": 2.6418242491657398,
      "grad_norm": 0.5453163385391235,
      "learning_rate": 1.6984149054505004e-05,
      "loss": 0.2545,
      "step": 4750
    },
    {
      "epoch": 2.6473859844271415,
      "grad_norm": 1.0752631425857544,
      "learning_rate": 1.6914627363737485e-05,
      "loss": 0.4225,
      "step": 4760
    },
    {
      "epoch": 2.6529477196885427,
      "grad_norm": 0.7439974546432495,
      "learning_rate": 1.684510567296997e-05,
      "loss": 0.3534,
      "step": 4770
    },
    {
      "epoch": 2.6585094549499444,
      "grad_norm": 0.5080178380012512,
      "learning_rate": 1.6775583982202447e-05,
      "loss": 0.2963,
      "step": 4780
    },
    {
      "epoch": 2.664071190211346,
      "grad_norm": 0.8079877495765686,
      "learning_rate": 1.6706062291434928e-05,
      "loss": 0.3938,
      "step": 4790
    },
    {
      "epoch": 2.6696329254727473,
      "grad_norm": 0.3798200786113739,
      "learning_rate": 1.663654060066741e-05,
      "loss": 0.2996,
      "step": 4800
    },
    {
      "epoch": 2.675194660734149,
      "grad_norm": 0.32307276129722595,
      "learning_rate": 1.656701890989989e-05,
      "loss": 0.255,
      "step": 4810
    },
    {
      "epoch": 2.6807563959955507,
      "grad_norm": 0.5192011594772339,
      "learning_rate": 1.649749721913237e-05,
      "loss": 0.3544,
      "step": 4820
    },
    {
      "epoch": 2.686318131256952,
      "grad_norm": 0.5388277769088745,
      "learning_rate": 1.642797552836485e-05,
      "loss": 0.319,
      "step": 4830
    },
    {
      "epoch": 2.6918798665183536,
      "grad_norm": 0.5057376623153687,
      "learning_rate": 1.6358453837597333e-05,
      "loss": 0.3444,
      "step": 4840
    },
    {
      "epoch": 2.6974416017797553,
      "grad_norm": 0.4994593858718872,
      "learning_rate": 1.628893214682981e-05,
      "loss": 0.3098,
      "step": 4850
    },
    {
      "epoch": 2.7030033370411566,
      "grad_norm": 0.5659316182136536,
      "learning_rate": 1.621941045606229e-05,
      "loss": 0.2783,
      "step": 4860
    },
    {
      "epoch": 2.7085650723025583,
      "grad_norm": 0.3576295077800751,
      "learning_rate": 1.6149888765294773e-05,
      "loss": 0.2943,
      "step": 4870
    },
    {
      "epoch": 2.71412680756396,
      "grad_norm": 0.6955867409706116,
      "learning_rate": 1.6080367074527253e-05,
      "loss": 0.2767,
      "step": 4880
    },
    {
      "epoch": 2.7196885428253617,
      "grad_norm": 0.5381481051445007,
      "learning_rate": 1.6010845383759734e-05,
      "loss": 0.3315,
      "step": 4890
    },
    {
      "epoch": 2.7252502780867633,
      "grad_norm": 0.5386108160018921,
      "learning_rate": 1.5941323692992212e-05,
      "loss": 0.2973,
      "step": 4900
    },
    {
      "epoch": 2.7308120133481646,
      "grad_norm": 0.4361756443977356,
      "learning_rate": 1.5871802002224696e-05,
      "loss": 0.2871,
      "step": 4910
    },
    {
      "epoch": 2.7363737486095663,
      "grad_norm": 0.42937156558036804,
      "learning_rate": 1.5802280311457177e-05,
      "loss": 0.3275,
      "step": 4920
    },
    {
      "epoch": 2.741935483870968,
      "grad_norm": 0.7587068676948547,
      "learning_rate": 1.5732758620689655e-05,
      "loss": 0.3,
      "step": 4930
    },
    {
      "epoch": 2.747497219132369,
      "grad_norm": 0.5007337331771851,
      "learning_rate": 1.5663236929922136e-05,
      "loss": 0.3456,
      "step": 4940
    },
    {
      "epoch": 2.753058954393771,
      "grad_norm": 0.4670027196407318,
      "learning_rate": 1.5593715239154617e-05,
      "loss": 0.2557,
      "step": 4950
    },
    {
      "epoch": 2.7586206896551726,
      "grad_norm": 0.5451241135597229,
      "learning_rate": 1.5524193548387098e-05,
      "loss": 0.2737,
      "step": 4960
    },
    {
      "epoch": 2.764182424916574,
      "grad_norm": 0.9430128335952759,
      "learning_rate": 1.545467185761958e-05,
      "loss": 0.3496,
      "step": 4970
    },
    {
      "epoch": 2.7697441601779755,
      "grad_norm": 0.5277742743492126,
      "learning_rate": 1.538515016685206e-05,
      "loss": 0.3158,
      "step": 4980
    },
    {
      "epoch": 2.7753058954393772,
      "grad_norm": 0.4285942316055298,
      "learning_rate": 1.531562847608454e-05,
      "loss": 0.3233,
      "step": 4990
    },
    {
      "epoch": 2.7808676307007785,
      "grad_norm": 0.5915485620498657,
      "learning_rate": 1.5246106785317018e-05,
      "loss": 0.2442,
      "step": 5000
    },
    {
      "epoch": 2.78642936596218,
      "grad_norm": 0.7582971453666687,
      "learning_rate": 1.51765850945495e-05,
      "loss": 0.3282,
      "step": 5010
    },
    {
      "epoch": 2.791991101223582,
      "grad_norm": 0.3541043996810913,
      "learning_rate": 1.5107063403781982e-05,
      "loss": 0.3008,
      "step": 5020
    },
    {
      "epoch": 2.797552836484983,
      "grad_norm": 0.3325120508670807,
      "learning_rate": 1.5037541713014461e-05,
      "loss": 0.3305,
      "step": 5030
    },
    {
      "epoch": 2.803114571746385,
      "grad_norm": 0.5110053420066833,
      "learning_rate": 1.4968020022246942e-05,
      "loss": 0.3053,
      "step": 5040
    },
    {
      "epoch": 2.8086763070077865,
      "grad_norm": 0.5007989406585693,
      "learning_rate": 1.4898498331479421e-05,
      "loss": 0.368,
      "step": 5050
    },
    {
      "epoch": 2.8142380422691877,
      "grad_norm": 0.7395428419113159,
      "learning_rate": 1.4828976640711902e-05,
      "loss": 0.2786,
      "step": 5060
    },
    {
      "epoch": 2.8197997775305894,
      "grad_norm": 0.4006054103374481,
      "learning_rate": 1.4759454949944385e-05,
      "loss": 0.3173,
      "step": 5070
    },
    {
      "epoch": 2.825361512791991,
      "grad_norm": 0.32947975397109985,
      "learning_rate": 1.4689933259176864e-05,
      "loss": 0.2163,
      "step": 5080
    },
    {
      "epoch": 2.830923248053393,
      "grad_norm": 0.7458900213241577,
      "learning_rate": 1.4620411568409345e-05,
      "loss": 0.2965,
      "step": 5090
    },
    {
      "epoch": 2.8364849833147945,
      "grad_norm": 0.5588935613632202,
      "learning_rate": 1.4550889877641824e-05,
      "loss": 0.2889,
      "step": 5100
    },
    {
      "epoch": 2.8420467185761957,
      "grad_norm": 0.6498419642448425,
      "learning_rate": 1.4481368186874305e-05,
      "loss": 0.2678,
      "step": 5110
    },
    {
      "epoch": 2.8476084538375974,
      "grad_norm": 0.6433287262916565,
      "learning_rate": 1.4411846496106788e-05,
      "loss": 0.3002,
      "step": 5120
    },
    {
      "epoch": 2.853170189098999,
      "grad_norm": 0.622009813785553,
      "learning_rate": 1.4342324805339265e-05,
      "loss": 0.3315,
      "step": 5130
    },
    {
      "epoch": 2.8587319243604004,
      "grad_norm": 0.36424681544303894,
      "learning_rate": 1.4272803114571748e-05,
      "loss": 0.3322,
      "step": 5140
    },
    {
      "epoch": 2.864293659621802,
      "grad_norm": 0.9427787065505981,
      "learning_rate": 1.4203281423804227e-05,
      "loss": 0.3322,
      "step": 5150
    },
    {
      "epoch": 2.8698553948832037,
      "grad_norm": 0.7471688985824585,
      "learning_rate": 1.4133759733036708e-05,
      "loss": 0.2806,
      "step": 5160
    },
    {
      "epoch": 2.875417130144605,
      "grad_norm": 0.5172590613365173,
      "learning_rate": 1.406423804226919e-05,
      "loss": 0.2507,
      "step": 5170
    },
    {
      "epoch": 2.8809788654060067,
      "grad_norm": 0.4014153778553009,
      "learning_rate": 1.3994716351501669e-05,
      "loss": 0.344,
      "step": 5180
    },
    {
      "epoch": 2.8865406006674084,
      "grad_norm": 0.5484068393707275,
      "learning_rate": 1.3925194660734151e-05,
      "loss": 0.2897,
      "step": 5190
    },
    {
      "epoch": 2.8921023359288096,
      "grad_norm": 0.43883568048477173,
      "learning_rate": 1.3855672969966629e-05,
      "loss": 0.2581,
      "step": 5200
    },
    {
      "epoch": 2.8976640711902113,
      "grad_norm": 0.575921893119812,
      "learning_rate": 1.3786151279199111e-05,
      "loss": 0.3466,
      "step": 5210
    },
    {
      "epoch": 2.903225806451613,
      "grad_norm": 0.47785741090774536,
      "learning_rate": 1.3716629588431592e-05,
      "loss": 0.3079,
      "step": 5220
    },
    {
      "epoch": 2.9087875417130142,
      "grad_norm": 0.5589526295661926,
      "learning_rate": 1.3647107897664072e-05,
      "loss": 0.2508,
      "step": 5230
    },
    {
      "epoch": 2.914349276974416,
      "grad_norm": 0.7613093852996826,
      "learning_rate": 1.3577586206896553e-05,
      "loss": 0.3148,
      "step": 5240
    },
    {
      "epoch": 2.9199110122358176,
      "grad_norm": 0.3453430235385895,
      "learning_rate": 1.3508064516129032e-05,
      "loss": 0.3027,
      "step": 5250
    },
    {
      "epoch": 2.925472747497219,
      "grad_norm": 0.41357845067977905,
      "learning_rate": 1.3438542825361514e-05,
      "loss": 0.2726,
      "step": 5260
    },
    {
      "epoch": 2.9310344827586206,
      "grad_norm": 0.5695844292640686,
      "learning_rate": 1.3369021134593995e-05,
      "loss": 0.3049,
      "step": 5270
    },
    {
      "epoch": 2.9365962180200222,
      "grad_norm": 0.5574050545692444,
      "learning_rate": 1.3299499443826475e-05,
      "loss": 0.2314,
      "step": 5280
    },
    {
      "epoch": 2.942157953281424,
      "grad_norm": 0.6020756363868713,
      "learning_rate": 1.3229977753058956e-05,
      "loss": 0.269,
      "step": 5290
    },
    {
      "epoch": 2.9477196885428256,
      "grad_norm": 0.6230267286300659,
      "learning_rate": 1.3160456062291435e-05,
      "loss": 0.2801,
      "step": 5300
    },
    {
      "epoch": 2.953281423804227,
      "grad_norm": 0.29607293009757996,
      "learning_rate": 1.3090934371523916e-05,
      "loss": 0.2924,
      "step": 5310
    },
    {
      "epoch": 2.9588431590656286,
      "grad_norm": 0.4022091329097748,
      "learning_rate": 1.3021412680756399e-05,
      "loss": 0.2282,
      "step": 5320
    },
    {
      "epoch": 2.9644048943270302,
      "grad_norm": 0.49661844968795776,
      "learning_rate": 1.2951890989988876e-05,
      "loss": 0.2623,
      "step": 5330
    },
    {
      "epoch": 2.9699666295884315,
      "grad_norm": 0.5372877717018127,
      "learning_rate": 1.2882369299221359e-05,
      "loss": 0.3504,
      "step": 5340
    },
    {
      "epoch": 2.975528364849833,
      "grad_norm": 0.5277346968650818,
      "learning_rate": 1.2812847608453838e-05,
      "loss": 0.2416,
      "step": 5350
    },
    {
      "epoch": 2.981090100111235,
      "grad_norm": 0.3468489646911621,
      "learning_rate": 1.2743325917686319e-05,
      "loss": 0.2346,
      "step": 5360
    },
    {
      "epoch": 2.986651835372636,
      "grad_norm": 0.44782841205596924,
      "learning_rate": 1.26738042269188e-05,
      "loss": 0.2937,
      "step": 5370
    },
    {
      "epoch": 2.992213570634038,
      "grad_norm": 0.883388340473175,
      "learning_rate": 1.260428253615128e-05,
      "loss": 0.3005,
      "step": 5380
    },
    {
      "epoch": 2.9977753058954395,
      "grad_norm": 0.36719411611557007,
      "learning_rate": 1.2534760845383762e-05,
      "loss": 0.2957,
      "step": 5390
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.28269705176353455,
      "eval_runtime": 7.7613,
      "eval_samples_per_second": 206.021,
      "eval_steps_per_second": 25.769,
      "step": 5394
    },
    {
      "epoch": 3.0033370411568407,
      "grad_norm": 0.41609883308410645,
      "learning_rate": 1.2465239154616241e-05,
      "loss": 0.2924,
      "step": 5400
    },
    {
      "epoch": 3.0088987764182424,
      "grad_norm": 0.4789288640022278,
      "learning_rate": 1.2395717463848722e-05,
      "loss": 0.265,
      "step": 5410
    },
    {
      "epoch": 3.014460511679644,
      "grad_norm": 0.3724687993526459,
      "learning_rate": 1.2326195773081201e-05,
      "loss": 0.2639,
      "step": 5420
    },
    {
      "epoch": 3.020022246941046,
      "grad_norm": 0.47796332836151123,
      "learning_rate": 1.2256674082313682e-05,
      "loss": 0.2862,
      "step": 5430
    },
    {
      "epoch": 3.025583982202447,
      "grad_norm": 0.4169856607913971,
      "learning_rate": 1.2187152391546163e-05,
      "loss": 0.2542,
      "step": 5440
    },
    {
      "epoch": 3.0311457174638488,
      "grad_norm": 0.5695911645889282,
      "learning_rate": 1.2117630700778644e-05,
      "loss": 0.2462,
      "step": 5450
    },
    {
      "epoch": 3.0367074527252504,
      "grad_norm": 0.38532182574272156,
      "learning_rate": 1.2048109010011125e-05,
      "loss": 0.2613,
      "step": 5460
    },
    {
      "epoch": 3.0422691879866517,
      "grad_norm": 0.5966489315032959,
      "learning_rate": 1.1978587319243604e-05,
      "loss": 0.3785,
      "step": 5470
    },
    {
      "epoch": 3.0478309232480534,
      "grad_norm": 0.6894206404685974,
      "learning_rate": 1.1909065628476085e-05,
      "loss": 0.3511,
      "step": 5480
    },
    {
      "epoch": 3.053392658509455,
      "grad_norm": 0.5573084354400635,
      "learning_rate": 1.1839543937708565e-05,
      "loss": 0.3584,
      "step": 5490
    },
    {
      "epoch": 3.0589543937708563,
      "grad_norm": 0.5645208954811096,
      "learning_rate": 1.1770022246941047e-05,
      "loss": 0.3394,
      "step": 5500
    },
    {
      "epoch": 3.064516129032258,
      "grad_norm": 0.6033862233161926,
      "learning_rate": 1.1700500556173526e-05,
      "loss": 0.2701,
      "step": 5510
    },
    {
      "epoch": 3.0700778642936597,
      "grad_norm": 0.3953275978565216,
      "learning_rate": 1.1630978865406007e-05,
      "loss": 0.2349,
      "step": 5520
    },
    {
      "epoch": 3.0756395995550614,
      "grad_norm": 0.7296066284179688,
      "learning_rate": 1.1561457174638487e-05,
      "loss": 0.3538,
      "step": 5530
    },
    {
      "epoch": 3.0812013348164626,
      "grad_norm": 0.4475948214530945,
      "learning_rate": 1.1491935483870968e-05,
      "loss": 0.2961,
      "step": 5540
    },
    {
      "epoch": 3.0867630700778643,
      "grad_norm": 0.46843692660331726,
      "learning_rate": 1.1422413793103449e-05,
      "loss": 0.2653,
      "step": 5550
    },
    {
      "epoch": 3.092324805339266,
      "grad_norm": 0.23708930611610413,
      "learning_rate": 1.135289210233593e-05,
      "loss": 0.2231,
      "step": 5560
    },
    {
      "epoch": 3.0978865406006673,
      "grad_norm": 0.5850154161453247,
      "learning_rate": 1.128337041156841e-05,
      "loss": 0.2819,
      "step": 5570
    },
    {
      "epoch": 3.103448275862069,
      "grad_norm": 0.530879557132721,
      "learning_rate": 1.121384872080089e-05,
      "loss": 0.2848,
      "step": 5580
    },
    {
      "epoch": 3.1090100111234706,
      "grad_norm": 0.6169335842132568,
      "learning_rate": 1.114432703003337e-05,
      "loss": 0.2912,
      "step": 5590
    },
    {
      "epoch": 3.114571746384872,
      "grad_norm": 0.3902513086795807,
      "learning_rate": 1.1074805339265852e-05,
      "loss": 0.2433,
      "step": 5600
    },
    {
      "epoch": 3.1201334816462736,
      "grad_norm": 0.3509436249732971,
      "learning_rate": 1.1005283648498333e-05,
      "loss": 0.2342,
      "step": 5610
    },
    {
      "epoch": 3.1256952169076753,
      "grad_norm": 0.8094770312309265,
      "learning_rate": 1.0935761957730812e-05,
      "loss": 0.3111,
      "step": 5620
    },
    {
      "epoch": 3.131256952169077,
      "grad_norm": 0.5594826340675354,
      "learning_rate": 1.0866240266963293e-05,
      "loss": 0.32,
      "step": 5630
    },
    {
      "epoch": 3.136818687430478,
      "grad_norm": 0.9164758920669556,
      "learning_rate": 1.0796718576195774e-05,
      "loss": 0.3584,
      "step": 5640
    },
    {
      "epoch": 3.14238042269188,
      "grad_norm": 0.3886602520942688,
      "learning_rate": 1.0727196885428255e-05,
      "loss": 0.2448,
      "step": 5650
    },
    {
      "epoch": 3.1479421579532816,
      "grad_norm": 0.5273708701133728,
      "learning_rate": 1.0657675194660736e-05,
      "loss": 0.268,
      "step": 5660
    },
    {
      "epoch": 3.153503893214683,
      "grad_norm": 0.29501134157180786,
      "learning_rate": 1.0588153503893215e-05,
      "loss": 0.223,
      "step": 5670
    },
    {
      "epoch": 3.1590656284760845,
      "grad_norm": 0.41211819648742676,
      "learning_rate": 1.0518631813125696e-05,
      "loss": 0.3346,
      "step": 5680
    },
    {
      "epoch": 3.164627363737486,
      "grad_norm": 0.39696016907691956,
      "learning_rate": 1.0449110122358175e-05,
      "loss": 0.3229,
      "step": 5690
    },
    {
      "epoch": 3.1701890989988875,
      "grad_norm": 1.0366350412368774,
      "learning_rate": 1.0379588431590658e-05,
      "loss": 0.31,
      "step": 5700
    },
    {
      "epoch": 3.175750834260289,
      "grad_norm": 0.7105482220649719,
      "learning_rate": 1.0310066740823137e-05,
      "loss": 0.3156,
      "step": 5710
    },
    {
      "epoch": 3.181312569521691,
      "grad_norm": 0.4078960716724396,
      "learning_rate": 1.0240545050055618e-05,
      "loss": 0.2585,
      "step": 5720
    },
    {
      "epoch": 3.1868743047830925,
      "grad_norm": 0.5191875100135803,
      "learning_rate": 1.0171023359288099e-05,
      "loss": 0.3337,
      "step": 5730
    },
    {
      "epoch": 3.1924360400444938,
      "grad_norm": 0.3281891942024231,
      "learning_rate": 1.0101501668520578e-05,
      "loss": 0.2727,
      "step": 5740
    },
    {
      "epoch": 3.1979977753058955,
      "grad_norm": 0.7015206217765808,
      "learning_rate": 1.003197997775306e-05,
      "loss": 0.2688,
      "step": 5750
    },
    {
      "epoch": 3.203559510567297,
      "grad_norm": 0.6093529462814331,
      "learning_rate": 9.96245828698554e-06,
      "loss": 0.2934,
      "step": 5760
    },
    {
      "epoch": 3.2091212458286984,
      "grad_norm": 6.968392848968506,
      "learning_rate": 9.892936596218021e-06,
      "loss": 0.2539,
      "step": 5770
    },
    {
      "epoch": 3.2146829810901,
      "grad_norm": 0.5346902012825012,
      "learning_rate": 9.8234149054505e-06,
      "loss": 0.2113,
      "step": 5780
    },
    {
      "epoch": 3.220244716351502,
      "grad_norm": 0.31407710909843445,
      "learning_rate": 9.753893214682981e-06,
      "loss": 0.2558,
      "step": 5790
    },
    {
      "epoch": 3.225806451612903,
      "grad_norm": 0.4831027388572693,
      "learning_rate": 9.68437152391546e-06,
      "loss": 0.2917,
      "step": 5800
    },
    {
      "epoch": 3.2313681868743047,
      "grad_norm": 0.9357530474662781,
      "learning_rate": 9.614849833147943e-06,
      "loss": 0.3696,
      "step": 5810
    },
    {
      "epoch": 3.2369299221357064,
      "grad_norm": 0.47790804505348206,
      "learning_rate": 9.545328142380423e-06,
      "loss": 0.2469,
      "step": 5820
    },
    {
      "epoch": 3.242491657397108,
      "grad_norm": 0.43773263692855835,
      "learning_rate": 9.475806451612903e-06,
      "loss": 0.2695,
      "step": 5830
    },
    {
      "epoch": 3.2480533926585093,
      "grad_norm": 0.5779737830162048,
      "learning_rate": 9.406284760845384e-06,
      "loss": 0.2406,
      "step": 5840
    },
    {
      "epoch": 3.253615127919911,
      "grad_norm": 0.3119135797023773,
      "learning_rate": 9.336763070077864e-06,
      "loss": 0.2614,
      "step": 5850
    },
    {
      "epoch": 3.2591768631813127,
      "grad_norm": 0.6003299355506897,
      "learning_rate": 9.267241379310346e-06,
      "loss": 0.3622,
      "step": 5860
    },
    {
      "epoch": 3.264738598442714,
      "grad_norm": 0.4219099283218384,
      "learning_rate": 9.197719688542826e-06,
      "loss": 0.2718,
      "step": 5870
    },
    {
      "epoch": 3.2703003337041157,
      "grad_norm": 0.5252382159233093,
      "learning_rate": 9.128197997775307e-06,
      "loss": 0.4053,
      "step": 5880
    },
    {
      "epoch": 3.2758620689655173,
      "grad_norm": 0.3951624035835266,
      "learning_rate": 9.058676307007786e-06,
      "loss": 0.2119,
      "step": 5890
    },
    {
      "epoch": 3.281423804226919,
      "grad_norm": 0.6007903814315796,
      "learning_rate": 8.989154616240267e-06,
      "loss": 0.2609,
      "step": 5900
    },
    {
      "epoch": 3.2869855394883203,
      "grad_norm": 0.3258345425128937,
      "learning_rate": 8.919632925472748e-06,
      "loss": 0.3466,
      "step": 5910
    },
    {
      "epoch": 3.292547274749722,
      "grad_norm": 0.5284444093704224,
      "learning_rate": 8.850111234705229e-06,
      "loss": 0.3143,
      "step": 5920
    },
    {
      "epoch": 3.2981090100111237,
      "grad_norm": 0.8240516781806946,
      "learning_rate": 8.78058954393771e-06,
      "loss": 0.3105,
      "step": 5930
    },
    {
      "epoch": 3.303670745272525,
      "grad_norm": 0.7176814675331116,
      "learning_rate": 8.711067853170189e-06,
      "loss": 0.2712,
      "step": 5940
    },
    {
      "epoch": 3.3092324805339266,
      "grad_norm": 0.40675437450408936,
      "learning_rate": 8.64154616240267e-06,
      "loss": 0.2516,
      "step": 5950
    },
    {
      "epoch": 3.3147942157953283,
      "grad_norm": 0.5453593730926514,
      "learning_rate": 8.57202447163515e-06,
      "loss": 0.3281,
      "step": 5960
    },
    {
      "epoch": 3.3203559510567295,
      "grad_norm": 0.64634770154953,
      "learning_rate": 8.502502780867632e-06,
      "loss": 0.3349,
      "step": 5970
    },
    {
      "epoch": 3.3259176863181312,
      "grad_norm": 0.6757411360740662,
      "learning_rate": 8.432981090100111e-06,
      "loss": 0.328,
      "step": 5980
    },
    {
      "epoch": 3.331479421579533,
      "grad_norm": 0.5859034061431885,
      "learning_rate": 8.363459399332592e-06,
      "loss": 0.386,
      "step": 5990
    },
    {
      "epoch": 3.337041156840934,
      "grad_norm": 0.505200982093811,
      "learning_rate": 8.293937708565073e-06,
      "loss": 0.3566,
      "step": 6000
    },
    {
      "epoch": 3.342602892102336,
      "grad_norm": 0.5325371623039246,
      "learning_rate": 8.224416017797554e-06,
      "loss": 0.3538,
      "step": 6010
    },
    {
      "epoch": 3.3481646273637375,
      "grad_norm": 0.38307949900627136,
      "learning_rate": 8.154894327030035e-06,
      "loss": 0.2912,
      "step": 6020
    },
    {
      "epoch": 3.3537263626251392,
      "grad_norm": 0.38518667221069336,
      "learning_rate": 8.085372636262514e-06,
      "loss": 0.2713,
      "step": 6030
    },
    {
      "epoch": 3.3592880978865405,
      "grad_norm": 0.6716933846473694,
      "learning_rate": 8.015850945494995e-06,
      "loss": 0.2412,
      "step": 6040
    },
    {
      "epoch": 3.364849833147942,
      "grad_norm": 0.8496624827384949,
      "learning_rate": 7.946329254727474e-06,
      "loss": 0.3358,
      "step": 6050
    },
    {
      "epoch": 3.370411568409344,
      "grad_norm": 0.546903133392334,
      "learning_rate": 7.876807563959957e-06,
      "loss": 0.2601,
      "step": 6060
    },
    {
      "epoch": 3.375973303670745,
      "grad_norm": 0.7644777297973633,
      "learning_rate": 7.807285873192436e-06,
      "loss": 0.3379,
      "step": 6070
    },
    {
      "epoch": 3.381535038932147,
      "grad_norm": 0.8415753841400146,
      "learning_rate": 7.737764182424917e-06,
      "loss": 0.332,
      "step": 6080
    },
    {
      "epoch": 3.3870967741935485,
      "grad_norm": 0.6821874976158142,
      "learning_rate": 7.668242491657396e-06,
      "loss": 0.3732,
      "step": 6090
    },
    {
      "epoch": 3.39265850945495,
      "grad_norm": 0.269291490316391,
      "learning_rate": 7.598720800889877e-06,
      "loss": 0.2607,
      "step": 6100
    },
    {
      "epoch": 3.3982202447163514,
      "grad_norm": 0.428007572889328,
      "learning_rate": 7.529199110122359e-06,
      "loss": 0.3195,
      "step": 6110
    },
    {
      "epoch": 3.403781979977753,
      "grad_norm": 0.7251949310302734,
      "learning_rate": 7.459677419354839e-06,
      "loss": 0.3202,
      "step": 6120
    },
    {
      "epoch": 3.409343715239155,
      "grad_norm": 0.611221194267273,
      "learning_rate": 7.390155728587319e-06,
      "loss": 0.2518,
      "step": 6130
    },
    {
      "epoch": 3.414905450500556,
      "grad_norm": 0.36746224761009216,
      "learning_rate": 7.3206340378197995e-06,
      "loss": 0.3094,
      "step": 6140
    },
    {
      "epoch": 3.4204671857619577,
      "grad_norm": 0.370792418718338,
      "learning_rate": 7.2511123470522805e-06,
      "loss": 0.2223,
      "step": 6150
    },
    {
      "epoch": 3.4260289210233594,
      "grad_norm": 0.3426188826560974,
      "learning_rate": 7.1815906562847614e-06,
      "loss": 0.2642,
      "step": 6160
    },
    {
      "epoch": 3.4315906562847607,
      "grad_norm": 0.6988728642463684,
      "learning_rate": 7.112068965517242e-06,
      "loss": 0.3319,
      "step": 6170
    },
    {
      "epoch": 3.4371523915461624,
      "grad_norm": 0.7157030701637268,
      "learning_rate": 7.0425472747497225e-06,
      "loss": 0.295,
      "step": 6180
    },
    {
      "epoch": 3.442714126807564,
      "grad_norm": 0.42061230540275574,
      "learning_rate": 6.973025583982203e-06,
      "loss": 0.2465,
      "step": 6190
    },
    {
      "epoch": 3.4482758620689653,
      "grad_norm": 0.2781018614768982,
      "learning_rate": 6.903503893214683e-06,
      "loss": 0.2495,
      "step": 6200
    },
    {
      "epoch": 3.453837597330367,
      "grad_norm": 0.5127992630004883,
      "learning_rate": 6.8339822024471645e-06,
      "loss": 0.2461,
      "step": 6210
    },
    {
      "epoch": 3.4593993325917687,
      "grad_norm": 0.5368841886520386,
      "learning_rate": 6.764460511679645e-06,
      "loss": 0.301,
      "step": 6220
    },
    {
      "epoch": 3.4649610678531704,
      "grad_norm": 0.5338907241821289,
      "learning_rate": 6.694938820912125e-06,
      "loss": 0.3725,
      "step": 6230
    },
    {
      "epoch": 3.4705228031145716,
      "grad_norm": 0.5360279083251953,
      "learning_rate": 6.625417130144605e-06,
      "loss": 0.2551,
      "step": 6240
    },
    {
      "epoch": 3.4760845383759733,
      "grad_norm": 0.48544520139694214,
      "learning_rate": 6.555895439377086e-06,
      "loss": 0.3431,
      "step": 6250
    },
    {
      "epoch": 3.481646273637375,
      "grad_norm": 0.46724042296409607,
      "learning_rate": 6.486373748609567e-06,
      "loss": 0.3216,
      "step": 6260
    },
    {
      "epoch": 3.4872080088987762,
      "grad_norm": 0.8280910849571228,
      "learning_rate": 6.416852057842048e-06,
      "loss": 0.2753,
      "step": 6270
    },
    {
      "epoch": 3.492769744160178,
      "grad_norm": 0.5995312333106995,
      "learning_rate": 6.347330367074528e-06,
      "loss": 0.2819,
      "step": 6280
    },
    {
      "epoch": 3.4983314794215796,
      "grad_norm": 0.6350462436676025,
      "learning_rate": 6.277808676307008e-06,
      "loss": 0.3715,
      "step": 6290
    },
    {
      "epoch": 3.5038932146829813,
      "grad_norm": 0.47007083892822266,
      "learning_rate": 6.208286985539489e-06,
      "loss": 0.3318,
      "step": 6300
    },
    {
      "epoch": 3.5094549499443826,
      "grad_norm": 0.5490261912345886,
      "learning_rate": 6.138765294771969e-06,
      "loss": 0.3513,
      "step": 6310
    },
    {
      "epoch": 3.5150166852057843,
      "grad_norm": 0.3335091173648834,
      "learning_rate": 6.069243604004449e-06,
      "loss": 0.2724,
      "step": 6320
    },
    {
      "epoch": 3.520578420467186,
      "grad_norm": 0.740649938583374,
      "learning_rate": 5.99972191323693e-06,
      "loss": 0.2826,
      "step": 6330
    },
    {
      "epoch": 3.526140155728587,
      "grad_norm": 0.31576603651046753,
      "learning_rate": 5.930200222469411e-06,
      "loss": 0.2903,
      "step": 6340
    },
    {
      "epoch": 3.531701890989989,
      "grad_norm": 0.4569782018661499,
      "learning_rate": 5.860678531701892e-06,
      "loss": 0.2475,
      "step": 6350
    },
    {
      "epoch": 3.5372636262513906,
      "grad_norm": 0.5481356382369995,
      "learning_rate": 5.791156840934372e-06,
      "loss": 0.2857,
      "step": 6360
    },
    {
      "epoch": 3.542825361512792,
      "grad_norm": 0.2673964500427246,
      "learning_rate": 5.721635150166852e-06,
      "loss": 0.375,
      "step": 6370
    },
    {
      "epoch": 3.5483870967741935,
      "grad_norm": 0.44053417444229126,
      "learning_rate": 5.652113459399333e-06,
      "loss": 0.3595,
      "step": 6380
    },
    {
      "epoch": 3.553948832035595,
      "grad_norm": 0.5663745999336243,
      "learning_rate": 5.582591768631813e-06,
      "loss": 0.2929,
      "step": 6390
    },
    {
      "epoch": 3.5595105672969964,
      "grad_norm": 0.645420253276825,
      "learning_rate": 5.513070077864294e-06,
      "loss": 0.3595,
      "step": 6400
    },
    {
      "epoch": 3.565072302558398,
      "grad_norm": 0.46495938301086426,
      "learning_rate": 5.443548387096774e-06,
      "loss": 0.3004,
      "step": 6410
    },
    {
      "epoch": 3.5706340378198,
      "grad_norm": 0.4185827076435089,
      "learning_rate": 5.374026696329254e-06,
      "loss": 0.2281,
      "step": 6420
    },
    {
      "epoch": 3.576195773081201,
      "grad_norm": 0.5107420682907104,
      "learning_rate": 5.304505005561735e-06,
      "loss": 0.3003,
      "step": 6430
    },
    {
      "epoch": 3.5817575083426028,
      "grad_norm": 0.6766192317008972,
      "learning_rate": 5.234983314794216e-06,
      "loss": 0.2647,
      "step": 6440
    },
    {
      "epoch": 3.5873192436040044,
      "grad_norm": 0.6314684152603149,
      "learning_rate": 5.165461624026697e-06,
      "loss": 0.2742,
      "step": 6450
    },
    {
      "epoch": 3.592880978865406,
      "grad_norm": 0.44342100620269775,
      "learning_rate": 5.095939933259177e-06,
      "loss": 0.2682,
      "step": 6460
    },
    {
      "epoch": 3.598442714126808,
      "grad_norm": 0.3529830574989319,
      "learning_rate": 5.0264182424916575e-06,
      "loss": 0.2328,
      "step": 6470
    },
    {
      "epoch": 3.604004449388209,
      "grad_norm": 0.5008590817451477,
      "learning_rate": 4.9568965517241384e-06,
      "loss": 0.2541,
      "step": 6480
    },
    {
      "epoch": 3.6095661846496108,
      "grad_norm": 0.4816952645778656,
      "learning_rate": 4.8873748609566185e-06,
      "loss": 0.23,
      "step": 6490
    },
    {
      "epoch": 3.6151279199110125,
      "grad_norm": 0.8457440137863159,
      "learning_rate": 4.8178531701890995e-06,
      "loss": 0.2729,
      "step": 6500
    },
    {
      "epoch": 3.6206896551724137,
      "grad_norm": 0.4162186086177826,
      "learning_rate": 4.74833147942158e-06,
      "loss": 0.3527,
      "step": 6510
    },
    {
      "epoch": 3.6262513904338154,
      "grad_norm": 0.4801127016544342,
      "learning_rate": 4.67880978865406e-06,
      "loss": 0.2307,
      "step": 6520
    },
    {
      "epoch": 3.631813125695217,
      "grad_norm": 0.3967067301273346,
      "learning_rate": 4.609288097886541e-06,
      "loss": 0.3363,
      "step": 6530
    },
    {
      "epoch": 3.6373748609566183,
      "grad_norm": 0.6303086280822754,
      "learning_rate": 4.539766407119022e-06,
      "loss": 0.2451,
      "step": 6540
    },
    {
      "epoch": 3.64293659621802,
      "grad_norm": 0.8391394019126892,
      "learning_rate": 4.470244716351502e-06,
      "loss": 0.2765,
      "step": 6550
    },
    {
      "epoch": 3.6484983314794217,
      "grad_norm": 0.34963715076446533,
      "learning_rate": 4.400723025583983e-06,
      "loss": 0.3622,
      "step": 6560
    },
    {
      "epoch": 3.654060066740823,
      "grad_norm": 0.48982954025268555,
      "learning_rate": 4.331201334816463e-06,
      "loss": 0.3164,
      "step": 6570
    },
    {
      "epoch": 3.6596218020022246,
      "grad_norm": 1.7247192859649658,
      "learning_rate": 4.261679644048944e-06,
      "loss": 0.257,
      "step": 6580
    },
    {
      "epoch": 3.6651835372636263,
      "grad_norm": 0.7921558022499084,
      "learning_rate": 4.192157953281424e-06,
      "loss": 0.3775,
      "step": 6590
    },
    {
      "epoch": 3.6707452725250276,
      "grad_norm": 0.9015834331512451,
      "learning_rate": 4.122636262513904e-06,
      "loss": 0.3135,
      "step": 6600
    },
    {
      "epoch": 3.6763070077864293,
      "grad_norm": 0.18842321634292603,
      "learning_rate": 4.053114571746385e-06,
      "loss": 0.2019,
      "step": 6610
    },
    {
      "epoch": 3.681868743047831,
      "grad_norm": 0.35145971179008484,
      "learning_rate": 3.983592880978865e-06,
      "loss": 0.2471,
      "step": 6620
    },
    {
      "epoch": 3.687430478309232,
      "grad_norm": 0.43031296133995056,
      "learning_rate": 3.914071190211346e-06,
      "loss": 0.331,
      "step": 6630
    },
    {
      "epoch": 3.692992213570634,
      "grad_norm": 0.497689813375473,
      "learning_rate": 3.844549499443827e-06,
      "loss": 0.2199,
      "step": 6640
    },
    {
      "epoch": 3.6985539488320356,
      "grad_norm": 0.29521864652633667,
      "learning_rate": 3.775027808676307e-06,
      "loss": 0.2432,
      "step": 6650
    },
    {
      "epoch": 3.7041156840934373,
      "grad_norm": 0.8546123504638672,
      "learning_rate": 3.705506117908788e-06,
      "loss": 0.4009,
      "step": 6660
    },
    {
      "epoch": 3.709677419354839,
      "grad_norm": 0.8066685795783997,
      "learning_rate": 3.635984427141268e-06,
      "loss": 0.3025,
      "step": 6670
    },
    {
      "epoch": 3.71523915461624,
      "grad_norm": 0.29025986790657043,
      "learning_rate": 3.566462736373749e-06,
      "loss": 0.2893,
      "step": 6680
    },
    {
      "epoch": 3.720800889877642,
      "grad_norm": 0.6625093817710876,
      "learning_rate": 3.496941045606229e-06,
      "loss": 0.3593,
      "step": 6690
    },
    {
      "epoch": 3.7263626251390436,
      "grad_norm": 0.5258078575134277,
      "learning_rate": 3.4274193548387097e-06,
      "loss": 0.283,
      "step": 6700
    },
    {
      "epoch": 3.731924360400445,
      "grad_norm": 0.33363109827041626,
      "learning_rate": 3.3578976640711906e-06,
      "loss": 0.2791,
      "step": 6710
    },
    {
      "epoch": 3.7374860956618465,
      "grad_norm": 0.5418437123298645,
      "learning_rate": 3.2883759733036708e-06,
      "loss": 0.2428,
      "step": 6720
    },
    {
      "epoch": 3.743047830923248,
      "grad_norm": 0.6340230703353882,
      "learning_rate": 3.2188542825361517e-06,
      "loss": 0.2694,
      "step": 6730
    },
    {
      "epoch": 3.7486095661846495,
      "grad_norm": 0.45587262511253357,
      "learning_rate": 3.149332591768632e-06,
      "loss": 0.32,
      "step": 6740
    },
    {
      "epoch": 3.754171301446051,
      "grad_norm": 0.31684979796409607,
      "learning_rate": 3.0798109010011128e-06,
      "loss": 0.2446,
      "step": 6750
    },
    {
      "epoch": 3.759733036707453,
      "grad_norm": 0.372510701417923,
      "learning_rate": 3.010289210233593e-06,
      "loss": 0.2646,
      "step": 6760
    },
    {
      "epoch": 3.765294771968854,
      "grad_norm": 0.40465107560157776,
      "learning_rate": 2.9407675194660734e-06,
      "loss": 0.2716,
      "step": 6770
    },
    {
      "epoch": 3.770856507230256,
      "grad_norm": 0.4713502824306488,
      "learning_rate": 2.871245828698554e-06,
      "loss": 0.3202,
      "step": 6780
    },
    {
      "epoch": 3.7764182424916575,
      "grad_norm": 0.2387162744998932,
      "learning_rate": 2.8017241379310345e-06,
      "loss": 0.267,
      "step": 6790
    },
    {
      "epoch": 3.7819799777530587,
      "grad_norm": 0.5950148701667786,
      "learning_rate": 2.7322024471635154e-06,
      "loss": 0.2709,
      "step": 6800
    },
    {
      "epoch": 3.7875417130144604,
      "grad_norm": 0.4362105131149292,
      "learning_rate": 2.6626807563959955e-06,
      "loss": 0.319,
      "step": 6810
    },
    {
      "epoch": 3.793103448275862,
      "grad_norm": 0.42741265892982483,
      "learning_rate": 2.593159065628476e-06,
      "loss": 0.321,
      "step": 6820
    },
    {
      "epoch": 3.798665183537264,
      "grad_norm": 0.4190111756324768,
      "learning_rate": 2.5236373748609566e-06,
      "loss": 0.218,
      "step": 6830
    },
    {
      "epoch": 3.804226918798665,
      "grad_norm": 0.4452134370803833,
      "learning_rate": 2.4541156840934375e-06,
      "loss": 0.2207,
      "step": 6840
    },
    {
      "epoch": 3.8097886540600667,
      "grad_norm": 0.4134957790374756,
      "learning_rate": 2.384593993325918e-06,
      "loss": 0.2825,
      "step": 6850
    },
    {
      "epoch": 3.8153503893214684,
      "grad_norm": 0.3150370121002197,
      "learning_rate": 2.315072302558398e-06,
      "loss": 0.3186,
      "step": 6860
    },
    {
      "epoch": 3.82091212458287,
      "grad_norm": 0.5587698817253113,
      "learning_rate": 2.2455506117908787e-06,
      "loss": 0.3277,
      "step": 6870
    },
    {
      "epoch": 3.8264738598442714,
      "grad_norm": 0.4590167701244354,
      "learning_rate": 2.1760289210233593e-06,
      "loss": 0.2572,
      "step": 6880
    },
    {
      "epoch": 3.832035595105673,
      "grad_norm": 0.2634437680244446,
      "learning_rate": 2.10650723025584e-06,
      "loss": 0.2591,
      "step": 6890
    },
    {
      "epoch": 3.8375973303670747,
      "grad_norm": 0.44748154282569885,
      "learning_rate": 2.0369855394883207e-06,
      "loss": 0.2835,
      "step": 6900
    },
    {
      "epoch": 3.843159065628476,
      "grad_norm": 0.47398513555526733,
      "learning_rate": 1.967463848720801e-06,
      "loss": 0.2408,
      "step": 6910
    },
    {
      "epoch": 3.8487208008898777,
      "grad_norm": 0.6520892977714539,
      "learning_rate": 1.8979421579532814e-06,
      "loss": 0.2543,
      "step": 6920
    },
    {
      "epoch": 3.8542825361512794,
      "grad_norm": 0.473018616437912,
      "learning_rate": 1.8284204671857621e-06,
      "loss": 0.3144,
      "step": 6930
    },
    {
      "epoch": 3.8598442714126806,
      "grad_norm": 0.3138541281223297,
      "learning_rate": 1.7588987764182426e-06,
      "loss": 0.3115,
      "step": 6940
    },
    {
      "epoch": 3.8654060066740823,
      "grad_norm": 0.458025187253952,
      "learning_rate": 1.689377085650723e-06,
      "loss": 0.3019,
      "step": 6950
    },
    {
      "epoch": 3.870967741935484,
      "grad_norm": 0.5861018300056458,
      "learning_rate": 1.6198553948832035e-06,
      "loss": 0.2518,
      "step": 6960
    },
    {
      "epoch": 3.8765294771968852,
      "grad_norm": 0.6626324653625488,
      "learning_rate": 1.5503337041156842e-06,
      "loss": 0.3096,
      "step": 6970
    },
    {
      "epoch": 3.882091212458287,
      "grad_norm": 0.4669268727302551,
      "learning_rate": 1.4808120133481648e-06,
      "loss": 0.2974,
      "step": 6980
    },
    {
      "epoch": 3.8876529477196886,
      "grad_norm": 0.4060131311416626,
      "learning_rate": 1.411290322580645e-06,
      "loss": 0.3147,
      "step": 6990
    },
    {
      "epoch": 3.89321468298109,
      "grad_norm": 0.40965116024017334,
      "learning_rate": 1.3417686318131258e-06,
      "loss": 0.3196,
      "step": 7000
    },
    {
      "epoch": 3.8987764182424915,
      "grad_norm": 0.4623655080795288,
      "learning_rate": 1.2722469410456062e-06,
      "loss": 0.2408,
      "step": 7010
    },
    {
      "epoch": 3.9043381535038932,
      "grad_norm": 2.429088830947876,
      "learning_rate": 1.202725250278087e-06,
      "loss": 0.2643,
      "step": 7020
    },
    {
      "epoch": 3.909899888765295,
      "grad_norm": 0.5671985745429993,
      "learning_rate": 1.1332035595105674e-06,
      "loss": 0.2962,
      "step": 7030
    },
    {
      "epoch": 3.915461624026696,
      "grad_norm": 0.6445538401603699,
      "learning_rate": 1.063681868743048e-06,
      "loss": 0.2627,
      "step": 7040
    },
    {
      "epoch": 3.921023359288098,
      "grad_norm": 0.6293631196022034,
      "learning_rate": 9.941601779755285e-07,
      "loss": 0.3167,
      "step": 7050
    },
    {
      "epoch": 3.9265850945494996,
      "grad_norm": 0.3174208998680115,
      "learning_rate": 9.246384872080089e-07,
      "loss": 0.3481,
      "step": 7060
    },
    {
      "epoch": 3.9321468298109012,
      "grad_norm": 0.3567233681678772,
      "learning_rate": 8.551167964404896e-07,
      "loss": 0.2889,
      "step": 7070
    },
    {
      "epoch": 3.9377085650723025,
      "grad_norm": 0.6596034169197083,
      "learning_rate": 7.8559510567297e-07,
      "loss": 0.3292,
      "step": 7080
    },
    {
      "epoch": 3.943270300333704,
      "grad_norm": 0.7191445827484131,
      "learning_rate": 7.160734149054505e-07,
      "loss": 0.3235,
      "step": 7090
    },
    {
      "epoch": 3.948832035595106,
      "grad_norm": 0.3892284333705902,
      "learning_rate": 6.46551724137931e-07,
      "loss": 0.3145,
      "step": 7100
    },
    {
      "epoch": 3.954393770856507,
      "grad_norm": 0.7225123047828674,
      "learning_rate": 5.770300333704116e-07,
      "loss": 0.3364,
      "step": 7110
    },
    {
      "epoch": 3.959955506117909,
      "grad_norm": 0.8936095833778381,
      "learning_rate": 5.075083426028921e-07,
      "loss": 0.306,
      "step": 7120
    },
    {
      "epoch": 3.9655172413793105,
      "grad_norm": 0.7946800589561462,
      "learning_rate": 4.379866518353727e-07,
      "loss": 0.2463,
      "step": 7130
    },
    {
      "epoch": 3.9710789766407117,
      "grad_norm": 0.681087076663971,
      "learning_rate": 3.6846496106785316e-07,
      "loss": 0.332,
      "step": 7140
    },
    {
      "epoch": 3.9766407119021134,
      "grad_norm": 0.5210220813751221,
      "learning_rate": 2.9894327030033375e-07,
      "loss": 0.2943,
      "step": 7150
    },
    {
      "epoch": 3.982202447163515,
      "grad_norm": 0.42458173632621765,
      "learning_rate": 2.2942157953281425e-07,
      "loss": 0.2455,
      "step": 7160
    },
    {
      "epoch": 3.9877641824249164,
      "grad_norm": 0.78684401512146,
      "learning_rate": 1.5989988876529478e-07,
      "loss": 0.2654,
      "step": 7170
    },
    {
      "epoch": 3.993325917686318,
      "grad_norm": 0.6939674615859985,
      "learning_rate": 9.03781979977753e-08,
      "loss": 0.3869,
      "step": 7180
    },
    {
      "epoch": 3.9988876529477198,
      "grad_norm": 0.29793983697891235,
      "learning_rate": 2.0856507230255843e-08,
      "loss": 0.2262,
      "step": 7190
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.2771552503108978,
      "eval_runtime": 7.8363,
      "eval_samples_per_second": 204.05,
      "eval_steps_per_second": 25.522,
      "step": 7192
    }
  ],
  "logging_steps": 10,
  "max_steps": 7192,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1946621130571776.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
