{
  "best_global_step": 8990,
  "best_metric": 0.2622697651386261,
  "best_model_checkpoint": "./model_output/checkpoint-8990",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 8990,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0055617352614015575,
      "grad_norm": 1.5644617080688477,
      "learning_rate": 4.994994438264739e-05,
      "loss": 2.5393,
      "step": 10
    },
    {
      "epoch": 0.011123470522803115,
      "grad_norm": 1.4218497276306152,
      "learning_rate": 4.989432703003337e-05,
      "loss": 1.336,
      "step": 20
    },
    {
      "epoch": 0.01668520578420467,
      "grad_norm": 0.902086079120636,
      "learning_rate": 4.983870967741936e-05,
      "loss": 0.8863,
      "step": 30
    },
    {
      "epoch": 0.02224694104560623,
      "grad_norm": 0.6482670307159424,
      "learning_rate": 4.978309232480534e-05,
      "loss": 0.9419,
      "step": 40
    },
    {
      "epoch": 0.027808676307007785,
      "grad_norm": 0.9133040308952332,
      "learning_rate": 4.9727474972191325e-05,
      "loss": 0.7593,
      "step": 50
    },
    {
      "epoch": 0.03337041156840934,
      "grad_norm": 0.6533145904541016,
      "learning_rate": 4.967185761957731e-05,
      "loss": 0.81,
      "step": 60
    },
    {
      "epoch": 0.0389321468298109,
      "grad_norm": 0.7329212427139282,
      "learning_rate": 4.9616240266963295e-05,
      "loss": 0.6814,
      "step": 70
    },
    {
      "epoch": 0.04449388209121246,
      "grad_norm": 2.9457757472991943,
      "learning_rate": 4.956062291434928e-05,
      "loss": 0.8951,
      "step": 80
    },
    {
      "epoch": 0.05005561735261402,
      "grad_norm": 0.8793553709983826,
      "learning_rate": 4.9505005561735264e-05,
      "loss": 0.8024,
      "step": 90
    },
    {
      "epoch": 0.05561735261401557,
      "grad_norm": 1.35953950881958,
      "learning_rate": 4.944938820912125e-05,
      "loss": 0.8078,
      "step": 100
    },
    {
      "epoch": 0.06117908787541713,
      "grad_norm": 1.1862797737121582,
      "learning_rate": 4.9393770856507234e-05,
      "loss": 0.6381,
      "step": 110
    },
    {
      "epoch": 0.06674082313681869,
      "grad_norm": 1.20048987865448,
      "learning_rate": 4.933815350389322e-05,
      "loss": 0.5597,
      "step": 120
    },
    {
      "epoch": 0.07230255839822025,
      "grad_norm": 1.1487962007522583,
      "learning_rate": 4.92825361512792e-05,
      "loss": 0.7481,
      "step": 130
    },
    {
      "epoch": 0.0778642936596218,
      "grad_norm": 1.0668425559997559,
      "learning_rate": 4.922691879866518e-05,
      "loss": 0.5695,
      "step": 140
    },
    {
      "epoch": 0.08342602892102335,
      "grad_norm": 1.5285557508468628,
      "learning_rate": 4.917130144605117e-05,
      "loss": 0.687,
      "step": 150
    },
    {
      "epoch": 0.08898776418242492,
      "grad_norm": 0.6619119048118591,
      "learning_rate": 4.911568409343715e-05,
      "loss": 0.6608,
      "step": 160
    },
    {
      "epoch": 0.09454949944382647,
      "grad_norm": 0.7513905167579651,
      "learning_rate": 4.906006674082314e-05,
      "loss": 0.5928,
      "step": 170
    },
    {
      "epoch": 0.10011123470522804,
      "grad_norm": 1.0018261671066284,
      "learning_rate": 4.900444938820912e-05,
      "loss": 0.5951,
      "step": 180
    },
    {
      "epoch": 0.10567296996662959,
      "grad_norm": 0.8170598745346069,
      "learning_rate": 4.894883203559511e-05,
      "loss": 0.6368,
      "step": 190
    },
    {
      "epoch": 0.11123470522803114,
      "grad_norm": 0.8661732077598572,
      "learning_rate": 4.889321468298109e-05,
      "loss": 0.6086,
      "step": 200
    },
    {
      "epoch": 0.1167964404894327,
      "grad_norm": 0.8441433310508728,
      "learning_rate": 4.8837597330367074e-05,
      "loss": 0.6749,
      "step": 210
    },
    {
      "epoch": 0.12235817575083426,
      "grad_norm": 1.100049376487732,
      "learning_rate": 4.878197997775306e-05,
      "loss": 0.7116,
      "step": 220
    },
    {
      "epoch": 0.12791991101223582,
      "grad_norm": 0.6193163990974426,
      "learning_rate": 4.8726362625139044e-05,
      "loss": 0.4445,
      "step": 230
    },
    {
      "epoch": 0.13348164627363737,
      "grad_norm": 0.8780858516693115,
      "learning_rate": 4.867074527252503e-05,
      "loss": 0.6236,
      "step": 240
    },
    {
      "epoch": 0.13904338153503892,
      "grad_norm": 0.561882495880127,
      "learning_rate": 4.8615127919911014e-05,
      "loss": 0.626,
      "step": 250
    },
    {
      "epoch": 0.1446051167964405,
      "grad_norm": 1.349529504776001,
      "learning_rate": 4.8559510567297e-05,
      "loss": 0.6092,
      "step": 260
    },
    {
      "epoch": 0.15016685205784205,
      "grad_norm": 1.4107921123504639,
      "learning_rate": 4.850389321468298e-05,
      "loss": 0.5948,
      "step": 270
    },
    {
      "epoch": 0.1557285873192436,
      "grad_norm": 0.5203419923782349,
      "learning_rate": 4.844827586206897e-05,
      "loss": 0.472,
      "step": 280
    },
    {
      "epoch": 0.16129032258064516,
      "grad_norm": 1.2106854915618896,
      "learning_rate": 4.839265850945495e-05,
      "loss": 0.5477,
      "step": 290
    },
    {
      "epoch": 0.1668520578420467,
      "grad_norm": 0.6783835887908936,
      "learning_rate": 4.833704115684094e-05,
      "loss": 0.4848,
      "step": 300
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 0.5396688580513,
      "learning_rate": 4.828142380422692e-05,
      "loss": 0.64,
      "step": 310
    },
    {
      "epoch": 0.17797552836484984,
      "grad_norm": 0.4243879020214081,
      "learning_rate": 4.822580645161291e-05,
      "loss": 0.441,
      "step": 320
    },
    {
      "epoch": 0.1835372636262514,
      "grad_norm": 1.0320347547531128,
      "learning_rate": 4.817018909899889e-05,
      "loss": 0.5664,
      "step": 330
    },
    {
      "epoch": 0.18909899888765294,
      "grad_norm": 0.4157470464706421,
      "learning_rate": 4.8114571746384876e-05,
      "loss": 0.5915,
      "step": 340
    },
    {
      "epoch": 0.1946607341490545,
      "grad_norm": 1.4406603574752808,
      "learning_rate": 4.805895439377086e-05,
      "loss": 0.5725,
      "step": 350
    },
    {
      "epoch": 0.20022246941045607,
      "grad_norm": 0.716001570224762,
      "learning_rate": 4.8003337041156846e-05,
      "loss": 0.6373,
      "step": 360
    },
    {
      "epoch": 0.20578420467185762,
      "grad_norm": 0.448042094707489,
      "learning_rate": 4.794771968854283e-05,
      "loss": 0.4965,
      "step": 370
    },
    {
      "epoch": 0.21134593993325917,
      "grad_norm": 0.6285927295684814,
      "learning_rate": 4.7892102335928815e-05,
      "loss": 0.4828,
      "step": 380
    },
    {
      "epoch": 0.21690767519466073,
      "grad_norm": 0.5028076171875,
      "learning_rate": 4.7836484983314793e-05,
      "loss": 0.4793,
      "step": 390
    },
    {
      "epoch": 0.22246941045606228,
      "grad_norm": 1.1467211246490479,
      "learning_rate": 4.7780867630700785e-05,
      "loss": 0.45,
      "step": 400
    },
    {
      "epoch": 0.22803114571746386,
      "grad_norm": 0.5646633505821228,
      "learning_rate": 4.772525027808676e-05,
      "loss": 0.545,
      "step": 410
    },
    {
      "epoch": 0.2335928809788654,
      "grad_norm": 0.4963145852088928,
      "learning_rate": 4.7669632925472755e-05,
      "loss": 0.5568,
      "step": 420
    },
    {
      "epoch": 0.23915461624026696,
      "grad_norm": 1.284170150756836,
      "learning_rate": 4.761401557285873e-05,
      "loss": 0.5864,
      "step": 430
    },
    {
      "epoch": 0.2447163515016685,
      "grad_norm": 1.11406672000885,
      "learning_rate": 4.7558398220244724e-05,
      "loss": 0.681,
      "step": 440
    },
    {
      "epoch": 0.25027808676307006,
      "grad_norm": 1.262968897819519,
      "learning_rate": 4.75027808676307e-05,
      "loss": 0.4776,
      "step": 450
    },
    {
      "epoch": 0.25583982202447164,
      "grad_norm": 0.7973092198371887,
      "learning_rate": 4.744716351501669e-05,
      "loss": 0.5766,
      "step": 460
    },
    {
      "epoch": 0.26140155728587317,
      "grad_norm": 1.0531082153320312,
      "learning_rate": 4.739154616240267e-05,
      "loss": 0.5098,
      "step": 470
    },
    {
      "epoch": 0.26696329254727474,
      "grad_norm": 0.737508237361908,
      "learning_rate": 4.7335928809788656e-05,
      "loss": 0.5263,
      "step": 480
    },
    {
      "epoch": 0.2725250278086763,
      "grad_norm": 0.7435683012008667,
      "learning_rate": 4.728031145717464e-05,
      "loss": 0.4738,
      "step": 490
    },
    {
      "epoch": 0.27808676307007785,
      "grad_norm": 0.9363501071929932,
      "learning_rate": 4.7224694104560626e-05,
      "loss": 0.7001,
      "step": 500
    },
    {
      "epoch": 0.2836484983314794,
      "grad_norm": 0.8447442054748535,
      "learning_rate": 4.716907675194661e-05,
      "loss": 0.6317,
      "step": 510
    },
    {
      "epoch": 0.289210233592881,
      "grad_norm": 0.8604906797409058,
      "learning_rate": 4.7113459399332595e-05,
      "loss": 0.5915,
      "step": 520
    },
    {
      "epoch": 0.29477196885428253,
      "grad_norm": 1.327532172203064,
      "learning_rate": 4.705784204671858e-05,
      "loss": 0.5057,
      "step": 530
    },
    {
      "epoch": 0.3003337041156841,
      "grad_norm": 0.5799897313117981,
      "learning_rate": 4.7002224694104565e-05,
      "loss": 0.4995,
      "step": 540
    },
    {
      "epoch": 0.30589543937708563,
      "grad_norm": 0.8173880577087402,
      "learning_rate": 4.694660734149054e-05,
      "loss": 0.4252,
      "step": 550
    },
    {
      "epoch": 0.3114571746384872,
      "grad_norm": 0.6350221633911133,
      "learning_rate": 4.6890989988876534e-05,
      "loss": 0.6079,
      "step": 560
    },
    {
      "epoch": 0.3170189098998888,
      "grad_norm": 0.4830128252506256,
      "learning_rate": 4.683537263626251e-05,
      "loss": 0.3687,
      "step": 570
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 0.5712074637413025,
      "learning_rate": 4.6779755283648504e-05,
      "loss": 0.4817,
      "step": 580
    },
    {
      "epoch": 0.3281423804226919,
      "grad_norm": 0.7550252676010132,
      "learning_rate": 4.672413793103448e-05,
      "loss": 0.6192,
      "step": 590
    },
    {
      "epoch": 0.3337041156840934,
      "grad_norm": 0.3805789649486542,
      "learning_rate": 4.6668520578420473e-05,
      "loss": 0.5131,
      "step": 600
    },
    {
      "epoch": 0.339265850945495,
      "grad_norm": 0.8072139620780945,
      "learning_rate": 4.661290322580645e-05,
      "loss": 0.574,
      "step": 610
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 0.7422954440116882,
      "learning_rate": 4.6557285873192436e-05,
      "loss": 0.4504,
      "step": 620
    },
    {
      "epoch": 0.3503893214682981,
      "grad_norm": 0.8322761058807373,
      "learning_rate": 4.650166852057842e-05,
      "loss": 0.5038,
      "step": 630
    },
    {
      "epoch": 0.3559510567296997,
      "grad_norm": 0.6715607643127441,
      "learning_rate": 4.6446051167964406e-05,
      "loss": 0.4117,
      "step": 640
    },
    {
      "epoch": 0.3615127919911012,
      "grad_norm": 0.5021796226501465,
      "learning_rate": 4.639043381535039e-05,
      "loss": 0.5546,
      "step": 650
    },
    {
      "epoch": 0.3670745272525028,
      "grad_norm": 0.6508240699768066,
      "learning_rate": 4.6334816462736375e-05,
      "loss": 0.4173,
      "step": 660
    },
    {
      "epoch": 0.37263626251390436,
      "grad_norm": 0.793722927570343,
      "learning_rate": 4.627919911012236e-05,
      "loss": 0.4741,
      "step": 670
    },
    {
      "epoch": 0.3781979977753059,
      "grad_norm": 0.42059895396232605,
      "learning_rate": 4.6223581757508345e-05,
      "loss": 0.4585,
      "step": 680
    },
    {
      "epoch": 0.38375973303670746,
      "grad_norm": 0.4459444284439087,
      "learning_rate": 4.616796440489433e-05,
      "loss": 0.3911,
      "step": 690
    },
    {
      "epoch": 0.389321468298109,
      "grad_norm": 0.7852665185928345,
      "learning_rate": 4.6112347052280314e-05,
      "loss": 0.4871,
      "step": 700
    },
    {
      "epoch": 0.39488320355951056,
      "grad_norm": 1.026409387588501,
      "learning_rate": 4.605672969966629e-05,
      "loss": 0.4692,
      "step": 710
    },
    {
      "epoch": 0.40044493882091214,
      "grad_norm": 0.9801706075668335,
      "learning_rate": 4.6001112347052284e-05,
      "loss": 0.5054,
      "step": 720
    },
    {
      "epoch": 0.40600667408231367,
      "grad_norm": 0.7943743467330933,
      "learning_rate": 4.594549499443826e-05,
      "loss": 0.4656,
      "step": 730
    },
    {
      "epoch": 0.41156840934371525,
      "grad_norm": 0.33768758177757263,
      "learning_rate": 4.5889877641824253e-05,
      "loss": 0.4812,
      "step": 740
    },
    {
      "epoch": 0.41713014460511677,
      "grad_norm": 0.8955248594284058,
      "learning_rate": 4.583426028921023e-05,
      "loss": 0.4761,
      "step": 750
    },
    {
      "epoch": 0.42269187986651835,
      "grad_norm": 0.5193465948104858,
      "learning_rate": 4.577864293659622e-05,
      "loss": 0.435,
      "step": 760
    },
    {
      "epoch": 0.42825361512791993,
      "grad_norm": 0.5719959735870361,
      "learning_rate": 4.57230255839822e-05,
      "loss": 0.4611,
      "step": 770
    },
    {
      "epoch": 0.43381535038932145,
      "grad_norm": 0.8154593110084534,
      "learning_rate": 4.566740823136819e-05,
      "loss": 0.5112,
      "step": 780
    },
    {
      "epoch": 0.43937708565072303,
      "grad_norm": 0.6348971128463745,
      "learning_rate": 4.561179087875417e-05,
      "loss": 0.4217,
      "step": 790
    },
    {
      "epoch": 0.44493882091212456,
      "grad_norm": 0.827019453048706,
      "learning_rate": 4.5556173526140155e-05,
      "loss": 0.5213,
      "step": 800
    },
    {
      "epoch": 0.45050055617352613,
      "grad_norm": 0.8618985414505005,
      "learning_rate": 4.550055617352614e-05,
      "loss": 0.5583,
      "step": 810
    },
    {
      "epoch": 0.4560622914349277,
      "grad_norm": 0.7020318508148193,
      "learning_rate": 4.5444938820912125e-05,
      "loss": 0.4168,
      "step": 820
    },
    {
      "epoch": 0.46162402669632924,
      "grad_norm": 0.7077307105064392,
      "learning_rate": 4.538932146829811e-05,
      "loss": 0.4752,
      "step": 830
    },
    {
      "epoch": 0.4671857619577308,
      "grad_norm": 0.4795917272567749,
      "learning_rate": 4.5333704115684094e-05,
      "loss": 0.4289,
      "step": 840
    },
    {
      "epoch": 0.4727474972191324,
      "grad_norm": 0.8081238269805908,
      "learning_rate": 4.527808676307008e-05,
      "loss": 0.4585,
      "step": 850
    },
    {
      "epoch": 0.4783092324805339,
      "grad_norm": 0.5975729823112488,
      "learning_rate": 4.5222469410456064e-05,
      "loss": 0.4353,
      "step": 860
    },
    {
      "epoch": 0.4838709677419355,
      "grad_norm": 0.9823892116546631,
      "learning_rate": 4.516685205784205e-05,
      "loss": 0.5457,
      "step": 870
    },
    {
      "epoch": 0.489432703003337,
      "grad_norm": 0.8548790216445923,
      "learning_rate": 4.511123470522803e-05,
      "loss": 0.4759,
      "step": 880
    },
    {
      "epoch": 0.4949944382647386,
      "grad_norm": 0.7041309475898743,
      "learning_rate": 4.505561735261402e-05,
      "loss": 0.5102,
      "step": 890
    },
    {
      "epoch": 0.5005561735261401,
      "grad_norm": 1.2489421367645264,
      "learning_rate": 4.5e-05,
      "loss": 0.4653,
      "step": 900
    },
    {
      "epoch": 0.5061179087875417,
      "grad_norm": 0.7418347597122192,
      "learning_rate": 4.494438264738599e-05,
      "loss": 0.3799,
      "step": 910
    },
    {
      "epoch": 0.5116796440489433,
      "grad_norm": 0.534386932849884,
      "learning_rate": 4.488876529477197e-05,
      "loss": 0.488,
      "step": 920
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 0.4585161805152893,
      "learning_rate": 4.483314794215796e-05,
      "loss": 0.4576,
      "step": 930
    },
    {
      "epoch": 0.5228031145717463,
      "grad_norm": 0.7078929543495178,
      "learning_rate": 4.477753058954394e-05,
      "loss": 0.4153,
      "step": 940
    },
    {
      "epoch": 0.5283648498331479,
      "grad_norm": 1.2338416576385498,
      "learning_rate": 4.472191323692993e-05,
      "loss": 0.6566,
      "step": 950
    },
    {
      "epoch": 0.5339265850945495,
      "grad_norm": 0.45055073499679565,
      "learning_rate": 4.4666295884315905e-05,
      "loss": 0.5192,
      "step": 960
    },
    {
      "epoch": 0.5394883203559511,
      "grad_norm": 0.6383432149887085,
      "learning_rate": 4.4610678531701896e-05,
      "loss": 0.4383,
      "step": 970
    },
    {
      "epoch": 0.5450500556173526,
      "grad_norm": 0.5935222506523132,
      "learning_rate": 4.4555061179087874e-05,
      "loss": 0.4086,
      "step": 980
    },
    {
      "epoch": 0.5506117908787542,
      "grad_norm": 0.4993321895599365,
      "learning_rate": 4.4499443826473866e-05,
      "loss": 0.4801,
      "step": 990
    },
    {
      "epoch": 0.5561735261401557,
      "grad_norm": 0.9007981419563293,
      "learning_rate": 4.4443826473859844e-05,
      "loss": 0.4307,
      "step": 1000
    },
    {
      "epoch": 0.5617352614015573,
      "grad_norm": 0.5576415061950684,
      "learning_rate": 4.4388209121245835e-05,
      "loss": 0.3734,
      "step": 1010
    },
    {
      "epoch": 0.5672969966629589,
      "grad_norm": 0.6335195899009705,
      "learning_rate": 4.433259176863181e-05,
      "loss": 0.4585,
      "step": 1020
    },
    {
      "epoch": 0.5728587319243604,
      "grad_norm": 0.5973862409591675,
      "learning_rate": 4.4276974416017805e-05,
      "loss": 0.4373,
      "step": 1030
    },
    {
      "epoch": 0.578420467185762,
      "grad_norm": 0.8816512823104858,
      "learning_rate": 4.422135706340378e-05,
      "loss": 0.4621,
      "step": 1040
    },
    {
      "epoch": 0.5839822024471635,
      "grad_norm": 0.5370500683784485,
      "learning_rate": 4.416573971078977e-05,
      "loss": 0.4306,
      "step": 1050
    },
    {
      "epoch": 0.5895439377085651,
      "grad_norm": 0.5899920463562012,
      "learning_rate": 4.411012235817575e-05,
      "loss": 0.3329,
      "step": 1060
    },
    {
      "epoch": 0.5951056729699666,
      "grad_norm": 0.8267195224761963,
      "learning_rate": 4.405450500556174e-05,
      "loss": 0.4475,
      "step": 1070
    },
    {
      "epoch": 0.6006674082313682,
      "grad_norm": 0.7011145949363708,
      "learning_rate": 4.399888765294772e-05,
      "loss": 0.3988,
      "step": 1080
    },
    {
      "epoch": 0.6062291434927698,
      "grad_norm": 0.44179993867874146,
      "learning_rate": 4.3943270300333707e-05,
      "loss": 0.408,
      "step": 1090
    },
    {
      "epoch": 0.6117908787541713,
      "grad_norm": 1.0097451210021973,
      "learning_rate": 4.388765294771969e-05,
      "loss": 0.4462,
      "step": 1100
    },
    {
      "epoch": 0.6173526140155728,
      "grad_norm": 0.538932204246521,
      "learning_rate": 4.3832035595105676e-05,
      "loss": 0.3431,
      "step": 1110
    },
    {
      "epoch": 0.6229143492769744,
      "grad_norm": 0.9805849194526672,
      "learning_rate": 4.3776418242491654e-05,
      "loss": 0.4322,
      "step": 1120
    },
    {
      "epoch": 0.628476084538376,
      "grad_norm": 0.7683868408203125,
      "learning_rate": 4.3720800889877646e-05,
      "loss": 0.3804,
      "step": 1130
    },
    {
      "epoch": 0.6340378197997776,
      "grad_norm": 0.5629649758338928,
      "learning_rate": 4.3665183537263624e-05,
      "loss": 0.3966,
      "step": 1140
    },
    {
      "epoch": 0.639599555061179,
      "grad_norm": 0.6774889230728149,
      "learning_rate": 4.3609566184649615e-05,
      "loss": 0.4283,
      "step": 1150
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 0.5887281894683838,
      "learning_rate": 4.355394883203559e-05,
      "loss": 0.3953,
      "step": 1160
    },
    {
      "epoch": 0.6507230255839822,
      "grad_norm": 0.3944963812828064,
      "learning_rate": 4.3498331479421585e-05,
      "loss": 0.3562,
      "step": 1170
    },
    {
      "epoch": 0.6562847608453838,
      "grad_norm": 0.6555697917938232,
      "learning_rate": 4.344271412680756e-05,
      "loss": 0.3873,
      "step": 1180
    },
    {
      "epoch": 0.6618464961067854,
      "grad_norm": 0.42640528082847595,
      "learning_rate": 4.3387096774193554e-05,
      "loss": 0.5574,
      "step": 1190
    },
    {
      "epoch": 0.6674082313681868,
      "grad_norm": 0.4139012396335602,
      "learning_rate": 4.333147942157953e-05,
      "loss": 0.4517,
      "step": 1200
    },
    {
      "epoch": 0.6729699666295884,
      "grad_norm": 0.6192848086357117,
      "learning_rate": 4.327586206896552e-05,
      "loss": 0.3523,
      "step": 1210
    },
    {
      "epoch": 0.67853170189099,
      "grad_norm": 0.5479583740234375,
      "learning_rate": 4.32202447163515e-05,
      "loss": 0.4448,
      "step": 1220
    },
    {
      "epoch": 0.6840934371523916,
      "grad_norm": 1.1544244289398193,
      "learning_rate": 4.3164627363737486e-05,
      "loss": 0.3721,
      "step": 1230
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 1.193289875984192,
      "learning_rate": 4.310901001112347e-05,
      "loss": 0.3148,
      "step": 1240
    },
    {
      "epoch": 0.6952169076751946,
      "grad_norm": 0.8444048166275024,
      "learning_rate": 4.3053392658509456e-05,
      "loss": 0.4955,
      "step": 1250
    },
    {
      "epoch": 0.7007786429365962,
      "grad_norm": 0.7322465777397156,
      "learning_rate": 4.299777530589544e-05,
      "loss": 0.3467,
      "step": 1260
    },
    {
      "epoch": 0.7063403781979978,
      "grad_norm": 0.3846014142036438,
      "learning_rate": 4.2942157953281426e-05,
      "loss": 0.3233,
      "step": 1270
    },
    {
      "epoch": 0.7119021134593994,
      "grad_norm": 0.47036799788475037,
      "learning_rate": 4.288654060066741e-05,
      "loss": 0.4269,
      "step": 1280
    },
    {
      "epoch": 0.7174638487208009,
      "grad_norm": 0.4217783808708191,
      "learning_rate": 4.2830923248053395e-05,
      "loss": 0.5386,
      "step": 1290
    },
    {
      "epoch": 0.7230255839822024,
      "grad_norm": 0.6481621861457825,
      "learning_rate": 4.277530589543938e-05,
      "loss": 0.3817,
      "step": 1300
    },
    {
      "epoch": 0.728587319243604,
      "grad_norm": 0.5770562887191772,
      "learning_rate": 4.2719688542825365e-05,
      "loss": 0.55,
      "step": 1310
    },
    {
      "epoch": 0.7341490545050056,
      "grad_norm": 1.1048997640609741,
      "learning_rate": 4.266407119021135e-05,
      "loss": 0.3665,
      "step": 1320
    },
    {
      "epoch": 0.7397107897664071,
      "grad_norm": 0.424085795879364,
      "learning_rate": 4.2608453837597334e-05,
      "loss": 0.2845,
      "step": 1330
    },
    {
      "epoch": 0.7452725250278087,
      "grad_norm": 0.5610393285751343,
      "learning_rate": 4.255283648498332e-05,
      "loss": 0.5583,
      "step": 1340
    },
    {
      "epoch": 0.7508342602892102,
      "grad_norm": 0.46805018186569214,
      "learning_rate": 4.2497219132369304e-05,
      "loss": 0.3424,
      "step": 1350
    },
    {
      "epoch": 0.7563959955506118,
      "grad_norm": 0.531815230846405,
      "learning_rate": 4.244160177975529e-05,
      "loss": 0.4237,
      "step": 1360
    },
    {
      "epoch": 0.7619577308120133,
      "grad_norm": 0.5095939636230469,
      "learning_rate": 4.2385984427141266e-05,
      "loss": 0.3709,
      "step": 1370
    },
    {
      "epoch": 0.7675194660734149,
      "grad_norm": 0.4489385485649109,
      "learning_rate": 4.233036707452726e-05,
      "loss": 0.349,
      "step": 1380
    },
    {
      "epoch": 0.7730812013348165,
      "grad_norm": 0.47382667660713196,
      "learning_rate": 4.2274749721913236e-05,
      "loss": 0.5106,
      "step": 1390
    },
    {
      "epoch": 0.778642936596218,
      "grad_norm": 0.610694408416748,
      "learning_rate": 4.221913236929923e-05,
      "loss": 0.3499,
      "step": 1400
    },
    {
      "epoch": 0.7842046718576196,
      "grad_norm": 0.7499902248382568,
      "learning_rate": 4.2163515016685205e-05,
      "loss": 0.4858,
      "step": 1410
    },
    {
      "epoch": 0.7897664071190211,
      "grad_norm": 1.157396912574768,
      "learning_rate": 4.21078976640712e-05,
      "loss": 0.3295,
      "step": 1420
    },
    {
      "epoch": 0.7953281423804227,
      "grad_norm": 0.5032267570495605,
      "learning_rate": 4.2052280311457175e-05,
      "loss": 0.3352,
      "step": 1430
    },
    {
      "epoch": 0.8008898776418243,
      "grad_norm": 0.8629232048988342,
      "learning_rate": 4.1996662958843167e-05,
      "loss": 0.4827,
      "step": 1440
    },
    {
      "epoch": 0.8064516129032258,
      "grad_norm": 0.4805523157119751,
      "learning_rate": 4.1941045606229145e-05,
      "loss": 0.378,
      "step": 1450
    },
    {
      "epoch": 0.8120133481646273,
      "grad_norm": 0.46443015336990356,
      "learning_rate": 4.188542825361513e-05,
      "loss": 0.3333,
      "step": 1460
    },
    {
      "epoch": 0.8175750834260289,
      "grad_norm": 0.4822893738746643,
      "learning_rate": 4.1829810901001114e-05,
      "loss": 0.3391,
      "step": 1470
    },
    {
      "epoch": 0.8231368186874305,
      "grad_norm": 0.3881751298904419,
      "learning_rate": 4.17741935483871e-05,
      "loss": 0.4088,
      "step": 1480
    },
    {
      "epoch": 0.8286985539488321,
      "grad_norm": 0.4930274188518524,
      "learning_rate": 4.1718576195773084e-05,
      "loss": 0.3481,
      "step": 1490
    },
    {
      "epoch": 0.8342602892102335,
      "grad_norm": 0.43815886974334717,
      "learning_rate": 4.166295884315907e-05,
      "loss": 0.3991,
      "step": 1500
    },
    {
      "epoch": 0.8398220244716351,
      "grad_norm": 0.7102105617523193,
      "learning_rate": 4.160734149054505e-05,
      "loss": 0.4389,
      "step": 1510
    },
    {
      "epoch": 0.8453837597330367,
      "grad_norm": 0.5562310814857483,
      "learning_rate": 4.155172413793104e-05,
      "loss": 0.2711,
      "step": 1520
    },
    {
      "epoch": 0.8509454949944383,
      "grad_norm": 0.4435250461101532,
      "learning_rate": 4.1496106785317016e-05,
      "loss": 0.3476,
      "step": 1530
    },
    {
      "epoch": 0.8565072302558399,
      "grad_norm": 0.5407854318618774,
      "learning_rate": 4.144048943270301e-05,
      "loss": 0.3882,
      "step": 1540
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 0.719120442867279,
      "learning_rate": 4.1384872080088985e-05,
      "loss": 0.4602,
      "step": 1550
    },
    {
      "epoch": 0.8676307007786429,
      "grad_norm": 0.4944436252117157,
      "learning_rate": 4.132925472747498e-05,
      "loss": 0.4384,
      "step": 1560
    },
    {
      "epoch": 0.8731924360400445,
      "grad_norm": 0.788714587688446,
      "learning_rate": 4.1273637374860955e-05,
      "loss": 0.4164,
      "step": 1570
    },
    {
      "epoch": 0.8787541713014461,
      "grad_norm": 0.4615589380264282,
      "learning_rate": 4.1218020022246946e-05,
      "loss": 0.407,
      "step": 1580
    },
    {
      "epoch": 0.8843159065628476,
      "grad_norm": 0.672448992729187,
      "learning_rate": 4.1162402669632924e-05,
      "loss": 0.4301,
      "step": 1590
    },
    {
      "epoch": 0.8898776418242491,
      "grad_norm": 0.8902431726455688,
      "learning_rate": 4.1106785317018916e-05,
      "loss": 0.4768,
      "step": 1600
    },
    {
      "epoch": 0.8954393770856507,
      "grad_norm": 0.6040278673171997,
      "learning_rate": 4.1051167964404894e-05,
      "loss": 0.4445,
      "step": 1610
    },
    {
      "epoch": 0.9010011123470523,
      "grad_norm": 0.5574684143066406,
      "learning_rate": 4.099555061179088e-05,
      "loss": 0.3869,
      "step": 1620
    },
    {
      "epoch": 0.9065628476084538,
      "grad_norm": 0.5092565417289734,
      "learning_rate": 4.0939933259176863e-05,
      "loss": 0.4136,
      "step": 1630
    },
    {
      "epoch": 0.9121245828698554,
      "grad_norm": 0.5147649645805359,
      "learning_rate": 4.088431590656285e-05,
      "loss": 0.2837,
      "step": 1640
    },
    {
      "epoch": 0.917686318131257,
      "grad_norm": 0.5927622318267822,
      "learning_rate": 4.082869855394883e-05,
      "loss": 0.3392,
      "step": 1650
    },
    {
      "epoch": 0.9232480533926585,
      "grad_norm": 0.44684404134750366,
      "learning_rate": 4.077308120133482e-05,
      "loss": 0.3387,
      "step": 1660
    },
    {
      "epoch": 0.92880978865406,
      "grad_norm": 0.5862912535667419,
      "learning_rate": 4.07174638487208e-05,
      "loss": 0.3607,
      "step": 1670
    },
    {
      "epoch": 0.9343715239154616,
      "grad_norm": 0.418423593044281,
      "learning_rate": 4.066184649610679e-05,
      "loss": 0.3527,
      "step": 1680
    },
    {
      "epoch": 0.9399332591768632,
      "grad_norm": 0.8193773031234741,
      "learning_rate": 4.060622914349277e-05,
      "loss": 0.3514,
      "step": 1690
    },
    {
      "epoch": 0.9454949944382648,
      "grad_norm": 0.5867600440979004,
      "learning_rate": 4.055061179087876e-05,
      "loss": 0.4102,
      "step": 1700
    },
    {
      "epoch": 0.9510567296996663,
      "grad_norm": 0.5638793110847473,
      "learning_rate": 4.049499443826474e-05,
      "loss": 0.3116,
      "step": 1710
    },
    {
      "epoch": 0.9566184649610678,
      "grad_norm": 0.5291292667388916,
      "learning_rate": 4.0439377085650726e-05,
      "loss": 0.4184,
      "step": 1720
    },
    {
      "epoch": 0.9621802002224694,
      "grad_norm": 0.48514196276664734,
      "learning_rate": 4.038375973303671e-05,
      "loss": 0.3214,
      "step": 1730
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 0.45229464769363403,
      "learning_rate": 4.0328142380422696e-05,
      "loss": 0.3693,
      "step": 1740
    },
    {
      "epoch": 0.9733036707452726,
      "grad_norm": 0.5314483642578125,
      "learning_rate": 4.027252502780868e-05,
      "loss": 0.4396,
      "step": 1750
    },
    {
      "epoch": 0.978865406006674,
      "grad_norm": 0.5113329887390137,
      "learning_rate": 4.0216907675194665e-05,
      "loss": 0.3568,
      "step": 1760
    },
    {
      "epoch": 0.9844271412680756,
      "grad_norm": 0.5526580214500427,
      "learning_rate": 4.016129032258065e-05,
      "loss": 0.3537,
      "step": 1770
    },
    {
      "epoch": 0.9899888765294772,
      "grad_norm": 0.8242576718330383,
      "learning_rate": 4.010567296996663e-05,
      "loss": 0.4204,
      "step": 1780
    },
    {
      "epoch": 0.9955506117908788,
      "grad_norm": 0.7403225898742676,
      "learning_rate": 4.005005561735262e-05,
      "loss": 0.3161,
      "step": 1790
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.33865198493003845,
      "eval_runtime": 7.7342,
      "eval_samples_per_second": 206.744,
      "eval_steps_per_second": 25.859,
      "step": 1798
    },
    {
      "epoch": 1.0011123470522802,
      "grad_norm": 0.3063986897468567,
      "learning_rate": 3.99944382647386e-05,
      "loss": 0.4154,
      "step": 1800
    },
    {
      "epoch": 1.006674082313682,
      "grad_norm": 0.5222868919372559,
      "learning_rate": 3.993882091212459e-05,
      "loss": 0.3954,
      "step": 1810
    },
    {
      "epoch": 1.0122358175750834,
      "grad_norm": 0.9558289051055908,
      "learning_rate": 3.988320355951057e-05,
      "loss": 0.4137,
      "step": 1820
    },
    {
      "epoch": 1.0177975528364849,
      "grad_norm": 0.6086492538452148,
      "learning_rate": 3.982758620689656e-05,
      "loss": 0.3654,
      "step": 1830
    },
    {
      "epoch": 1.0233592880978866,
      "grad_norm": 0.5911427736282349,
      "learning_rate": 3.977196885428254e-05,
      "loss": 0.3135,
      "step": 1840
    },
    {
      "epoch": 1.028921023359288,
      "grad_norm": 0.9360820055007935,
      "learning_rate": 3.971635150166853e-05,
      "loss": 0.4823,
      "step": 1850
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 0.8599550724029541,
      "learning_rate": 3.9660734149054506e-05,
      "loss": 0.2985,
      "step": 1860
    },
    {
      "epoch": 1.0400444938820912,
      "grad_norm": 0.6690285801887512,
      "learning_rate": 3.960511679644049e-05,
      "loss": 0.381,
      "step": 1870
    },
    {
      "epoch": 1.0456062291434929,
      "grad_norm": 0.5986256003379822,
      "learning_rate": 3.9549499443826476e-05,
      "loss": 0.4557,
      "step": 1880
    },
    {
      "epoch": 1.0511679644048944,
      "grad_norm": 0.8614373803138733,
      "learning_rate": 3.949388209121246e-05,
      "loss": 0.3901,
      "step": 1890
    },
    {
      "epoch": 1.0567296996662958,
      "grad_norm": 1.0936628580093384,
      "learning_rate": 3.9438264738598445e-05,
      "loss": 0.3342,
      "step": 1900
    },
    {
      "epoch": 1.0622914349276975,
      "grad_norm": 0.8061587810516357,
      "learning_rate": 3.938264738598443e-05,
      "loss": 0.3813,
      "step": 1910
    },
    {
      "epoch": 1.067853170189099,
      "grad_norm": 0.5879286527633667,
      "learning_rate": 3.9327030033370415e-05,
      "loss": 0.3963,
      "step": 1920
    },
    {
      "epoch": 1.0734149054505004,
      "grad_norm": 0.6047784686088562,
      "learning_rate": 3.92714126807564e-05,
      "loss": 0.3757,
      "step": 1930
    },
    {
      "epoch": 1.0789766407119021,
      "grad_norm": 0.5703405737876892,
      "learning_rate": 3.921579532814238e-05,
      "loss": 0.4126,
      "step": 1940
    },
    {
      "epoch": 1.0845383759733036,
      "grad_norm": 0.7889434695243835,
      "learning_rate": 3.916017797552837e-05,
      "loss": 0.3469,
      "step": 1950
    },
    {
      "epoch": 1.0901001112347053,
      "grad_norm": 0.8621045351028442,
      "learning_rate": 3.910456062291435e-05,
      "loss": 0.4723,
      "step": 1960
    },
    {
      "epoch": 1.0956618464961068,
      "grad_norm": 0.5942044258117676,
      "learning_rate": 3.904894327030034e-05,
      "loss": 0.3718,
      "step": 1970
    },
    {
      "epoch": 1.1012235817575085,
      "grad_norm": 0.5552781820297241,
      "learning_rate": 3.899332591768632e-05,
      "loss": 0.2793,
      "step": 1980
    },
    {
      "epoch": 1.10678531701891,
      "grad_norm": 1.031005620956421,
      "learning_rate": 3.893770856507231e-05,
      "loss": 0.3832,
      "step": 1990
    },
    {
      "epoch": 1.1123470522803114,
      "grad_norm": 0.4598941504955292,
      "learning_rate": 3.8882091212458286e-05,
      "loss": 0.3955,
      "step": 2000
    },
    {
      "epoch": 1.117908787541713,
      "grad_norm": 0.46758389472961426,
      "learning_rate": 3.882647385984428e-05,
      "loss": 0.3144,
      "step": 2010
    },
    {
      "epoch": 1.1234705228031145,
      "grad_norm": 0.6135331988334656,
      "learning_rate": 3.8770856507230256e-05,
      "loss": 0.3431,
      "step": 2020
    },
    {
      "epoch": 1.129032258064516,
      "grad_norm": 0.4081723392009735,
      "learning_rate": 3.871523915461624e-05,
      "loss": 0.2949,
      "step": 2030
    },
    {
      "epoch": 1.1345939933259177,
      "grad_norm": 0.582291841506958,
      "learning_rate": 3.8659621802002225e-05,
      "loss": 0.3012,
      "step": 2040
    },
    {
      "epoch": 1.1401557285873192,
      "grad_norm": 0.38188615441322327,
      "learning_rate": 3.860400444938821e-05,
      "loss": 0.4149,
      "step": 2050
    },
    {
      "epoch": 1.1457174638487209,
      "grad_norm": 0.6009599566459656,
      "learning_rate": 3.8548387096774195e-05,
      "loss": 0.3558,
      "step": 2060
    },
    {
      "epoch": 1.1512791991101223,
      "grad_norm": 0.42074742913246155,
      "learning_rate": 3.849276974416018e-05,
      "loss": 0.3995,
      "step": 2070
    },
    {
      "epoch": 1.156840934371524,
      "grad_norm": 0.3549414575099945,
      "learning_rate": 3.8437152391546164e-05,
      "loss": 0.3639,
      "step": 2080
    },
    {
      "epoch": 1.1624026696329255,
      "grad_norm": 0.38207152485847473,
      "learning_rate": 3.838153503893215e-05,
      "loss": 0.278,
      "step": 2090
    },
    {
      "epoch": 1.167964404894327,
      "grad_norm": 0.8304917812347412,
      "learning_rate": 3.8325917686318134e-05,
      "loss": 0.2405,
      "step": 2100
    },
    {
      "epoch": 1.1735261401557286,
      "grad_norm": 0.6466344594955444,
      "learning_rate": 3.827030033370412e-05,
      "loss": 0.3249,
      "step": 2110
    },
    {
      "epoch": 1.1790878754171301,
      "grad_norm": 0.3486882448196411,
      "learning_rate": 3.8214682981090097e-05,
      "loss": 0.3547,
      "step": 2120
    },
    {
      "epoch": 1.1846496106785316,
      "grad_norm": 0.563267171382904,
      "learning_rate": 3.815906562847609e-05,
      "loss": 0.291,
      "step": 2130
    },
    {
      "epoch": 1.1902113459399333,
      "grad_norm": 0.8568204641342163,
      "learning_rate": 3.8103448275862066e-05,
      "loss": 0.4068,
      "step": 2140
    },
    {
      "epoch": 1.1957730812013347,
      "grad_norm": 0.5818738341331482,
      "learning_rate": 3.804783092324806e-05,
      "loss": 0.265,
      "step": 2150
    },
    {
      "epoch": 1.2013348164627364,
      "grad_norm": 0.5876656770706177,
      "learning_rate": 3.7992213570634036e-05,
      "loss": 0.3064,
      "step": 2160
    },
    {
      "epoch": 1.206896551724138,
      "grad_norm": 0.44836822152137756,
      "learning_rate": 3.793659621802003e-05,
      "loss": 0.3809,
      "step": 2170
    },
    {
      "epoch": 1.2124582869855396,
      "grad_norm": 0.5700399279594421,
      "learning_rate": 3.7880978865406005e-05,
      "loss": 0.2868,
      "step": 2180
    },
    {
      "epoch": 1.218020022246941,
      "grad_norm": 0.6824696063995361,
      "learning_rate": 3.782536151279199e-05,
      "loss": 0.3243,
      "step": 2190
    },
    {
      "epoch": 1.2235817575083425,
      "grad_norm": 0.7518145442008972,
      "learning_rate": 3.7769744160177975e-05,
      "loss": 0.4372,
      "step": 2200
    },
    {
      "epoch": 1.2291434927697442,
      "grad_norm": 0.6504685878753662,
      "learning_rate": 3.771412680756396e-05,
      "loss": 0.3778,
      "step": 2210
    },
    {
      "epoch": 1.2347052280311457,
      "grad_norm": 0.47694864869117737,
      "learning_rate": 3.7658509454949944e-05,
      "loss": 0.3157,
      "step": 2220
    },
    {
      "epoch": 1.2402669632925472,
      "grad_norm": 0.7201205492019653,
      "learning_rate": 3.760289210233593e-05,
      "loss": 0.4114,
      "step": 2230
    },
    {
      "epoch": 1.2458286985539488,
      "grad_norm": 0.4468573033809662,
      "learning_rate": 3.7547274749721914e-05,
      "loss": 0.2908,
      "step": 2240
    },
    {
      "epoch": 1.2513904338153503,
      "grad_norm": 0.48584628105163574,
      "learning_rate": 3.74916573971079e-05,
      "loss": 0.3486,
      "step": 2250
    },
    {
      "epoch": 1.256952169076752,
      "grad_norm": 0.7068109512329102,
      "learning_rate": 3.743604004449388e-05,
      "loss": 0.4044,
      "step": 2260
    },
    {
      "epoch": 1.2625139043381535,
      "grad_norm": 0.39674583077430725,
      "learning_rate": 3.738042269187987e-05,
      "loss": 0.3549,
      "step": 2270
    },
    {
      "epoch": 1.2680756395995552,
      "grad_norm": 0.3126586675643921,
      "learning_rate": 3.732480533926585e-05,
      "loss": 0.3462,
      "step": 2280
    },
    {
      "epoch": 1.2736373748609566,
      "grad_norm": 0.6104019284248352,
      "learning_rate": 3.726918798665184e-05,
      "loss": 0.3216,
      "step": 2290
    },
    {
      "epoch": 1.279199110122358,
      "grad_norm": 0.332522451877594,
      "learning_rate": 3.721357063403782e-05,
      "loss": 0.3608,
      "step": 2300
    },
    {
      "epoch": 1.2847608453837598,
      "grad_norm": 0.35411539673805237,
      "learning_rate": 3.715795328142381e-05,
      "loss": 0.3099,
      "step": 2310
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 0.422325998544693,
      "learning_rate": 3.710233592880979e-05,
      "loss": 0.3866,
      "step": 2320
    },
    {
      "epoch": 1.2958843159065627,
      "grad_norm": 0.571172297000885,
      "learning_rate": 3.7046718576195777e-05,
      "loss": 0.389,
      "step": 2330
    },
    {
      "epoch": 1.3014460511679644,
      "grad_norm": 0.3948937952518463,
      "learning_rate": 3.699110122358176e-05,
      "loss": 0.3937,
      "step": 2340
    },
    {
      "epoch": 1.3070077864293659,
      "grad_norm": 0.5899654626846313,
      "learning_rate": 3.6935483870967746e-05,
      "loss": 0.3584,
      "step": 2350
    },
    {
      "epoch": 1.3125695216907676,
      "grad_norm": 0.6969188451766968,
      "learning_rate": 3.687986651835373e-05,
      "loss": 0.3077,
      "step": 2360
    },
    {
      "epoch": 1.318131256952169,
      "grad_norm": 0.3981521427631378,
      "learning_rate": 3.682424916573971e-05,
      "loss": 0.2872,
      "step": 2370
    },
    {
      "epoch": 1.3236929922135707,
      "grad_norm": 0.7600193023681641,
      "learning_rate": 3.67686318131257e-05,
      "loss": 0.3454,
      "step": 2380
    },
    {
      "epoch": 1.3292547274749722,
      "grad_norm": 0.46623262763023376,
      "learning_rate": 3.671301446051168e-05,
      "loss": 0.3661,
      "step": 2390
    },
    {
      "epoch": 1.3348164627363737,
      "grad_norm": 0.4976073205471039,
      "learning_rate": 3.665739710789767e-05,
      "loss": 0.3527,
      "step": 2400
    },
    {
      "epoch": 1.3403781979977754,
      "grad_norm": 0.5913940668106079,
      "learning_rate": 3.660177975528365e-05,
      "loss": 0.3183,
      "step": 2410
    },
    {
      "epoch": 1.3459399332591768,
      "grad_norm": 0.6436366438865662,
      "learning_rate": 3.654616240266964e-05,
      "loss": 0.3381,
      "step": 2420
    },
    {
      "epoch": 1.3515016685205783,
      "grad_norm": 0.4064256250858307,
      "learning_rate": 3.649054505005562e-05,
      "loss": 0.2834,
      "step": 2430
    },
    {
      "epoch": 1.35706340378198,
      "grad_norm": 0.4143715798854828,
      "learning_rate": 3.64349276974416e-05,
      "loss": 0.2906,
      "step": 2440
    },
    {
      "epoch": 1.3626251390433817,
      "grad_norm": 0.47213083505630493,
      "learning_rate": 3.637931034482759e-05,
      "loss": 0.4043,
      "step": 2450
    },
    {
      "epoch": 1.3681868743047831,
      "grad_norm": 0.8050674200057983,
      "learning_rate": 3.632369299221357e-05,
      "loss": 0.2917,
      "step": 2460
    },
    {
      "epoch": 1.3737486095661846,
      "grad_norm": 0.7422429323196411,
      "learning_rate": 3.6268075639599557e-05,
      "loss": 0.4753,
      "step": 2470
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 0.5038986802101135,
      "learning_rate": 3.621245828698554e-05,
      "loss": 0.355,
      "step": 2480
    },
    {
      "epoch": 1.3848720800889878,
      "grad_norm": 0.4897049069404602,
      "learning_rate": 3.6156840934371526e-05,
      "loss": 0.4136,
      "step": 2490
    },
    {
      "epoch": 1.3904338153503892,
      "grad_norm": 0.2924220561981201,
      "learning_rate": 3.610122358175751e-05,
      "loss": 0.3602,
      "step": 2500
    },
    {
      "epoch": 1.395995550611791,
      "grad_norm": 0.7258354425430298,
      "learning_rate": 3.6045606229143496e-05,
      "loss": 0.3369,
      "step": 2510
    },
    {
      "epoch": 1.4015572858731924,
      "grad_norm": 0.8324310779571533,
      "learning_rate": 3.598998887652948e-05,
      "loss": 0.3957,
      "step": 2520
    },
    {
      "epoch": 1.4071190211345939,
      "grad_norm": 0.3518253564834595,
      "learning_rate": 3.593437152391546e-05,
      "loss": 0.3241,
      "step": 2530
    },
    {
      "epoch": 1.4126807563959956,
      "grad_norm": 0.4542972445487976,
      "learning_rate": 3.587875417130145e-05,
      "loss": 0.3415,
      "step": 2540
    },
    {
      "epoch": 1.4182424916573972,
      "grad_norm": 0.6486878395080566,
      "learning_rate": 3.582313681868743e-05,
      "loss": 0.4145,
      "step": 2550
    },
    {
      "epoch": 1.4238042269187987,
      "grad_norm": 0.525397539138794,
      "learning_rate": 3.576751946607342e-05,
      "loss": 0.3825,
      "step": 2560
    },
    {
      "epoch": 1.4293659621802002,
      "grad_norm": 0.716737687587738,
      "learning_rate": 3.57119021134594e-05,
      "loss": 0.3907,
      "step": 2570
    },
    {
      "epoch": 1.4349276974416019,
      "grad_norm": 0.9611771702766418,
      "learning_rate": 3.565628476084539e-05,
      "loss": 0.487,
      "step": 2580
    },
    {
      "epoch": 1.4404894327030033,
      "grad_norm": 0.5557839274406433,
      "learning_rate": 3.560066740823137e-05,
      "loss": 0.368,
      "step": 2590
    },
    {
      "epoch": 1.4460511679644048,
      "grad_norm": 0.7811416387557983,
      "learning_rate": 3.554505005561735e-05,
      "loss": 0.4691,
      "step": 2600
    },
    {
      "epoch": 1.4516129032258065,
      "grad_norm": 0.5346786975860596,
      "learning_rate": 3.5489432703003336e-05,
      "loss": 0.348,
      "step": 2610
    },
    {
      "epoch": 1.457174638487208,
      "grad_norm": 0.5487717390060425,
      "learning_rate": 3.543381535038932e-05,
      "loss": 0.2981,
      "step": 2620
    },
    {
      "epoch": 1.4627363737486094,
      "grad_norm": 0.6474741101264954,
      "learning_rate": 3.5378197997775306e-05,
      "loss": 0.2545,
      "step": 2630
    },
    {
      "epoch": 1.4682981090100111,
      "grad_norm": 0.5455912947654724,
      "learning_rate": 3.532258064516129e-05,
      "loss": 0.2817,
      "step": 2640
    },
    {
      "epoch": 1.4738598442714128,
      "grad_norm": 0.3703497350215912,
      "learning_rate": 3.5266963292547275e-05,
      "loss": 0.3722,
      "step": 2650
    },
    {
      "epoch": 1.4794215795328143,
      "grad_norm": 0.9890578389167786,
      "learning_rate": 3.521134593993326e-05,
      "loss": 0.301,
      "step": 2660
    },
    {
      "epoch": 1.4849833147942157,
      "grad_norm": 0.5873007774353027,
      "learning_rate": 3.5155728587319245e-05,
      "loss": 0.3559,
      "step": 2670
    },
    {
      "epoch": 1.4905450500556174,
      "grad_norm": 0.3162776529788971,
      "learning_rate": 3.510011123470523e-05,
      "loss": 0.3296,
      "step": 2680
    },
    {
      "epoch": 1.496106785317019,
      "grad_norm": 0.4078555405139923,
      "learning_rate": 3.5044493882091215e-05,
      "loss": 0.4967,
      "step": 2690
    },
    {
      "epoch": 1.5016685205784204,
      "grad_norm": 0.4042895436286926,
      "learning_rate": 3.49888765294772e-05,
      "loss": 0.3121,
      "step": 2700
    },
    {
      "epoch": 1.507230255839822,
      "grad_norm": 0.4066956639289856,
      "learning_rate": 3.4933259176863184e-05,
      "loss": 0.2842,
      "step": 2710
    },
    {
      "epoch": 1.5127919911012235,
      "grad_norm": 0.5290343761444092,
      "learning_rate": 3.487764182424917e-05,
      "loss": 0.4924,
      "step": 2720
    },
    {
      "epoch": 1.518353726362625,
      "grad_norm": 0.6518344283103943,
      "learning_rate": 3.4822024471635154e-05,
      "loss": 0.3708,
      "step": 2730
    },
    {
      "epoch": 1.5239154616240267,
      "grad_norm": 0.4427662789821625,
      "learning_rate": 3.476640711902114e-05,
      "loss": 0.2759,
      "step": 2740
    },
    {
      "epoch": 1.5294771968854284,
      "grad_norm": 0.6113162040710449,
      "learning_rate": 3.471078976640712e-05,
      "loss": 0.3112,
      "step": 2750
    },
    {
      "epoch": 1.5350389321468298,
      "grad_norm": 0.6751188039779663,
      "learning_rate": 3.465517241379311e-05,
      "loss": 0.3999,
      "step": 2760
    },
    {
      "epoch": 1.5406006674082313,
      "grad_norm": 0.3378235399723053,
      "learning_rate": 3.459955506117909e-05,
      "loss": 0.3511,
      "step": 2770
    },
    {
      "epoch": 1.546162402669633,
      "grad_norm": 0.7805290222167969,
      "learning_rate": 3.454393770856507e-05,
      "loss": 0.2808,
      "step": 2780
    },
    {
      "epoch": 1.5517241379310345,
      "grad_norm": 0.3734419047832489,
      "learning_rate": 3.448832035595106e-05,
      "loss": 0.2832,
      "step": 2790
    },
    {
      "epoch": 1.557285873192436,
      "grad_norm": 0.5834055542945862,
      "learning_rate": 3.443270300333704e-05,
      "loss": 0.3509,
      "step": 2800
    },
    {
      "epoch": 1.5628476084538376,
      "grad_norm": 0.7973039746284485,
      "learning_rate": 3.437708565072303e-05,
      "loss": 0.3261,
      "step": 2810
    },
    {
      "epoch": 1.568409343715239,
      "grad_norm": 0.5377610921859741,
      "learning_rate": 3.432146829810901e-05,
      "loss": 0.3625,
      "step": 2820
    },
    {
      "epoch": 1.5739710789766406,
      "grad_norm": 0.26366370916366577,
      "learning_rate": 3.4265850945495e-05,
      "loss": 0.3626,
      "step": 2830
    },
    {
      "epoch": 1.5795328142380423,
      "grad_norm": 0.34524598717689514,
      "learning_rate": 3.421023359288098e-05,
      "loss": 0.287,
      "step": 2840
    },
    {
      "epoch": 1.585094549499444,
      "grad_norm": 0.5130419135093689,
      "learning_rate": 3.4154616240266964e-05,
      "loss": 0.3078,
      "step": 2850
    },
    {
      "epoch": 1.5906562847608454,
      "grad_norm": 0.4247719347476959,
      "learning_rate": 3.409899888765295e-05,
      "loss": 0.2938,
      "step": 2860
    },
    {
      "epoch": 1.5962180200222469,
      "grad_norm": 0.44349947571754456,
      "learning_rate": 3.4043381535038934e-05,
      "loss": 0.3261,
      "step": 2870
    },
    {
      "epoch": 1.6017797552836486,
      "grad_norm": 0.786751389503479,
      "learning_rate": 3.398776418242492e-05,
      "loss": 0.3745,
      "step": 2880
    },
    {
      "epoch": 1.60734149054505,
      "grad_norm": 0.6661301851272583,
      "learning_rate": 3.39321468298109e-05,
      "loss": 0.3418,
      "step": 2890
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 0.5807397365570068,
      "learning_rate": 3.387652947719689e-05,
      "loss": 0.3888,
      "step": 2900
    },
    {
      "epoch": 1.6184649610678532,
      "grad_norm": 0.5463305711746216,
      "learning_rate": 3.382091212458287e-05,
      "loss": 0.2955,
      "step": 2910
    },
    {
      "epoch": 1.624026696329255,
      "grad_norm": 0.6676979660987854,
      "learning_rate": 3.376529477196886e-05,
      "loss": 0.3382,
      "step": 2920
    },
    {
      "epoch": 1.6295884315906561,
      "grad_norm": 0.5821678042411804,
      "learning_rate": 3.370967741935484e-05,
      "loss": 0.2896,
      "step": 2930
    },
    {
      "epoch": 1.6351501668520578,
      "grad_norm": 0.4346933364868164,
      "learning_rate": 3.365406006674082e-05,
      "loss": 0.2658,
      "step": 2940
    },
    {
      "epoch": 1.6407119021134595,
      "grad_norm": 0.5979222655296326,
      "learning_rate": 3.359844271412681e-05,
      "loss": 0.3819,
      "step": 2950
    },
    {
      "epoch": 1.646273637374861,
      "grad_norm": 0.3357214331626892,
      "learning_rate": 3.354282536151279e-05,
      "loss": 0.2852,
      "step": 2960
    },
    {
      "epoch": 1.6518353726362625,
      "grad_norm": 0.45889222621917725,
      "learning_rate": 3.348720800889878e-05,
      "loss": 0.2645,
      "step": 2970
    },
    {
      "epoch": 1.6573971078976641,
      "grad_norm": 0.5672470927238464,
      "learning_rate": 3.343159065628476e-05,
      "loss": 0.3372,
      "step": 2980
    },
    {
      "epoch": 1.6629588431590656,
      "grad_norm": 0.36633434891700745,
      "learning_rate": 3.337597330367075e-05,
      "loss": 0.4661,
      "step": 2990
    },
    {
      "epoch": 1.668520578420467,
      "grad_norm": 0.7521384954452515,
      "learning_rate": 3.332035595105673e-05,
      "loss": 0.3167,
      "step": 3000
    },
    {
      "epoch": 1.6740823136818688,
      "grad_norm": 0.44929105043411255,
      "learning_rate": 3.326473859844272e-05,
      "loss": 0.3068,
      "step": 3010
    },
    {
      "epoch": 1.6796440489432705,
      "grad_norm": 0.49073314666748047,
      "learning_rate": 3.32091212458287e-05,
      "loss": 0.285,
      "step": 3020
    },
    {
      "epoch": 1.6852057842046717,
      "grad_norm": 0.521959662437439,
      "learning_rate": 3.315350389321468e-05,
      "loss": 0.3541,
      "step": 3030
    },
    {
      "epoch": 1.6907675194660734,
      "grad_norm": 0.9121065735816956,
      "learning_rate": 3.309788654060067e-05,
      "loss": 0.435,
      "step": 3040
    },
    {
      "epoch": 1.696329254727475,
      "grad_norm": 0.5925778150558472,
      "learning_rate": 3.304226918798665e-05,
      "loss": 0.3517,
      "step": 3050
    },
    {
      "epoch": 1.7018909899888766,
      "grad_norm": 0.31107839941978455,
      "learning_rate": 3.298665183537264e-05,
      "loss": 0.3143,
      "step": 3060
    },
    {
      "epoch": 1.707452725250278,
      "grad_norm": 0.973663866519928,
      "learning_rate": 3.293103448275862e-05,
      "loss": 0.327,
      "step": 3070
    },
    {
      "epoch": 1.7130144605116797,
      "grad_norm": 0.5858042240142822,
      "learning_rate": 3.287541713014461e-05,
      "loss": 0.3147,
      "step": 3080
    },
    {
      "epoch": 1.7185761957730812,
      "grad_norm": 0.6781976819038391,
      "learning_rate": 3.281979977753059e-05,
      "loss": 0.371,
      "step": 3090
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 0.5680878758430481,
      "learning_rate": 3.2764182424916576e-05,
      "loss": 0.3736,
      "step": 3100
    },
    {
      "epoch": 1.7296996662958843,
      "grad_norm": 0.4811469614505768,
      "learning_rate": 3.270856507230256e-05,
      "loss": 0.3842,
      "step": 3110
    },
    {
      "epoch": 1.735261401557286,
      "grad_norm": 0.6760674118995667,
      "learning_rate": 3.2652947719688546e-05,
      "loss": 0.3319,
      "step": 3120
    },
    {
      "epoch": 1.7408231368186873,
      "grad_norm": 0.5189338326454163,
      "learning_rate": 3.259733036707453e-05,
      "loss": 0.2952,
      "step": 3130
    },
    {
      "epoch": 1.746384872080089,
      "grad_norm": 0.3404560089111328,
      "learning_rate": 3.2541713014460515e-05,
      "loss": 0.349,
      "step": 3140
    },
    {
      "epoch": 1.7519466073414907,
      "grad_norm": 0.7292677164077759,
      "learning_rate": 3.24860956618465e-05,
      "loss": 0.453,
      "step": 3150
    },
    {
      "epoch": 1.7575083426028921,
      "grad_norm": 0.5114433765411377,
      "learning_rate": 3.2430478309232485e-05,
      "loss": 0.2814,
      "step": 3160
    },
    {
      "epoch": 1.7630700778642936,
      "grad_norm": 0.7692161202430725,
      "learning_rate": 3.237486095661847e-05,
      "loss": 0.3473,
      "step": 3170
    },
    {
      "epoch": 1.7686318131256953,
      "grad_norm": 0.34206485748291016,
      "learning_rate": 3.2319243604004454e-05,
      "loss": 0.3547,
      "step": 3180
    },
    {
      "epoch": 1.7741935483870968,
      "grad_norm": 0.3859288692474365,
      "learning_rate": 3.226362625139043e-05,
      "loss": 0.294,
      "step": 3190
    },
    {
      "epoch": 1.7797552836484982,
      "grad_norm": 0.3697267472743988,
      "learning_rate": 3.2208008898776424e-05,
      "loss": 0.3684,
      "step": 3200
    },
    {
      "epoch": 1.7853170189099,
      "grad_norm": 0.48044875264167786,
      "learning_rate": 3.21523915461624e-05,
      "loss": 0.2871,
      "step": 3210
    },
    {
      "epoch": 1.7908787541713016,
      "grad_norm": 0.7217158675193787,
      "learning_rate": 3.2096774193548393e-05,
      "loss": 0.3178,
      "step": 3220
    },
    {
      "epoch": 1.7964404894327028,
      "grad_norm": 1.2176927328109741,
      "learning_rate": 3.204115684093437e-05,
      "loss": 0.3459,
      "step": 3230
    },
    {
      "epoch": 1.8020022246941045,
      "grad_norm": 0.9779223203659058,
      "learning_rate": 3.198553948832036e-05,
      "loss": 0.3666,
      "step": 3240
    },
    {
      "epoch": 1.8075639599555062,
      "grad_norm": 0.35039788484573364,
      "learning_rate": 3.192992213570634e-05,
      "loss": 0.2627,
      "step": 3250
    },
    {
      "epoch": 1.8131256952169077,
      "grad_norm": 0.29079368710517883,
      "learning_rate": 3.1874304783092326e-05,
      "loss": 0.2717,
      "step": 3260
    },
    {
      "epoch": 1.8186874304783092,
      "grad_norm": 0.8480327725410461,
      "learning_rate": 3.181868743047831e-05,
      "loss": 0.3297,
      "step": 3270
    },
    {
      "epoch": 1.8242491657397109,
      "grad_norm": 0.3977685570716858,
      "learning_rate": 3.1763070077864295e-05,
      "loss": 0.3668,
      "step": 3280
    },
    {
      "epoch": 1.8298109010011123,
      "grad_norm": 0.5963373184204102,
      "learning_rate": 3.170745272525028e-05,
      "loss": 0.3261,
      "step": 3290
    },
    {
      "epoch": 1.8353726362625138,
      "grad_norm": 0.5958873629570007,
      "learning_rate": 3.1651835372636265e-05,
      "loss": 0.3161,
      "step": 3300
    },
    {
      "epoch": 1.8409343715239155,
      "grad_norm": 0.8033862709999084,
      "learning_rate": 3.159621802002225e-05,
      "loss": 0.3231,
      "step": 3310
    },
    {
      "epoch": 1.8464961067853172,
      "grad_norm": 0.632763683795929,
      "learning_rate": 3.1540600667408234e-05,
      "loss": 0.3038,
      "step": 3320
    },
    {
      "epoch": 1.8520578420467184,
      "grad_norm": 0.6727837920188904,
      "learning_rate": 3.148498331479422e-05,
      "loss": 0.4765,
      "step": 3330
    },
    {
      "epoch": 1.85761957730812,
      "grad_norm": 0.4918590486049652,
      "learning_rate": 3.1429365962180204e-05,
      "loss": 0.3578,
      "step": 3340
    },
    {
      "epoch": 1.8631813125695218,
      "grad_norm": 0.8530657887458801,
      "learning_rate": 3.137374860956618e-05,
      "loss": 0.3576,
      "step": 3350
    },
    {
      "epoch": 1.8687430478309233,
      "grad_norm": 0.9381269812583923,
      "learning_rate": 3.131813125695217e-05,
      "loss": 0.2599,
      "step": 3360
    },
    {
      "epoch": 1.8743047830923247,
      "grad_norm": 0.43202659487724304,
      "learning_rate": 3.126251390433815e-05,
      "loss": 0.3546,
      "step": 3370
    },
    {
      "epoch": 1.8798665183537264,
      "grad_norm": 0.6839140057563782,
      "learning_rate": 3.120689655172414e-05,
      "loss": 0.366,
      "step": 3380
    },
    {
      "epoch": 1.885428253615128,
      "grad_norm": 0.5051263570785522,
      "learning_rate": 3.115127919911012e-05,
      "loss": 0.2838,
      "step": 3390
    },
    {
      "epoch": 1.8909899888765294,
      "grad_norm": 0.28580111265182495,
      "learning_rate": 3.109566184649611e-05,
      "loss": 0.2793,
      "step": 3400
    },
    {
      "epoch": 1.896551724137931,
      "grad_norm": 0.4199362099170685,
      "learning_rate": 3.104004449388209e-05,
      "loss": 0.2989,
      "step": 3410
    },
    {
      "epoch": 1.9021134593993327,
      "grad_norm": 0.9222924709320068,
      "learning_rate": 3.098442714126808e-05,
      "loss": 0.4035,
      "step": 3420
    },
    {
      "epoch": 1.907675194660734,
      "grad_norm": 0.6960586905479431,
      "learning_rate": 3.092880978865406e-05,
      "loss": 0.2978,
      "step": 3430
    },
    {
      "epoch": 1.9132369299221357,
      "grad_norm": 0.4119293689727783,
      "learning_rate": 3.0873192436040045e-05,
      "loss": 0.3368,
      "step": 3440
    },
    {
      "epoch": 1.9187986651835374,
      "grad_norm": 0.6734881401062012,
      "learning_rate": 3.081757508342603e-05,
      "loss": 0.2759,
      "step": 3450
    },
    {
      "epoch": 1.9243604004449388,
      "grad_norm": 0.75676029920578,
      "learning_rate": 3.0761957730812014e-05,
      "loss": 0.3711,
      "step": 3460
    },
    {
      "epoch": 1.9299221357063403,
      "grad_norm": 0.5862833857536316,
      "learning_rate": 3.0706340378198e-05,
      "loss": 0.3978,
      "step": 3470
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 0.28442955017089844,
      "learning_rate": 3.0650723025583984e-05,
      "loss": 0.3959,
      "step": 3480
    },
    {
      "epoch": 1.9410456062291435,
      "grad_norm": 0.5985276103019714,
      "learning_rate": 3.059510567296997e-05,
      "loss": 0.293,
      "step": 3490
    },
    {
      "epoch": 1.946607341490545,
      "grad_norm": 0.4208459258079529,
      "learning_rate": 3.053948832035595e-05,
      "loss": 0.2539,
      "step": 3500
    },
    {
      "epoch": 1.9521690767519466,
      "grad_norm": 0.633919894695282,
      "learning_rate": 3.0483870967741935e-05,
      "loss": 0.3428,
      "step": 3510
    },
    {
      "epoch": 1.9577308120133483,
      "grad_norm": 0.4037235975265503,
      "learning_rate": 3.0428253615127923e-05,
      "loss": 0.2794,
      "step": 3520
    },
    {
      "epoch": 1.9632925472747496,
      "grad_norm": 0.3854531943798065,
      "learning_rate": 3.0372636262513904e-05,
      "loss": 0.3372,
      "step": 3530
    },
    {
      "epoch": 1.9688542825361512,
      "grad_norm": 0.20015789568424225,
      "learning_rate": 3.0317018909899892e-05,
      "loss": 0.3145,
      "step": 3540
    },
    {
      "epoch": 1.974416017797553,
      "grad_norm": 0.35949617624282837,
      "learning_rate": 3.0261401557285874e-05,
      "loss": 0.3832,
      "step": 3550
    },
    {
      "epoch": 1.9799777530589544,
      "grad_norm": 0.57883220911026,
      "learning_rate": 3.0205784204671862e-05,
      "loss": 0.3051,
      "step": 3560
    },
    {
      "epoch": 1.9855394883203559,
      "grad_norm": 0.4771858751773834,
      "learning_rate": 3.0150166852057843e-05,
      "loss": 0.3687,
      "step": 3570
    },
    {
      "epoch": 1.9911012235817576,
      "grad_norm": 0.8780773282051086,
      "learning_rate": 3.009454949944383e-05,
      "loss": 0.3542,
      "step": 3580
    },
    {
      "epoch": 1.996662958843159,
      "grad_norm": 0.8476621508598328,
      "learning_rate": 3.0038932146829813e-05,
      "loss": 0.33,
      "step": 3590
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.29644086956977844,
      "eval_runtime": 7.7423,
      "eval_samples_per_second": 206.529,
      "eval_steps_per_second": 25.832,
      "step": 3596
    },
    {
      "epoch": 2.0022246941045605,
      "grad_norm": 0.6565834283828735,
      "learning_rate": 2.9983314794215794e-05,
      "loss": 0.3421,
      "step": 3600
    },
    {
      "epoch": 2.007786429365962,
      "grad_norm": 0.828906774520874,
      "learning_rate": 2.9927697441601782e-05,
      "loss": 0.3191,
      "step": 3610
    },
    {
      "epoch": 2.013348164627364,
      "grad_norm": 0.42324283719062805,
      "learning_rate": 2.9872080088987764e-05,
      "loss": 0.3285,
      "step": 3620
    },
    {
      "epoch": 2.018909899888765,
      "grad_norm": 0.5225617289543152,
      "learning_rate": 2.9816462736373752e-05,
      "loss": 0.4115,
      "step": 3630
    },
    {
      "epoch": 2.024471635150167,
      "grad_norm": 0.6363308429718018,
      "learning_rate": 2.9760845383759733e-05,
      "loss": 0.3371,
      "step": 3640
    },
    {
      "epoch": 2.0300333704115685,
      "grad_norm": 0.5477304458618164,
      "learning_rate": 2.970522803114572e-05,
      "loss": 0.384,
      "step": 3650
    },
    {
      "epoch": 2.0355951056729698,
      "grad_norm": 0.5737132430076599,
      "learning_rate": 2.9649610678531703e-05,
      "loss": 0.2532,
      "step": 3660
    },
    {
      "epoch": 2.0411568409343714,
      "grad_norm": 0.7675443291664124,
      "learning_rate": 2.959399332591769e-05,
      "loss": 0.2683,
      "step": 3670
    },
    {
      "epoch": 2.046718576195773,
      "grad_norm": 0.2651255428791046,
      "learning_rate": 2.9538375973303672e-05,
      "loss": 0.3418,
      "step": 3680
    },
    {
      "epoch": 2.052280311457175,
      "grad_norm": 0.43998822569847107,
      "learning_rate": 2.9482758620689654e-05,
      "loss": 0.3313,
      "step": 3690
    },
    {
      "epoch": 2.057842046718576,
      "grad_norm": 0.3999406397342682,
      "learning_rate": 2.9427141268075642e-05,
      "loss": 0.2748,
      "step": 3700
    },
    {
      "epoch": 2.0634037819799778,
      "grad_norm": 0.8072481155395508,
      "learning_rate": 2.9371523915461623e-05,
      "loss": 0.3489,
      "step": 3710
    },
    {
      "epoch": 2.0689655172413794,
      "grad_norm": 0.45708152651786804,
      "learning_rate": 2.931590656284761e-05,
      "loss": 0.3072,
      "step": 3720
    },
    {
      "epoch": 2.0745272525027807,
      "grad_norm": 0.7350027561187744,
      "learning_rate": 2.9260289210233593e-05,
      "loss": 0.3019,
      "step": 3730
    },
    {
      "epoch": 2.0800889877641824,
      "grad_norm": 1.006580114364624,
      "learning_rate": 2.920467185761958e-05,
      "loss": 0.3391,
      "step": 3740
    },
    {
      "epoch": 2.085650723025584,
      "grad_norm": 0.574459433555603,
      "learning_rate": 2.9149054505005562e-05,
      "loss": 0.3106,
      "step": 3750
    },
    {
      "epoch": 2.0912124582869858,
      "grad_norm": 0.33548668026924133,
      "learning_rate": 2.9093437152391544e-05,
      "loss": 0.4595,
      "step": 3760
    },
    {
      "epoch": 2.096774193548387,
      "grad_norm": 0.32520735263824463,
      "learning_rate": 2.9037819799777532e-05,
      "loss": 0.2899,
      "step": 3770
    },
    {
      "epoch": 2.1023359288097887,
      "grad_norm": 0.38086387515068054,
      "learning_rate": 2.8982202447163513e-05,
      "loss": 0.3359,
      "step": 3780
    },
    {
      "epoch": 2.1078976640711904,
      "grad_norm": 0.27096688747406006,
      "learning_rate": 2.89265850945495e-05,
      "loss": 0.3185,
      "step": 3790
    },
    {
      "epoch": 2.1134593993325916,
      "grad_norm": 0.5920576453208923,
      "learning_rate": 2.8870967741935483e-05,
      "loss": 0.2864,
      "step": 3800
    },
    {
      "epoch": 2.1190211345939933,
      "grad_norm": 0.6457786560058594,
      "learning_rate": 2.881535038932147e-05,
      "loss": 0.3229,
      "step": 3810
    },
    {
      "epoch": 2.124582869855395,
      "grad_norm": 0.6809496283531189,
      "learning_rate": 2.8759733036707452e-05,
      "loss": 0.309,
      "step": 3820
    },
    {
      "epoch": 2.1301446051167963,
      "grad_norm": 0.7951372265815735,
      "learning_rate": 2.870411568409344e-05,
      "loss": 0.3192,
      "step": 3830
    },
    {
      "epoch": 2.135706340378198,
      "grad_norm": 0.6940748691558838,
      "learning_rate": 2.8648498331479422e-05,
      "loss": 0.3283,
      "step": 3840
    },
    {
      "epoch": 2.1412680756395996,
      "grad_norm": 0.27250057458877563,
      "learning_rate": 2.8592880978865406e-05,
      "loss": 0.2546,
      "step": 3850
    },
    {
      "epoch": 2.146829810901001,
      "grad_norm": 0.580449104309082,
      "learning_rate": 2.853726362625139e-05,
      "loss": 0.3115,
      "step": 3860
    },
    {
      "epoch": 2.1523915461624026,
      "grad_norm": 0.5843621492385864,
      "learning_rate": 2.8481646273637376e-05,
      "loss": 0.3385,
      "step": 3870
    },
    {
      "epoch": 2.1579532814238043,
      "grad_norm": 0.5251189470291138,
      "learning_rate": 2.842602892102336e-05,
      "loss": 0.2348,
      "step": 3880
    },
    {
      "epoch": 2.163515016685206,
      "grad_norm": 0.46894678473472595,
      "learning_rate": 2.8370411568409346e-05,
      "loss": 0.3119,
      "step": 3890
    },
    {
      "epoch": 2.169076751946607,
      "grad_norm": 0.524830162525177,
      "learning_rate": 2.831479421579533e-05,
      "loss": 0.2647,
      "step": 3900
    },
    {
      "epoch": 2.174638487208009,
      "grad_norm": 0.5115578770637512,
      "learning_rate": 2.8259176863181315e-05,
      "loss": 0.3195,
      "step": 3910
    },
    {
      "epoch": 2.1802002224694106,
      "grad_norm": 0.39812761545181274,
      "learning_rate": 2.8203559510567296e-05,
      "loss": 0.2454,
      "step": 3920
    },
    {
      "epoch": 2.185761957730812,
      "grad_norm": 0.48710310459136963,
      "learning_rate": 2.8147942157953285e-05,
      "loss": 0.3077,
      "step": 3930
    },
    {
      "epoch": 2.1913236929922135,
      "grad_norm": 0.5990920662879944,
      "learning_rate": 2.8092324805339266e-05,
      "loss": 0.3444,
      "step": 3940
    },
    {
      "epoch": 2.196885428253615,
      "grad_norm": 1.1059927940368652,
      "learning_rate": 2.8036707452725254e-05,
      "loss": 0.3327,
      "step": 3950
    },
    {
      "epoch": 2.202447163515017,
      "grad_norm": 0.4871758818626404,
      "learning_rate": 2.7981090100111235e-05,
      "loss": 0.3228,
      "step": 3960
    },
    {
      "epoch": 2.208008898776418,
      "grad_norm": 0.5066546201705933,
      "learning_rate": 2.7925472747497224e-05,
      "loss": 0.3512,
      "step": 3970
    },
    {
      "epoch": 2.21357063403782,
      "grad_norm": 0.48435091972351074,
      "learning_rate": 2.7869855394883205e-05,
      "loss": 0.2992,
      "step": 3980
    },
    {
      "epoch": 2.2191323692992215,
      "grad_norm": 1.0560768842697144,
      "learning_rate": 2.7814238042269193e-05,
      "loss": 0.3143,
      "step": 3990
    },
    {
      "epoch": 2.2246941045606228,
      "grad_norm": 0.7150667309761047,
      "learning_rate": 2.7758620689655175e-05,
      "loss": 0.3146,
      "step": 4000
    },
    {
      "epoch": 2.2302558398220245,
      "grad_norm": 0.4514676332473755,
      "learning_rate": 2.7703003337041156e-05,
      "loss": 0.3313,
      "step": 4010
    },
    {
      "epoch": 2.235817575083426,
      "grad_norm": 0.33152422308921814,
      "learning_rate": 2.7647385984427144e-05,
      "loss": 0.2656,
      "step": 4020
    },
    {
      "epoch": 2.2413793103448274,
      "grad_norm": 0.7027514576911926,
      "learning_rate": 2.7591768631813125e-05,
      "loss": 0.3236,
      "step": 4030
    },
    {
      "epoch": 2.246941045606229,
      "grad_norm": 0.8878405094146729,
      "learning_rate": 2.7536151279199114e-05,
      "loss": 0.4217,
      "step": 4040
    },
    {
      "epoch": 2.252502780867631,
      "grad_norm": 0.5459432005882263,
      "learning_rate": 2.7480533926585095e-05,
      "loss": 0.3448,
      "step": 4050
    },
    {
      "epoch": 2.258064516129032,
      "grad_norm": 0.41620367765426636,
      "learning_rate": 2.7424916573971083e-05,
      "loss": 0.32,
      "step": 4060
    },
    {
      "epoch": 2.2636262513904337,
      "grad_norm": 0.8442811965942383,
      "learning_rate": 2.7369299221357064e-05,
      "loss": 0.2799,
      "step": 4070
    },
    {
      "epoch": 2.2691879866518354,
      "grad_norm": 0.9122823476791382,
      "learning_rate": 2.7313681868743053e-05,
      "loss": 0.2976,
      "step": 4080
    },
    {
      "epoch": 2.274749721913237,
      "grad_norm": 0.30668461322784424,
      "learning_rate": 2.7258064516129034e-05,
      "loss": 0.2607,
      "step": 4090
    },
    {
      "epoch": 2.2803114571746383,
      "grad_norm": 0.42140674591064453,
      "learning_rate": 2.7202447163515015e-05,
      "loss": 0.2323,
      "step": 4100
    },
    {
      "epoch": 2.28587319243604,
      "grad_norm": 0.6691399216651917,
      "learning_rate": 2.7146829810901004e-05,
      "loss": 0.2563,
      "step": 4110
    },
    {
      "epoch": 2.2914349276974417,
      "grad_norm": 0.35367754101753235,
      "learning_rate": 2.7091212458286985e-05,
      "loss": 0.2963,
      "step": 4120
    },
    {
      "epoch": 2.296996662958843,
      "grad_norm": 0.5319297313690186,
      "learning_rate": 2.7035595105672973e-05,
      "loss": 0.3166,
      "step": 4130
    },
    {
      "epoch": 2.3025583982202447,
      "grad_norm": 0.5238839983940125,
      "learning_rate": 2.6979977753058954e-05,
      "loss": 0.2666,
      "step": 4140
    },
    {
      "epoch": 2.3081201334816464,
      "grad_norm": 0.892331063747406,
      "learning_rate": 2.6924360400444943e-05,
      "loss": 0.2771,
      "step": 4150
    },
    {
      "epoch": 2.313681868743048,
      "grad_norm": 0.8743783831596375,
      "learning_rate": 2.6868743047830924e-05,
      "loss": 0.3743,
      "step": 4160
    },
    {
      "epoch": 2.3192436040044493,
      "grad_norm": 0.5410487651824951,
      "learning_rate": 2.6813125695216905e-05,
      "loss": 0.2469,
      "step": 4170
    },
    {
      "epoch": 2.324805339265851,
      "grad_norm": 0.7179416418075562,
      "learning_rate": 2.6757508342602894e-05,
      "loss": 0.3734,
      "step": 4180
    },
    {
      "epoch": 2.3303670745272527,
      "grad_norm": 1.1141636371612549,
      "learning_rate": 2.6701890989988875e-05,
      "loss": 0.3058,
      "step": 4190
    },
    {
      "epoch": 2.335928809788654,
      "grad_norm": 0.49179553985595703,
      "learning_rate": 2.6646273637374863e-05,
      "loss": 0.2796,
      "step": 4200
    },
    {
      "epoch": 2.3414905450500556,
      "grad_norm": 0.47561246156692505,
      "learning_rate": 2.6590656284760844e-05,
      "loss": 0.3028,
      "step": 4210
    },
    {
      "epoch": 2.3470522803114573,
      "grad_norm": 0.48107707500457764,
      "learning_rate": 2.6535038932146833e-05,
      "loss": 0.2513,
      "step": 4220
    },
    {
      "epoch": 2.3526140155728585,
      "grad_norm": 0.6896002888679504,
      "learning_rate": 2.6479421579532814e-05,
      "loss": 0.2977,
      "step": 4230
    },
    {
      "epoch": 2.3581757508342602,
      "grad_norm": 0.5774074792861938,
      "learning_rate": 2.6423804226918802e-05,
      "loss": 0.2548,
      "step": 4240
    },
    {
      "epoch": 2.363737486095662,
      "grad_norm": 0.4751880168914795,
      "learning_rate": 2.6368186874304783e-05,
      "loss": 0.2549,
      "step": 4250
    },
    {
      "epoch": 2.369299221357063,
      "grad_norm": 0.6937139630317688,
      "learning_rate": 2.6312569521690765e-05,
      "loss": 0.395,
      "step": 4260
    },
    {
      "epoch": 2.374860956618465,
      "grad_norm": 0.42943546175956726,
      "learning_rate": 2.6256952169076753e-05,
      "loss": 0.2963,
      "step": 4270
    },
    {
      "epoch": 2.3804226918798665,
      "grad_norm": 0.4748890697956085,
      "learning_rate": 2.6201334816462734e-05,
      "loss": 0.2462,
      "step": 4280
    },
    {
      "epoch": 2.3859844271412682,
      "grad_norm": 0.5876396894454956,
      "learning_rate": 2.6145717463848723e-05,
      "loss": 0.3111,
      "step": 4290
    },
    {
      "epoch": 2.3915461624026695,
      "grad_norm": 0.778855562210083,
      "learning_rate": 2.6090100111234704e-05,
      "loss": 0.3436,
      "step": 4300
    },
    {
      "epoch": 2.397107897664071,
      "grad_norm": 11.594305038452148,
      "learning_rate": 2.6034482758620692e-05,
      "loss": 0.3023,
      "step": 4310
    },
    {
      "epoch": 2.402669632925473,
      "grad_norm": 0.7494487166404724,
      "learning_rate": 2.5978865406006673e-05,
      "loss": 0.2785,
      "step": 4320
    },
    {
      "epoch": 2.408231368186874,
      "grad_norm": 0.6510406136512756,
      "learning_rate": 2.592324805339266e-05,
      "loss": 0.2951,
      "step": 4330
    },
    {
      "epoch": 2.413793103448276,
      "grad_norm": 0.6631435751914978,
      "learning_rate": 2.5867630700778643e-05,
      "loss": 0.4323,
      "step": 4340
    },
    {
      "epoch": 2.4193548387096775,
      "grad_norm": 0.7604230642318726,
      "learning_rate": 2.5812013348164628e-05,
      "loss": 0.1916,
      "step": 4350
    },
    {
      "epoch": 2.424916573971079,
      "grad_norm": 0.7466655373573303,
      "learning_rate": 2.5756395995550612e-05,
      "loss": 0.3782,
      "step": 4360
    },
    {
      "epoch": 2.4304783092324804,
      "grad_norm": 0.6365535855293274,
      "learning_rate": 2.5700778642936597e-05,
      "loss": 0.3843,
      "step": 4370
    },
    {
      "epoch": 2.436040044493882,
      "grad_norm": 0.6661643981933594,
      "learning_rate": 2.5645161290322582e-05,
      "loss": 0.3352,
      "step": 4380
    },
    {
      "epoch": 2.441601779755284,
      "grad_norm": 0.46703198552131653,
      "learning_rate": 2.5589543937708567e-05,
      "loss": 0.3015,
      "step": 4390
    },
    {
      "epoch": 2.447163515016685,
      "grad_norm": 0.6705120205879211,
      "learning_rate": 2.553392658509455e-05,
      "loss": 0.3205,
      "step": 4400
    },
    {
      "epoch": 2.4527252502780867,
      "grad_norm": 0.4873139262199402,
      "learning_rate": 2.5478309232480536e-05,
      "loss": 0.2963,
      "step": 4410
    },
    {
      "epoch": 2.4582869855394884,
      "grad_norm": 0.36834263801574707,
      "learning_rate": 2.5422691879866518e-05,
      "loss": 0.3625,
      "step": 4420
    },
    {
      "epoch": 2.4638487208008897,
      "grad_norm": 0.4247211515903473,
      "learning_rate": 2.5367074527252506e-05,
      "loss": 0.3048,
      "step": 4430
    },
    {
      "epoch": 2.4694104560622914,
      "grad_norm": 0.49534010887145996,
      "learning_rate": 2.5311457174638487e-05,
      "loss": 0.3234,
      "step": 4440
    },
    {
      "epoch": 2.474972191323693,
      "grad_norm": 0.28493115305900574,
      "learning_rate": 2.5255839822024475e-05,
      "loss": 0.2475,
      "step": 4450
    },
    {
      "epoch": 2.4805339265850943,
      "grad_norm": 0.5992431640625,
      "learning_rate": 2.5200222469410457e-05,
      "loss": 0.3541,
      "step": 4460
    },
    {
      "epoch": 2.486095661846496,
      "grad_norm": 0.5492128133773804,
      "learning_rate": 2.5144605116796445e-05,
      "loss": 0.3247,
      "step": 4470
    },
    {
      "epoch": 2.4916573971078977,
      "grad_norm": 0.7400621771812439,
      "learning_rate": 2.5088987764182426e-05,
      "loss": 0.4157,
      "step": 4480
    },
    {
      "epoch": 2.4972191323692994,
      "grad_norm": 0.4210664629936218,
      "learning_rate": 2.5033370411568414e-05,
      "loss": 0.2421,
      "step": 4490
    },
    {
      "epoch": 2.5027808676307006,
      "grad_norm": 0.3838355243206024,
      "learning_rate": 2.4977753058954396e-05,
      "loss": 0.3639,
      "step": 4500
    },
    {
      "epoch": 2.5083426028921023,
      "grad_norm": 0.3961300849914551,
      "learning_rate": 2.492213570634038e-05,
      "loss": 0.3434,
      "step": 4510
    },
    {
      "epoch": 2.513904338153504,
      "grad_norm": 0.6640475988388062,
      "learning_rate": 2.4866518353726365e-05,
      "loss": 0.3107,
      "step": 4520
    },
    {
      "epoch": 2.5194660734149057,
      "grad_norm": 0.9494476914405823,
      "learning_rate": 2.481090100111235e-05,
      "loss": 0.3375,
      "step": 4530
    },
    {
      "epoch": 2.525027808676307,
      "grad_norm": 0.5983530282974243,
      "learning_rate": 2.475528364849833e-05,
      "loss": 0.3006,
      "step": 4540
    },
    {
      "epoch": 2.5305895439377086,
      "grad_norm": 0.7997897863388062,
      "learning_rate": 2.4699666295884316e-05,
      "loss": 0.2834,
      "step": 4550
    },
    {
      "epoch": 2.5361512791991103,
      "grad_norm": 0.7808901071548462,
      "learning_rate": 2.46440489432703e-05,
      "loss": 0.3171,
      "step": 4560
    },
    {
      "epoch": 2.5417130144605116,
      "grad_norm": 0.5921703577041626,
      "learning_rate": 2.4588431590656286e-05,
      "loss": 0.3188,
      "step": 4570
    },
    {
      "epoch": 2.5472747497219133,
      "grad_norm": 0.3785390853881836,
      "learning_rate": 2.453281423804227e-05,
      "loss": 0.3046,
      "step": 4580
    },
    {
      "epoch": 2.552836484983315,
      "grad_norm": 0.4474717974662781,
      "learning_rate": 2.4477196885428255e-05,
      "loss": 0.3041,
      "step": 4590
    },
    {
      "epoch": 2.558398220244716,
      "grad_norm": 0.43443554639816284,
      "learning_rate": 2.442157953281424e-05,
      "loss": 0.3119,
      "step": 4600
    },
    {
      "epoch": 2.563959955506118,
      "grad_norm": 0.4331783056259155,
      "learning_rate": 2.4365962180200225e-05,
      "loss": 0.283,
      "step": 4610
    },
    {
      "epoch": 2.5695216907675196,
      "grad_norm": 0.5129738450050354,
      "learning_rate": 2.4310344827586206e-05,
      "loss": 0.273,
      "step": 4620
    },
    {
      "epoch": 2.575083426028921,
      "grad_norm": 0.4447430670261383,
      "learning_rate": 2.425472747497219e-05,
      "loss": 0.2714,
      "step": 4630
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 0.7246904969215393,
      "learning_rate": 2.4199110122358176e-05,
      "loss": 0.2551,
      "step": 4640
    },
    {
      "epoch": 2.586206896551724,
      "grad_norm": 0.4219615161418915,
      "learning_rate": 2.414349276974416e-05,
      "loss": 0.2106,
      "step": 4650
    },
    {
      "epoch": 2.5917686318131254,
      "grad_norm": 0.453235387802124,
      "learning_rate": 2.4087875417130145e-05,
      "loss": 0.3104,
      "step": 4660
    },
    {
      "epoch": 2.597330367074527,
      "grad_norm": 0.4959390163421631,
      "learning_rate": 2.403225806451613e-05,
      "loss": 0.3424,
      "step": 4670
    },
    {
      "epoch": 2.602892102335929,
      "grad_norm": 0.7213226556777954,
      "learning_rate": 2.3976640711902115e-05,
      "loss": 0.3741,
      "step": 4680
    },
    {
      "epoch": 2.6084538375973305,
      "grad_norm": 0.4586203694343567,
      "learning_rate": 2.39210233592881e-05,
      "loss": 0.3079,
      "step": 4690
    },
    {
      "epoch": 2.6140155728587318,
      "grad_norm": 0.4116736948490143,
      "learning_rate": 2.3865406006674084e-05,
      "loss": 0.2094,
      "step": 4700
    },
    {
      "epoch": 2.6195773081201335,
      "grad_norm": 0.5426535606384277,
      "learning_rate": 2.3809788654060066e-05,
      "loss": 0.4025,
      "step": 4710
    },
    {
      "epoch": 2.625139043381535,
      "grad_norm": 0.566636323928833,
      "learning_rate": 2.375417130144605e-05,
      "loss": 0.3066,
      "step": 4720
    },
    {
      "epoch": 2.630700778642937,
      "grad_norm": 0.38332119584083557,
      "learning_rate": 2.3698553948832035e-05,
      "loss": 0.3032,
      "step": 4730
    },
    {
      "epoch": 2.636262513904338,
      "grad_norm": 0.4623291492462158,
      "learning_rate": 2.364293659621802e-05,
      "loss": 0.2834,
      "step": 4740
    },
    {
      "epoch": 2.6418242491657398,
      "grad_norm": 0.5648987293243408,
      "learning_rate": 2.3587319243604005e-05,
      "loss": 0.2517,
      "step": 4750
    },
    {
      "epoch": 2.6473859844271415,
      "grad_norm": 1.081645131111145,
      "learning_rate": 2.353170189098999e-05,
      "loss": 0.4147,
      "step": 4760
    },
    {
      "epoch": 2.6529477196885427,
      "grad_norm": 0.7176092267036438,
      "learning_rate": 2.3476084538375974e-05,
      "loss": 0.3436,
      "step": 4770
    },
    {
      "epoch": 2.6585094549499444,
      "grad_norm": 0.512687623500824,
      "learning_rate": 2.342046718576196e-05,
      "loss": 0.2883,
      "step": 4780
    },
    {
      "epoch": 2.664071190211346,
      "grad_norm": 0.7942249178886414,
      "learning_rate": 2.3364849833147944e-05,
      "loss": 0.3854,
      "step": 4790
    },
    {
      "epoch": 2.6696329254727473,
      "grad_norm": 0.38134703040122986,
      "learning_rate": 2.3309232480533925e-05,
      "loss": 0.2934,
      "step": 4800
    },
    {
      "epoch": 2.675194660734149,
      "grad_norm": 0.32961779832839966,
      "learning_rate": 2.325361512791991e-05,
      "loss": 0.2489,
      "step": 4810
    },
    {
      "epoch": 2.6807563959955507,
      "grad_norm": 0.5126225352287292,
      "learning_rate": 2.3197997775305895e-05,
      "loss": 0.3471,
      "step": 4820
    },
    {
      "epoch": 2.686318131256952,
      "grad_norm": 0.5253092646598816,
      "learning_rate": 2.314238042269188e-05,
      "loss": 0.313,
      "step": 4830
    },
    {
      "epoch": 2.6918798665183536,
      "grad_norm": 0.4882756769657135,
      "learning_rate": 2.3086763070077864e-05,
      "loss": 0.3379,
      "step": 4840
    },
    {
      "epoch": 2.6974416017797553,
      "grad_norm": 0.5005188584327698,
      "learning_rate": 2.303114571746385e-05,
      "loss": 0.3022,
      "step": 4850
    },
    {
      "epoch": 2.7030033370411566,
      "grad_norm": 0.5631645321846008,
      "learning_rate": 2.2975528364849834e-05,
      "loss": 0.2713,
      "step": 4860
    },
    {
      "epoch": 2.7085650723025583,
      "grad_norm": 0.3518117368221283,
      "learning_rate": 2.291991101223582e-05,
      "loss": 0.2876,
      "step": 4870
    },
    {
      "epoch": 2.71412680756396,
      "grad_norm": 0.6942434906959534,
      "learning_rate": 2.2864293659621803e-05,
      "loss": 0.2705,
      "step": 4880
    },
    {
      "epoch": 2.7196885428253617,
      "grad_norm": 0.5344852805137634,
      "learning_rate": 2.2808676307007788e-05,
      "loss": 0.3261,
      "step": 4890
    },
    {
      "epoch": 2.7252502780867633,
      "grad_norm": 0.5348894596099854,
      "learning_rate": 2.2753058954393773e-05,
      "loss": 0.2917,
      "step": 4900
    },
    {
      "epoch": 2.7308120133481646,
      "grad_norm": 0.462928831577301,
      "learning_rate": 2.2697441601779758e-05,
      "loss": 0.2797,
      "step": 4910
    },
    {
      "epoch": 2.7363737486095663,
      "grad_norm": 0.494804710149765,
      "learning_rate": 2.2641824249165742e-05,
      "loss": 0.3223,
      "step": 4920
    },
    {
      "epoch": 2.741935483870968,
      "grad_norm": 0.7481495141983032,
      "learning_rate": 2.2586206896551727e-05,
      "loss": 0.2938,
      "step": 4930
    },
    {
      "epoch": 2.747497219132369,
      "grad_norm": 0.5019412636756897,
      "learning_rate": 2.2530589543937712e-05,
      "loss": 0.3354,
      "step": 4940
    },
    {
      "epoch": 2.753058954393771,
      "grad_norm": 0.47446760535240173,
      "learning_rate": 2.2474972191323693e-05,
      "loss": 0.2481,
      "step": 4950
    },
    {
      "epoch": 2.7586206896551726,
      "grad_norm": 0.5127977132797241,
      "learning_rate": 2.2419354838709678e-05,
      "loss": 0.2635,
      "step": 4960
    },
    {
      "epoch": 2.764182424916574,
      "grad_norm": 0.9682838320732117,
      "learning_rate": 2.2363737486095663e-05,
      "loss": 0.3434,
      "step": 4970
    },
    {
      "epoch": 2.7697441601779755,
      "grad_norm": 0.5299033522605896,
      "learning_rate": 2.2308120133481647e-05,
      "loss": 0.3095,
      "step": 4980
    },
    {
      "epoch": 2.7753058954393772,
      "grad_norm": 0.4293949604034424,
      "learning_rate": 2.2252502780867632e-05,
      "loss": 0.3161,
      "step": 4990
    },
    {
      "epoch": 2.7808676307007785,
      "grad_norm": 0.636273205280304,
      "learning_rate": 2.2196885428253617e-05,
      "loss": 0.2396,
      "step": 5000
    },
    {
      "epoch": 2.78642936596218,
      "grad_norm": 0.7371332049369812,
      "learning_rate": 2.2141268075639602e-05,
      "loss": 0.3217,
      "step": 5010
    },
    {
      "epoch": 2.791991101223582,
      "grad_norm": 0.3695807158946991,
      "learning_rate": 2.2085650723025587e-05,
      "loss": 0.2941,
      "step": 5020
    },
    {
      "epoch": 2.797552836484983,
      "grad_norm": 0.3285602033138275,
      "learning_rate": 2.203003337041157e-05,
      "loss": 0.3245,
      "step": 5030
    },
    {
      "epoch": 2.803114571746385,
      "grad_norm": 0.49635595083236694,
      "learning_rate": 2.1974416017797553e-05,
      "loss": 0.298,
      "step": 5040
    },
    {
      "epoch": 2.8086763070077865,
      "grad_norm": 0.4975477159023285,
      "learning_rate": 2.1918798665183537e-05,
      "loss": 0.3613,
      "step": 5050
    },
    {
      "epoch": 2.8142380422691877,
      "grad_norm": 0.7325577735900879,
      "learning_rate": 2.1863181312569522e-05,
      "loss": 0.2733,
      "step": 5060
    },
    {
      "epoch": 2.8197997775305894,
      "grad_norm": 0.4198249280452728,
      "learning_rate": 2.1807563959955507e-05,
      "loss": 0.312,
      "step": 5070
    },
    {
      "epoch": 2.825361512791991,
      "grad_norm": 0.3360730707645416,
      "learning_rate": 2.1751946607341492e-05,
      "loss": 0.2123,
      "step": 5080
    },
    {
      "epoch": 2.830923248053393,
      "grad_norm": 0.7444000840187073,
      "learning_rate": 2.1696329254727477e-05,
      "loss": 0.29,
      "step": 5090
    },
    {
      "epoch": 2.8364849833147945,
      "grad_norm": 0.5369381904602051,
      "learning_rate": 2.164071190211346e-05,
      "loss": 0.2822,
      "step": 5100
    },
    {
      "epoch": 2.8420467185761957,
      "grad_norm": 0.6734996438026428,
      "learning_rate": 2.1585094549499446e-05,
      "loss": 0.2619,
      "step": 5110
    },
    {
      "epoch": 2.8476084538375974,
      "grad_norm": 0.6549997925758362,
      "learning_rate": 2.1529477196885427e-05,
      "loss": 0.2944,
      "step": 5120
    },
    {
      "epoch": 2.853170189098999,
      "grad_norm": 0.6293540000915527,
      "learning_rate": 2.1473859844271412e-05,
      "loss": 0.3239,
      "step": 5130
    },
    {
      "epoch": 2.8587319243604004,
      "grad_norm": 0.36297181248664856,
      "learning_rate": 2.1418242491657397e-05,
      "loss": 0.3245,
      "step": 5140
    },
    {
      "epoch": 2.864293659621802,
      "grad_norm": 0.9440492391586304,
      "learning_rate": 2.1362625139043382e-05,
      "loss": 0.3233,
      "step": 5150
    },
    {
      "epoch": 2.8698553948832037,
      "grad_norm": 0.7464049458503723,
      "learning_rate": 2.1307007786429366e-05,
      "loss": 0.2754,
      "step": 5160
    },
    {
      "epoch": 2.875417130144605,
      "grad_norm": 0.51993328332901,
      "learning_rate": 2.125139043381535e-05,
      "loss": 0.2453,
      "step": 5170
    },
    {
      "epoch": 2.8809788654060067,
      "grad_norm": 0.38299670815467834,
      "learning_rate": 2.1195773081201336e-05,
      "loss": 0.3388,
      "step": 5180
    },
    {
      "epoch": 2.8865406006674084,
      "grad_norm": 0.5316861867904663,
      "learning_rate": 2.114015572858732e-05,
      "loss": 0.2828,
      "step": 5190
    },
    {
      "epoch": 2.8921023359288096,
      "grad_norm": 0.4474889934062958,
      "learning_rate": 2.1084538375973302e-05,
      "loss": 0.2523,
      "step": 5200
    },
    {
      "epoch": 2.8976640711902113,
      "grad_norm": 0.5800507664680481,
      "learning_rate": 2.1028921023359287e-05,
      "loss": 0.3393,
      "step": 5210
    },
    {
      "epoch": 2.903225806451613,
      "grad_norm": 0.4646589457988739,
      "learning_rate": 2.097330367074527e-05,
      "loss": 0.3005,
      "step": 5220
    },
    {
      "epoch": 2.9087875417130142,
      "grad_norm": 0.547583281993866,
      "learning_rate": 2.0917686318131256e-05,
      "loss": 0.2449,
      "step": 5230
    },
    {
      "epoch": 2.914349276974416,
      "grad_norm": 0.7818100452423096,
      "learning_rate": 2.086206896551724e-05,
      "loss": 0.3073,
      "step": 5240
    },
    {
      "epoch": 2.9199110122358176,
      "grad_norm": 0.34190478920936584,
      "learning_rate": 2.0806451612903226e-05,
      "loss": 0.2973,
      "step": 5250
    },
    {
      "epoch": 2.925472747497219,
      "grad_norm": 0.4041493237018585,
      "learning_rate": 2.075083426028921e-05,
      "loss": 0.266,
      "step": 5260
    },
    {
      "epoch": 2.9310344827586206,
      "grad_norm": 0.5638554692268372,
      "learning_rate": 2.0695216907675195e-05,
      "loss": 0.2963,
      "step": 5270
    },
    {
      "epoch": 2.9365962180200222,
      "grad_norm": 0.5571335554122925,
      "learning_rate": 2.063959955506118e-05,
      "loss": 0.2256,
      "step": 5280
    },
    {
      "epoch": 2.942157953281424,
      "grad_norm": 0.5855417847633362,
      "learning_rate": 2.0583982202447165e-05,
      "loss": 0.2612,
      "step": 5290
    },
    {
      "epoch": 2.9477196885428256,
      "grad_norm": 0.6027436852455139,
      "learning_rate": 2.052836484983315e-05,
      "loss": 0.2726,
      "step": 5300
    },
    {
      "epoch": 2.953281423804227,
      "grad_norm": 0.2934108376502991,
      "learning_rate": 2.0472747497219135e-05,
      "loss": 0.2856,
      "step": 5310
    },
    {
      "epoch": 2.9588431590656286,
      "grad_norm": 0.4057200849056244,
      "learning_rate": 2.041713014460512e-05,
      "loss": 0.2216,
      "step": 5320
    },
    {
      "epoch": 2.9644048943270302,
      "grad_norm": 0.4901392161846161,
      "learning_rate": 2.0361512791991104e-05,
      "loss": 0.2578,
      "step": 5330
    },
    {
      "epoch": 2.9699666295884315,
      "grad_norm": 0.5371862649917603,
      "learning_rate": 2.030589543937709e-05,
      "loss": 0.345,
      "step": 5340
    },
    {
      "epoch": 2.975528364849833,
      "grad_norm": 0.4985119700431824,
      "learning_rate": 2.0250278086763074e-05,
      "loss": 0.2349,
      "step": 5350
    },
    {
      "epoch": 2.981090100111235,
      "grad_norm": 0.3313044309616089,
      "learning_rate": 2.019466073414906e-05,
      "loss": 0.2281,
      "step": 5360
    },
    {
      "epoch": 2.986651835372636,
      "grad_norm": 0.4395664930343628,
      "learning_rate": 2.013904338153504e-05,
      "loss": 0.2855,
      "step": 5370
    },
    {
      "epoch": 2.992213570634038,
      "grad_norm": 0.9937044382095337,
      "learning_rate": 2.0083426028921024e-05,
      "loss": 0.2931,
      "step": 5380
    },
    {
      "epoch": 2.9977753058954395,
      "grad_norm": 0.4502929151058197,
      "learning_rate": 2.002780867630701e-05,
      "loss": 0.2888,
      "step": 5390
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.275970458984375,
      "eval_runtime": 7.7546,
      "eval_samples_per_second": 206.201,
      "eval_steps_per_second": 25.791,
      "step": 5394
    },
    {
      "epoch": 3.0033370411568407,
      "grad_norm": 0.3982665538787842,
      "learning_rate": 1.9972191323692994e-05,
      "loss": 0.2808,
      "step": 5400
    },
    {
      "epoch": 3.0088987764182424,
      "grad_norm": 0.504086971282959,
      "learning_rate": 1.991657397107898e-05,
      "loss": 0.2578,
      "step": 5410
    },
    {
      "epoch": 3.014460511679644,
      "grad_norm": 0.35994869470596313,
      "learning_rate": 1.9860956618464964e-05,
      "loss": 0.2566,
      "step": 5420
    },
    {
      "epoch": 3.020022246941046,
      "grad_norm": 0.4726756811141968,
      "learning_rate": 1.980533926585095e-05,
      "loss": 0.2778,
      "step": 5430
    },
    {
      "epoch": 3.025583982202447,
      "grad_norm": 0.42021188139915466,
      "learning_rate": 1.9749721913236933e-05,
      "loss": 0.2479,
      "step": 5440
    },
    {
      "epoch": 3.0311457174638488,
      "grad_norm": 0.5566240549087524,
      "learning_rate": 1.9694104560622914e-05,
      "loss": 0.2364,
      "step": 5450
    },
    {
      "epoch": 3.0367074527252504,
      "grad_norm": 0.3847070038318634,
      "learning_rate": 1.96384872080089e-05,
      "loss": 0.252,
      "step": 5460
    },
    {
      "epoch": 3.0422691879866517,
      "grad_norm": 0.607445478439331,
      "learning_rate": 1.9582869855394884e-05,
      "loss": 0.3692,
      "step": 5470
    },
    {
      "epoch": 3.0478309232480534,
      "grad_norm": 0.6815561056137085,
      "learning_rate": 1.952725250278087e-05,
      "loss": 0.3417,
      "step": 5480
    },
    {
      "epoch": 3.053392658509455,
      "grad_norm": 0.5369429588317871,
      "learning_rate": 1.9471635150166854e-05,
      "loss": 0.3454,
      "step": 5490
    },
    {
      "epoch": 3.0589543937708563,
      "grad_norm": 0.5550341010093689,
      "learning_rate": 1.9416017797552838e-05,
      "loss": 0.3291,
      "step": 5500
    },
    {
      "epoch": 3.064516129032258,
      "grad_norm": 0.6055121421813965,
      "learning_rate": 1.9360400444938823e-05,
      "loss": 0.2631,
      "step": 5510
    },
    {
      "epoch": 3.0700778642936597,
      "grad_norm": 0.40118375420570374,
      "learning_rate": 1.9304783092324808e-05,
      "loss": 0.2288,
      "step": 5520
    },
    {
      "epoch": 3.0756395995550614,
      "grad_norm": 0.6970715522766113,
      "learning_rate": 1.924916573971079e-05,
      "loss": 0.3413,
      "step": 5530
    },
    {
      "epoch": 3.0812013348164626,
      "grad_norm": 0.44519275426864624,
      "learning_rate": 1.9193548387096774e-05,
      "loss": 0.2878,
      "step": 5540
    },
    {
      "epoch": 3.0867630700778643,
      "grad_norm": 0.4447636008262634,
      "learning_rate": 1.913793103448276e-05,
      "loss": 0.2547,
      "step": 5550
    },
    {
      "epoch": 3.092324805339266,
      "grad_norm": 0.2371000051498413,
      "learning_rate": 1.9082313681868743e-05,
      "loss": 0.2181,
      "step": 5560
    },
    {
      "epoch": 3.0978865406006673,
      "grad_norm": 0.5751253366470337,
      "learning_rate": 1.9026696329254728e-05,
      "loss": 0.2728,
      "step": 5570
    },
    {
      "epoch": 3.103448275862069,
      "grad_norm": 0.5138014554977417,
      "learning_rate": 1.8971078976640713e-05,
      "loss": 0.2775,
      "step": 5580
    },
    {
      "epoch": 3.1090100111234706,
      "grad_norm": 0.6782065629959106,
      "learning_rate": 1.8915461624026698e-05,
      "loss": 0.2805,
      "step": 5590
    },
    {
      "epoch": 3.114571746384872,
      "grad_norm": 0.3815062940120697,
      "learning_rate": 1.8859844271412683e-05,
      "loss": 0.2343,
      "step": 5600
    },
    {
      "epoch": 3.1201334816462736,
      "grad_norm": 0.34506091475486755,
      "learning_rate": 1.8804226918798664e-05,
      "loss": 0.2271,
      "step": 5610
    },
    {
      "epoch": 3.1256952169076753,
      "grad_norm": 0.7922946214675903,
      "learning_rate": 1.874860956618465e-05,
      "loss": 0.2996,
      "step": 5620
    },
    {
      "epoch": 3.131256952169077,
      "grad_norm": 0.5550018548965454,
      "learning_rate": 1.8692992213570633e-05,
      "loss": 0.3115,
      "step": 5630
    },
    {
      "epoch": 3.136818687430478,
      "grad_norm": 0.8743687272071838,
      "learning_rate": 1.8637374860956618e-05,
      "loss": 0.3471,
      "step": 5640
    },
    {
      "epoch": 3.14238042269188,
      "grad_norm": 0.3638781011104584,
      "learning_rate": 1.8581757508342603e-05,
      "loss": 0.2349,
      "step": 5650
    },
    {
      "epoch": 3.1479421579532816,
      "grad_norm": 0.5084483623504639,
      "learning_rate": 1.8526140155728588e-05,
      "loss": 0.2592,
      "step": 5660
    },
    {
      "epoch": 3.153503893214683,
      "grad_norm": 0.3028697371482849,
      "learning_rate": 1.8470522803114572e-05,
      "loss": 0.2166,
      "step": 5670
    },
    {
      "epoch": 3.1590656284760845,
      "grad_norm": 0.39634421467781067,
      "learning_rate": 1.8414905450500557e-05,
      "loss": 0.3246,
      "step": 5680
    },
    {
      "epoch": 3.164627363737486,
      "grad_norm": 0.39526572823524475,
      "learning_rate": 1.8359288097886542e-05,
      "loss": 0.3121,
      "step": 5690
    },
    {
      "epoch": 3.1701890989988875,
      "grad_norm": 1.0239145755767822,
      "learning_rate": 1.8303670745272523e-05,
      "loss": 0.3006,
      "step": 5700
    },
    {
      "epoch": 3.175750834260289,
      "grad_norm": 0.7521277666091919,
      "learning_rate": 1.8248053392658508e-05,
      "loss": 0.3068,
      "step": 5710
    },
    {
      "epoch": 3.181312569521691,
      "grad_norm": 0.40550458431243896,
      "learning_rate": 1.8192436040044493e-05,
      "loss": 0.2499,
      "step": 5720
    },
    {
      "epoch": 3.1868743047830925,
      "grad_norm": 0.38309547305107117,
      "learning_rate": 1.8136818687430478e-05,
      "loss": 0.3224,
      "step": 5730
    },
    {
      "epoch": 3.1924360400444938,
      "grad_norm": 0.3349187970161438,
      "learning_rate": 1.8081201334816462e-05,
      "loss": 0.2652,
      "step": 5740
    },
    {
      "epoch": 3.1979977753058955,
      "grad_norm": 0.6720588803291321,
      "learning_rate": 1.8025583982202447e-05,
      "loss": 0.2578,
      "step": 5750
    },
    {
      "epoch": 3.203559510567297,
      "grad_norm": 0.5635179281234741,
      "learning_rate": 1.7969966629588432e-05,
      "loss": 0.284,
      "step": 5760
    },
    {
      "epoch": 3.2091212458286984,
      "grad_norm": 0.455527126789093,
      "learning_rate": 1.7914349276974417e-05,
      "loss": 0.2443,
      "step": 5770
    },
    {
      "epoch": 3.2146829810901,
      "grad_norm": 0.5120125412940979,
      "learning_rate": 1.78587319243604e-05,
      "loss": 0.2049,
      "step": 5780
    },
    {
      "epoch": 3.220244716351502,
      "grad_norm": 0.3104175925254822,
      "learning_rate": 1.7803114571746386e-05,
      "loss": 0.2499,
      "step": 5790
    },
    {
      "epoch": 3.225806451612903,
      "grad_norm": 0.4725671708583832,
      "learning_rate": 1.774749721913237e-05,
      "loss": 0.2827,
      "step": 5800
    },
    {
      "epoch": 3.2313681868743047,
      "grad_norm": 0.9432892799377441,
      "learning_rate": 1.7691879866518356e-05,
      "loss": 0.3594,
      "step": 5810
    },
    {
      "epoch": 3.2369299221357064,
      "grad_norm": 0.4989311099052429,
      "learning_rate": 1.763626251390434e-05,
      "loss": 0.2387,
      "step": 5820
    },
    {
      "epoch": 3.242491657397108,
      "grad_norm": 0.44322502613067627,
      "learning_rate": 1.7580645161290325e-05,
      "loss": 0.2595,
      "step": 5830
    },
    {
      "epoch": 3.2480533926585093,
      "grad_norm": 0.5886087417602539,
      "learning_rate": 1.752502780867631e-05,
      "loss": 0.2326,
      "step": 5840
    },
    {
      "epoch": 3.253615127919911,
      "grad_norm": 0.30832433700561523,
      "learning_rate": 1.7469410456062295e-05,
      "loss": 0.2496,
      "step": 5850
    },
    {
      "epoch": 3.2591768631813127,
      "grad_norm": 0.6036310195922852,
      "learning_rate": 1.7413793103448276e-05,
      "loss": 0.3494,
      "step": 5860
    },
    {
      "epoch": 3.264738598442714,
      "grad_norm": 0.4508431553840637,
      "learning_rate": 1.735817575083426e-05,
      "loss": 0.2622,
      "step": 5870
    },
    {
      "epoch": 3.2703003337041157,
      "grad_norm": 0.5272798538208008,
      "learning_rate": 1.7302558398220246e-05,
      "loss": 0.3933,
      "step": 5880
    },
    {
      "epoch": 3.2758620689655173,
      "grad_norm": 0.38335224986076355,
      "learning_rate": 1.724694104560623e-05,
      "loss": 0.2043,
      "step": 5890
    },
    {
      "epoch": 3.281423804226919,
      "grad_norm": 0.5937448740005493,
      "learning_rate": 1.7191323692992215e-05,
      "loss": 0.2525,
      "step": 5900
    },
    {
      "epoch": 3.2869855394883203,
      "grad_norm": 0.32590746879577637,
      "learning_rate": 1.71357063403782e-05,
      "loss": 0.3345,
      "step": 5910
    },
    {
      "epoch": 3.292547274749722,
      "grad_norm": 0.5215027332305908,
      "learning_rate": 1.7080088987764185e-05,
      "loss": 0.3049,
      "step": 5920
    },
    {
      "epoch": 3.2981090100111237,
      "grad_norm": 0.7927533984184265,
      "learning_rate": 1.702447163515017e-05,
      "loss": 0.3013,
      "step": 5930
    },
    {
      "epoch": 3.303670745272525,
      "grad_norm": 0.4142560660839081,
      "learning_rate": 1.696885428253615e-05,
      "loss": 0.2611,
      "step": 5940
    },
    {
      "epoch": 3.3092324805339266,
      "grad_norm": 0.4095122516155243,
      "learning_rate": 1.6913236929922136e-05,
      "loss": 0.2437,
      "step": 5950
    },
    {
      "epoch": 3.3147942157953283,
      "grad_norm": 0.5396614670753479,
      "learning_rate": 1.685761957730812e-05,
      "loss": 0.3163,
      "step": 5960
    },
    {
      "epoch": 3.3203559510567295,
      "grad_norm": 0.645285427570343,
      "learning_rate": 1.6802002224694105e-05,
      "loss": 0.325,
      "step": 5970
    },
    {
      "epoch": 3.3259176863181312,
      "grad_norm": 0.668375551700592,
      "learning_rate": 1.674638487208009e-05,
      "loss": 0.3176,
      "step": 5980
    },
    {
      "epoch": 3.331479421579533,
      "grad_norm": 0.5375426411628723,
      "learning_rate": 1.6690767519466075e-05,
      "loss": 0.3741,
      "step": 5990
    },
    {
      "epoch": 3.337041156840934,
      "grad_norm": 0.4849614202976227,
      "learning_rate": 1.663515016685206e-05,
      "loss": 0.3456,
      "step": 6000
    },
    {
      "epoch": 3.342602892102336,
      "grad_norm": 0.5335557460784912,
      "learning_rate": 1.6579532814238044e-05,
      "loss": 0.3439,
      "step": 6010
    },
    {
      "epoch": 3.3481646273637375,
      "grad_norm": 0.3601972460746765,
      "learning_rate": 1.652391546162403e-05,
      "loss": 0.2821,
      "step": 6020
    },
    {
      "epoch": 3.3537263626251392,
      "grad_norm": 0.38230594992637634,
      "learning_rate": 1.646829810901001e-05,
      "loss": 0.2624,
      "step": 6030
    },
    {
      "epoch": 3.3592880978865405,
      "grad_norm": 0.6920782923698425,
      "learning_rate": 1.6412680756395995e-05,
      "loss": 0.2349,
      "step": 6040
    },
    {
      "epoch": 3.364849833147942,
      "grad_norm": 0.6906844973564148,
      "learning_rate": 1.635706340378198e-05,
      "loss": 0.3265,
      "step": 6050
    },
    {
      "epoch": 3.370411568409344,
      "grad_norm": 0.49798086285591125,
      "learning_rate": 1.6301446051167965e-05,
      "loss": 0.2532,
      "step": 6060
    },
    {
      "epoch": 3.375973303670745,
      "grad_norm": 0.7574018836021423,
      "learning_rate": 1.624582869855395e-05,
      "loss": 0.3272,
      "step": 6070
    },
    {
      "epoch": 3.381535038932147,
      "grad_norm": 0.8255133628845215,
      "learning_rate": 1.6190211345939934e-05,
      "loss": 0.3201,
      "step": 6080
    },
    {
      "epoch": 3.3870967741935485,
      "grad_norm": 0.6826974749565125,
      "learning_rate": 1.613459399332592e-05,
      "loss": 0.3629,
      "step": 6090
    },
    {
      "epoch": 3.39265850945495,
      "grad_norm": 0.28046301007270813,
      "learning_rate": 1.6078976640711904e-05,
      "loss": 0.2515,
      "step": 6100
    },
    {
      "epoch": 3.3982202447163514,
      "grad_norm": 0.3713831603527069,
      "learning_rate": 1.6023359288097885e-05,
      "loss": 0.3074,
      "step": 6110
    },
    {
      "epoch": 3.403781979977753,
      "grad_norm": 0.7380386590957642,
      "learning_rate": 1.596774193548387e-05,
      "loss": 0.3109,
      "step": 6120
    },
    {
      "epoch": 3.409343715239155,
      "grad_norm": 0.6065388321876526,
      "learning_rate": 1.5912124582869855e-05,
      "loss": 0.241,
      "step": 6130
    },
    {
      "epoch": 3.414905450500556,
      "grad_norm": 0.3588167726993561,
      "learning_rate": 1.585650723025584e-05,
      "loss": 0.2993,
      "step": 6140
    },
    {
      "epoch": 3.4204671857619577,
      "grad_norm": 0.3554551303386688,
      "learning_rate": 1.5800889877641824e-05,
      "loss": 0.2121,
      "step": 6150
    },
    {
      "epoch": 3.4260289210233594,
      "grad_norm": 0.3354300260543823,
      "learning_rate": 1.574527252502781e-05,
      "loss": 0.2523,
      "step": 6160
    },
    {
      "epoch": 3.4315906562847607,
      "grad_norm": 0.7114141583442688,
      "learning_rate": 1.5689655172413794e-05,
      "loss": 0.3206,
      "step": 6170
    },
    {
      "epoch": 3.4371523915461624,
      "grad_norm": 0.6052894592285156,
      "learning_rate": 1.563403781979978e-05,
      "loss": 0.2837,
      "step": 6180
    },
    {
      "epoch": 3.442714126807564,
      "grad_norm": 0.436826229095459,
      "learning_rate": 1.557842046718576e-05,
      "loss": 0.2395,
      "step": 6190
    },
    {
      "epoch": 3.4482758620689653,
      "grad_norm": 0.2798926830291748,
      "learning_rate": 1.5522803114571745e-05,
      "loss": 0.2421,
      "step": 6200
    },
    {
      "epoch": 3.453837597330367,
      "grad_norm": 0.5067792534828186,
      "learning_rate": 1.546718576195773e-05,
      "loss": 0.2377,
      "step": 6210
    },
    {
      "epoch": 3.4593993325917687,
      "grad_norm": 0.5032324194908142,
      "learning_rate": 1.5411568409343714e-05,
      "loss": 0.2912,
      "step": 6220
    },
    {
      "epoch": 3.4649610678531704,
      "grad_norm": 0.5339304804801941,
      "learning_rate": 1.53559510567297e-05,
      "loss": 0.3579,
      "step": 6230
    },
    {
      "epoch": 3.4705228031145716,
      "grad_norm": 0.5287632346153259,
      "learning_rate": 1.5300333704115684e-05,
      "loss": 0.2488,
      "step": 6240
    },
    {
      "epoch": 3.4760845383759733,
      "grad_norm": 0.4856431484222412,
      "learning_rate": 1.524471635150167e-05,
      "loss": 0.3311,
      "step": 6250
    },
    {
      "epoch": 3.481646273637375,
      "grad_norm": 0.44326603412628174,
      "learning_rate": 1.5189098998887655e-05,
      "loss": 0.3102,
      "step": 6260
    },
    {
      "epoch": 3.4872080088987762,
      "grad_norm": 0.8452295660972595,
      "learning_rate": 1.5133481646273636e-05,
      "loss": 0.2655,
      "step": 6270
    },
    {
      "epoch": 3.492769744160178,
      "grad_norm": 0.5876279473304749,
      "learning_rate": 1.5077864293659621e-05,
      "loss": 0.2712,
      "step": 6280
    },
    {
      "epoch": 3.4983314794215796,
      "grad_norm": 0.6162927150726318,
      "learning_rate": 1.5022246941045606e-05,
      "loss": 0.3596,
      "step": 6290
    },
    {
      "epoch": 3.5038932146829813,
      "grad_norm": 0.46566519141197205,
      "learning_rate": 1.496662958843159e-05,
      "loss": 0.3193,
      "step": 6300
    },
    {
      "epoch": 3.5094549499443826,
      "grad_norm": 0.5399209260940552,
      "learning_rate": 1.4911012235817575e-05,
      "loss": 0.3402,
      "step": 6310
    },
    {
      "epoch": 3.5150166852057843,
      "grad_norm": 0.32203543186187744,
      "learning_rate": 1.485539488320356e-05,
      "loss": 0.2628,
      "step": 6320
    },
    {
      "epoch": 3.520578420467186,
      "grad_norm": 0.7334842681884766,
      "learning_rate": 1.4799777530589545e-05,
      "loss": 0.2712,
      "step": 6330
    },
    {
      "epoch": 3.526140155728587,
      "grad_norm": 0.28820645809173584,
      "learning_rate": 1.474416017797553e-05,
      "loss": 0.2804,
      "step": 6340
    },
    {
      "epoch": 3.531701890989989,
      "grad_norm": 0.4364497661590576,
      "learning_rate": 1.4688542825361514e-05,
      "loss": 0.2393,
      "step": 6350
    },
    {
      "epoch": 3.5372636262513906,
      "grad_norm": 0.535742461681366,
      "learning_rate": 1.4632925472747497e-05,
      "loss": 0.2755,
      "step": 6360
    },
    {
      "epoch": 3.542825361512792,
      "grad_norm": 0.2688031494617462,
      "learning_rate": 1.4577308120133482e-05,
      "loss": 0.361,
      "step": 6370
    },
    {
      "epoch": 3.5483870967741935,
      "grad_norm": 0.4290085732936859,
      "learning_rate": 1.4521690767519467e-05,
      "loss": 0.3456,
      "step": 6380
    },
    {
      "epoch": 3.553948832035595,
      "grad_norm": 0.4980129599571228,
      "learning_rate": 1.4466073414905452e-05,
      "loss": 0.2843,
      "step": 6390
    },
    {
      "epoch": 3.5595105672969964,
      "grad_norm": 0.6348577737808228,
      "learning_rate": 1.4410456062291437e-05,
      "loss": 0.3484,
      "step": 6400
    },
    {
      "epoch": 3.565072302558398,
      "grad_norm": 0.45133620500564575,
      "learning_rate": 1.4354838709677421e-05,
      "loss": 0.2879,
      "step": 6410
    },
    {
      "epoch": 3.5706340378198,
      "grad_norm": 0.3938741385936737,
      "learning_rate": 1.4299221357063406e-05,
      "loss": 0.218,
      "step": 6420
    },
    {
      "epoch": 3.576195773081201,
      "grad_norm": 0.536990761756897,
      "learning_rate": 1.424360400444939e-05,
      "loss": 0.2902,
      "step": 6430
    },
    {
      "epoch": 3.5817575083426028,
      "grad_norm": 0.6745401620864868,
      "learning_rate": 1.4187986651835372e-05,
      "loss": 0.2515,
      "step": 6440
    },
    {
      "epoch": 3.5873192436040044,
      "grad_norm": 0.6024802923202515,
      "learning_rate": 1.4132369299221357e-05,
      "loss": 0.2658,
      "step": 6450
    },
    {
      "epoch": 3.592880978865406,
      "grad_norm": 0.4318884015083313,
      "learning_rate": 1.4076751946607342e-05,
      "loss": 0.2598,
      "step": 6460
    },
    {
      "epoch": 3.598442714126808,
      "grad_norm": 0.33953019976615906,
      "learning_rate": 1.4021134593993326e-05,
      "loss": 0.2258,
      "step": 6470
    },
    {
      "epoch": 3.604004449388209,
      "grad_norm": 0.5018320679664612,
      "learning_rate": 1.3965517241379311e-05,
      "loss": 0.2448,
      "step": 6480
    },
    {
      "epoch": 3.6095661846496108,
      "grad_norm": 0.48757195472717285,
      "learning_rate": 1.3909899888765296e-05,
      "loss": 0.2235,
      "step": 6490
    },
    {
      "epoch": 3.6151279199110125,
      "grad_norm": 0.8026221990585327,
      "learning_rate": 1.385428253615128e-05,
      "loss": 0.2642,
      "step": 6500
    },
    {
      "epoch": 3.6206896551724137,
      "grad_norm": 0.38843104243278503,
      "learning_rate": 1.3798665183537266e-05,
      "loss": 0.3387,
      "step": 6510
    },
    {
      "epoch": 3.6262513904338154,
      "grad_norm": 0.4858226776123047,
      "learning_rate": 1.3743047830923247e-05,
      "loss": 0.223,
      "step": 6520
    },
    {
      "epoch": 3.631813125695217,
      "grad_norm": 0.3844059705734253,
      "learning_rate": 1.3687430478309232e-05,
      "loss": 0.3267,
      "step": 6530
    },
    {
      "epoch": 3.6373748609566183,
      "grad_norm": 0.6333187818527222,
      "learning_rate": 1.3631813125695216e-05,
      "loss": 0.2368,
      "step": 6540
    },
    {
      "epoch": 3.64293659621802,
      "grad_norm": 0.8575846552848816,
      "learning_rate": 1.3576195773081201e-05,
      "loss": 0.267,
      "step": 6550
    },
    {
      "epoch": 3.6484983314794217,
      "grad_norm": 0.34393125772476196,
      "learning_rate": 1.3520578420467186e-05,
      "loss": 0.3503,
      "step": 6560
    },
    {
      "epoch": 3.654060066740823,
      "grad_norm": 0.47978076338768005,
      "learning_rate": 1.346496106785317e-05,
      "loss": 0.3055,
      "step": 6570
    },
    {
      "epoch": 3.6596218020022246,
      "grad_norm": 0.6353543400764465,
      "learning_rate": 1.3409343715239155e-05,
      "loss": 0.2463,
      "step": 6580
    },
    {
      "epoch": 3.6651835372636263,
      "grad_norm": 0.7881833910942078,
      "learning_rate": 1.335372636262514e-05,
      "loss": 0.3631,
      "step": 6590
    },
    {
      "epoch": 3.6707452725250276,
      "grad_norm": 0.8629505634307861,
      "learning_rate": 1.3298109010011123e-05,
      "loss": 0.3021,
      "step": 6600
    },
    {
      "epoch": 3.6763070077864293,
      "grad_norm": 0.18300512433052063,
      "learning_rate": 1.3242491657397108e-05,
      "loss": 0.195,
      "step": 6610
    },
    {
      "epoch": 3.681868743047831,
      "grad_norm": 0.3462485074996948,
      "learning_rate": 1.3186874304783093e-05,
      "loss": 0.2384,
      "step": 6620
    },
    {
      "epoch": 3.687430478309232,
      "grad_norm": 0.43102720379829407,
      "learning_rate": 1.3131256952169078e-05,
      "loss": 0.3145,
      "step": 6630
    },
    {
      "epoch": 3.692992213570634,
      "grad_norm": 0.4897254705429077,
      "learning_rate": 1.3075639599555062e-05,
      "loss": 0.2107,
      "step": 6640
    },
    {
      "epoch": 3.6985539488320356,
      "grad_norm": 0.27225202322006226,
      "learning_rate": 1.3020022246941047e-05,
      "loss": 0.2336,
      "step": 6650
    },
    {
      "epoch": 3.7041156840934373,
      "grad_norm": 0.8807904124259949,
      "learning_rate": 1.2964404894327032e-05,
      "loss": 0.3868,
      "step": 6660
    },
    {
      "epoch": 3.709677419354839,
      "grad_norm": 0.8123050332069397,
      "learning_rate": 1.2908787541713017e-05,
      "loss": 0.2904,
      "step": 6670
    },
    {
      "epoch": 3.71523915461624,
      "grad_norm": 0.27907365560531616,
      "learning_rate": 1.2853170189099001e-05,
      "loss": 0.2791,
      "step": 6680
    },
    {
      "epoch": 3.720800889877642,
      "grad_norm": 0.6538630127906799,
      "learning_rate": 1.2797552836484983e-05,
      "loss": 0.347,
      "step": 6690
    },
    {
      "epoch": 3.7263626251390436,
      "grad_norm": 0.5137282013893127,
      "learning_rate": 1.2741935483870968e-05,
      "loss": 0.2714,
      "step": 6700
    },
    {
      "epoch": 3.731924360400445,
      "grad_norm": 0.3284044563770294,
      "learning_rate": 1.2686318131256952e-05,
      "loss": 0.2697,
      "step": 6710
    },
    {
      "epoch": 3.7374860956618465,
      "grad_norm": 0.5369620323181152,
      "learning_rate": 1.2630700778642937e-05,
      "loss": 0.2331,
      "step": 6720
    },
    {
      "epoch": 3.743047830923248,
      "grad_norm": 0.6107113361358643,
      "learning_rate": 1.2575083426028922e-05,
      "loss": 0.2592,
      "step": 6730
    },
    {
      "epoch": 3.7486095661846495,
      "grad_norm": 0.43896159529685974,
      "learning_rate": 1.2519466073414907e-05,
      "loss": 0.3065,
      "step": 6740
    },
    {
      "epoch": 3.754171301446051,
      "grad_norm": 0.30125972628593445,
      "learning_rate": 1.246384872080089e-05,
      "loss": 0.2343,
      "step": 6750
    },
    {
      "epoch": 3.759733036707453,
      "grad_norm": 0.36677640676498413,
      "learning_rate": 1.2408231368186874e-05,
      "loss": 0.2537,
      "step": 6760
    },
    {
      "epoch": 3.765294771968854,
      "grad_norm": 0.4006979763507843,
      "learning_rate": 1.235261401557286e-05,
      "loss": 0.2586,
      "step": 6770
    },
    {
      "epoch": 3.770856507230256,
      "grad_norm": 0.4566139578819275,
      "learning_rate": 1.2296996662958844e-05,
      "loss": 0.3079,
      "step": 6780
    },
    {
      "epoch": 3.7764182424916575,
      "grad_norm": 0.23206782341003418,
      "learning_rate": 1.2241379310344827e-05,
      "loss": 0.2573,
      "step": 6790
    },
    {
      "epoch": 3.7819799777530587,
      "grad_norm": 0.5940523743629456,
      "learning_rate": 1.2185761957730812e-05,
      "loss": 0.2607,
      "step": 6800
    },
    {
      "epoch": 3.7875417130144604,
      "grad_norm": 0.41944295167922974,
      "learning_rate": 1.2130144605116797e-05,
      "loss": 0.3091,
      "step": 6810
    },
    {
      "epoch": 3.793103448275862,
      "grad_norm": 0.43417900800704956,
      "learning_rate": 1.2074527252502781e-05,
      "loss": 0.3101,
      "step": 6820
    },
    {
      "epoch": 3.798665183537264,
      "grad_norm": 0.42837053537368774,
      "learning_rate": 1.2018909899888766e-05,
      "loss": 0.2077,
      "step": 6830
    },
    {
      "epoch": 3.804226918798665,
      "grad_norm": 0.4416770040988922,
      "learning_rate": 1.1963292547274751e-05,
      "loss": 0.2117,
      "step": 6840
    },
    {
      "epoch": 3.8097886540600667,
      "grad_norm": 0.4137883484363556,
      "learning_rate": 1.1907675194660736e-05,
      "loss": 0.2725,
      "step": 6850
    },
    {
      "epoch": 3.8153503893214684,
      "grad_norm": 0.31450605392456055,
      "learning_rate": 1.185205784204672e-05,
      "loss": 0.3044,
      "step": 6860
    },
    {
      "epoch": 3.82091212458287,
      "grad_norm": 0.5479997396469116,
      "learning_rate": 1.1796440489432703e-05,
      "loss": 0.3141,
      "step": 6870
    },
    {
      "epoch": 3.8264738598442714,
      "grad_norm": 0.430515319108963,
      "learning_rate": 1.1740823136818688e-05,
      "loss": 0.2481,
      "step": 6880
    },
    {
      "epoch": 3.832035595105673,
      "grad_norm": 0.27119889855384827,
      "learning_rate": 1.1685205784204673e-05,
      "loss": 0.2495,
      "step": 6890
    },
    {
      "epoch": 3.8375973303670747,
      "grad_norm": 0.4534801244735718,
      "learning_rate": 1.1629588431590658e-05,
      "loss": 0.2711,
      "step": 6900
    },
    {
      "epoch": 3.843159065628476,
      "grad_norm": 0.49064889550209045,
      "learning_rate": 1.157397107897664e-05,
      "loss": 0.2311,
      "step": 6910
    },
    {
      "epoch": 3.8487208008898777,
      "grad_norm": 0.6366422176361084,
      "learning_rate": 1.1518353726362626e-05,
      "loss": 0.2418,
      "step": 6920
    },
    {
      "epoch": 3.8542825361512794,
      "grad_norm": 0.48863139748573303,
      "learning_rate": 1.146273637374861e-05,
      "loss": 0.2991,
      "step": 6930
    },
    {
      "epoch": 3.8598442714126806,
      "grad_norm": 0.32149800658226013,
      "learning_rate": 1.1407119021134595e-05,
      "loss": 0.2993,
      "step": 6940
    },
    {
      "epoch": 3.8654060066740823,
      "grad_norm": 0.43509602546691895,
      "learning_rate": 1.1351501668520578e-05,
      "loss": 0.2881,
      "step": 6950
    },
    {
      "epoch": 3.870967741935484,
      "grad_norm": 0.5883486866950989,
      "learning_rate": 1.1295884315906563e-05,
      "loss": 0.2421,
      "step": 6960
    },
    {
      "epoch": 3.8765294771968852,
      "grad_norm": 0.5982584953308105,
      "learning_rate": 1.1240266963292548e-05,
      "loss": 0.2956,
      "step": 6970
    },
    {
      "epoch": 3.882091212458287,
      "grad_norm": 0.46337705850601196,
      "learning_rate": 1.1184649610678532e-05,
      "loss": 0.285,
      "step": 6980
    },
    {
      "epoch": 3.8876529477196886,
      "grad_norm": 0.39996084570884705,
      "learning_rate": 1.1129032258064517e-05,
      "loss": 0.3016,
      "step": 6990
    },
    {
      "epoch": 3.89321468298109,
      "grad_norm": 0.41302061080932617,
      "learning_rate": 1.10734149054505e-05,
      "loss": 0.3085,
      "step": 7000
    },
    {
      "epoch": 3.8987764182424915,
      "grad_norm": 0.4566386938095093,
      "learning_rate": 1.1017797552836485e-05,
      "loss": 0.2305,
      "step": 7010
    },
    {
      "epoch": 3.9043381535038932,
      "grad_norm": 0.7242574095726013,
      "learning_rate": 1.096218020022247e-05,
      "loss": 0.2506,
      "step": 7020
    },
    {
      "epoch": 3.909899888765295,
      "grad_norm": 0.5313642024993896,
      "learning_rate": 1.0906562847608455e-05,
      "loss": 0.2852,
      "step": 7030
    },
    {
      "epoch": 3.915461624026696,
      "grad_norm": 0.6484031677246094,
      "learning_rate": 1.0850945494994438e-05,
      "loss": 0.2493,
      "step": 7040
    },
    {
      "epoch": 3.921023359288098,
      "grad_norm": 0.63043212890625,
      "learning_rate": 1.0795328142380422e-05,
      "loss": 0.3015,
      "step": 7050
    },
    {
      "epoch": 3.9265850945494996,
      "grad_norm": 0.30450502038002014,
      "learning_rate": 1.0739710789766407e-05,
      "loss": 0.3324,
      "step": 7060
    },
    {
      "epoch": 3.9321468298109012,
      "grad_norm": 0.34620165824890137,
      "learning_rate": 1.0684093437152392e-05,
      "loss": 0.2753,
      "step": 7070
    },
    {
      "epoch": 3.9377085650723025,
      "grad_norm": 0.6915335655212402,
      "learning_rate": 1.0628476084538377e-05,
      "loss": 0.3141,
      "step": 7080
    },
    {
      "epoch": 3.943270300333704,
      "grad_norm": 0.6873727440834045,
      "learning_rate": 1.0572858731924361e-05,
      "loss": 0.3102,
      "step": 7090
    },
    {
      "epoch": 3.948832035595106,
      "grad_norm": 0.386136531829834,
      "learning_rate": 1.0517241379310346e-05,
      "loss": 0.302,
      "step": 7100
    },
    {
      "epoch": 3.954393770856507,
      "grad_norm": 0.7280128002166748,
      "learning_rate": 1.0461624026696331e-05,
      "loss": 0.3243,
      "step": 7110
    },
    {
      "epoch": 3.959955506117909,
      "grad_norm": 0.8461354970932007,
      "learning_rate": 1.0406006674082314e-05,
      "loss": 0.2922,
      "step": 7120
    },
    {
      "epoch": 3.9655172413793105,
      "grad_norm": 0.791964054107666,
      "learning_rate": 1.0350389321468299e-05,
      "loss": 0.2346,
      "step": 7130
    },
    {
      "epoch": 3.9710789766407117,
      "grad_norm": 0.5352492332458496,
      "learning_rate": 1.0294771968854284e-05,
      "loss": 0.3188,
      "step": 7140
    },
    {
      "epoch": 3.9766407119021134,
      "grad_norm": 0.40781083703041077,
      "learning_rate": 1.0239154616240268e-05,
      "loss": 0.2811,
      "step": 7150
    },
    {
      "epoch": 3.982202447163515,
      "grad_norm": 0.41657111048698425,
      "learning_rate": 1.0183537263626251e-05,
      "loss": 0.2339,
      "step": 7160
    },
    {
      "epoch": 3.9877641824249164,
      "grad_norm": 0.7160352468490601,
      "learning_rate": 1.0127919911012236e-05,
      "loss": 0.2544,
      "step": 7170
    },
    {
      "epoch": 3.993325917686318,
      "grad_norm": 0.6720845699310303,
      "learning_rate": 1.0072302558398221e-05,
      "loss": 0.3691,
      "step": 7180
    },
    {
      "epoch": 3.9988876529477198,
      "grad_norm": 0.26881468296051025,
      "learning_rate": 1.0016685205784206e-05,
      "loss": 0.2143,
      "step": 7190
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.2654128968715668,
      "eval_runtime": 7.7538,
      "eval_samples_per_second": 206.222,
      "eval_steps_per_second": 25.794,
      "step": 7192
    },
    {
      "epoch": 4.004449388209121,
      "grad_norm": 0.45365628600120544,
      "learning_rate": 9.961067853170189e-06,
      "loss": 0.2749,
      "step": 7200
    },
    {
      "epoch": 4.010011123470523,
      "grad_norm": 0.42198002338409424,
      "learning_rate": 9.905450500556174e-06,
      "loss": 0.2521,
      "step": 7210
    },
    {
      "epoch": 4.015572858731924,
      "grad_norm": 0.5982218384742737,
      "learning_rate": 9.849833147942158e-06,
      "loss": 0.2932,
      "step": 7220
    },
    {
      "epoch": 4.021134593993326,
      "grad_norm": 0.39615899324417114,
      "learning_rate": 9.794215795328143e-06,
      "loss": 0.2151,
      "step": 7230
    },
    {
      "epoch": 4.026696329254728,
      "grad_norm": 0.7698229551315308,
      "learning_rate": 9.738598442714126e-06,
      "loss": 0.2305,
      "step": 7240
    },
    {
      "epoch": 4.032258064516129,
      "grad_norm": 0.4478900134563446,
      "learning_rate": 9.682981090100111e-06,
      "loss": 0.2534,
      "step": 7250
    },
    {
      "epoch": 4.03781979977753,
      "grad_norm": 0.483545184135437,
      "learning_rate": 9.627363737486096e-06,
      "loss": 0.2389,
      "step": 7260
    },
    {
      "epoch": 4.043381535038932,
      "grad_norm": 0.4946233928203583,
      "learning_rate": 9.57174638487208e-06,
      "loss": 0.2616,
      "step": 7270
    },
    {
      "epoch": 4.048943270300334,
      "grad_norm": 0.39174917340278625,
      "learning_rate": 9.516129032258064e-06,
      "loss": 0.2387,
      "step": 7280
    },
    {
      "epoch": 4.054505005561735,
      "grad_norm": 0.5834798812866211,
      "learning_rate": 9.460511679644048e-06,
      "loss": 0.2631,
      "step": 7290
    },
    {
      "epoch": 4.060066740823137,
      "grad_norm": 0.7644367218017578,
      "learning_rate": 9.404894327030033e-06,
      "loss": 0.2778,
      "step": 7300
    },
    {
      "epoch": 4.065628476084538,
      "grad_norm": 0.41518735885620117,
      "learning_rate": 9.349276974416018e-06,
      "loss": 0.2664,
      "step": 7310
    },
    {
      "epoch": 4.0711902113459395,
      "grad_norm": 0.43029075860977173,
      "learning_rate": 9.293659621802003e-06,
      "loss": 0.3434,
      "step": 7320
    },
    {
      "epoch": 4.076751946607342,
      "grad_norm": 0.6845224499702454,
      "learning_rate": 9.238042269187987e-06,
      "loss": 0.3299,
      "step": 7330
    },
    {
      "epoch": 4.082313681868743,
      "grad_norm": 0.6222044229507446,
      "learning_rate": 9.182424916573972e-06,
      "loss": 0.238,
      "step": 7340
    },
    {
      "epoch": 4.087875417130145,
      "grad_norm": 0.5021974444389343,
      "learning_rate": 9.126807563959957e-06,
      "loss": 0.2505,
      "step": 7350
    },
    {
      "epoch": 4.093437152391546,
      "grad_norm": 0.37069663405418396,
      "learning_rate": 9.071190211345942e-06,
      "loss": 0.2601,
      "step": 7360
    },
    {
      "epoch": 4.0989988876529475,
      "grad_norm": 0.8078874945640564,
      "learning_rate": 9.015572858731925e-06,
      "loss": 0.2616,
      "step": 7370
    },
    {
      "epoch": 4.10456062291435,
      "grad_norm": 0.5746660828590393,
      "learning_rate": 8.95995550611791e-06,
      "loss": 0.249,
      "step": 7380
    },
    {
      "epoch": 4.110122358175751,
      "grad_norm": 0.33652567863464355,
      "learning_rate": 8.904338153503894e-06,
      "loss": 0.3235,
      "step": 7390
    },
    {
      "epoch": 4.115684093437152,
      "grad_norm": 0.4636046886444092,
      "learning_rate": 8.848720800889879e-06,
      "loss": 0.2197,
      "step": 7400
    },
    {
      "epoch": 4.121245828698554,
      "grad_norm": 0.5826122760772705,
      "learning_rate": 8.793103448275862e-06,
      "loss": 0.2765,
      "step": 7410
    },
    {
      "epoch": 4.1268075639599555,
      "grad_norm": 0.7313812971115112,
      "learning_rate": 8.737486095661847e-06,
      "loss": 0.2619,
      "step": 7420
    },
    {
      "epoch": 4.132369299221357,
      "grad_norm": 0.5547195672988892,
      "learning_rate": 8.681868743047832e-06,
      "loss": 0.3161,
      "step": 7430
    },
    {
      "epoch": 4.137931034482759,
      "grad_norm": 0.5972058773040771,
      "learning_rate": 8.626251390433816e-06,
      "loss": 0.3629,
      "step": 7440
    },
    {
      "epoch": 4.14349276974416,
      "grad_norm": 0.4296534061431885,
      "learning_rate": 8.5706340378198e-06,
      "loss": 0.2904,
      "step": 7450
    },
    {
      "epoch": 4.149054505005561,
      "grad_norm": 0.8724764585494995,
      "learning_rate": 8.515016685205784e-06,
      "loss": 0.2959,
      "step": 7460
    },
    {
      "epoch": 4.1546162402669635,
      "grad_norm": 0.6161012649536133,
      "learning_rate": 8.459399332591769e-06,
      "loss": 0.296,
      "step": 7470
    },
    {
      "epoch": 4.160177975528365,
      "grad_norm": 0.3186720013618469,
      "learning_rate": 8.403781979977754e-06,
      "loss": 0.1686,
      "step": 7480
    },
    {
      "epoch": 4.165739710789766,
      "grad_norm": 0.7120831608772278,
      "learning_rate": 8.348164627363737e-06,
      "loss": 0.2753,
      "step": 7490
    },
    {
      "epoch": 4.171301446051168,
      "grad_norm": 0.9384443163871765,
      "learning_rate": 8.292547274749722e-06,
      "loss": 0.3015,
      "step": 7500
    },
    {
      "epoch": 4.176863181312569,
      "grad_norm": 0.555385172367096,
      "learning_rate": 8.236929922135706e-06,
      "loss": 0.2413,
      "step": 7510
    },
    {
      "epoch": 4.1824249165739715,
      "grad_norm": 0.8264608979225159,
      "learning_rate": 8.181312569521691e-06,
      "loss": 0.3087,
      "step": 7520
    },
    {
      "epoch": 4.187986651835373,
      "grad_norm": 0.39678123593330383,
      "learning_rate": 8.125695216907676e-06,
      "loss": 0.1874,
      "step": 7530
    },
    {
      "epoch": 4.193548387096774,
      "grad_norm": 0.5614064335823059,
      "learning_rate": 8.07007786429366e-06,
      "loss": 0.2978,
      "step": 7540
    },
    {
      "epoch": 4.199110122358176,
      "grad_norm": 0.6308412551879883,
      "learning_rate": 8.014460511679644e-06,
      "loss": 0.3143,
      "step": 7550
    },
    {
      "epoch": 4.204671857619577,
      "grad_norm": 0.4686296582221985,
      "learning_rate": 7.958843159065628e-06,
      "loss": 0.1849,
      "step": 7560
    },
    {
      "epoch": 4.210233592880979,
      "grad_norm": 0.3484422564506531,
      "learning_rate": 7.903225806451613e-06,
      "loss": 0.2415,
      "step": 7570
    },
    {
      "epoch": 4.215795328142381,
      "grad_norm": 0.6681073904037476,
      "learning_rate": 7.847608453837598e-06,
      "loss": 0.2221,
      "step": 7580
    },
    {
      "epoch": 4.221357063403782,
      "grad_norm": 0.5884044766426086,
      "learning_rate": 7.791991101223583e-06,
      "loss": 0.2722,
      "step": 7590
    },
    {
      "epoch": 4.226918798665183,
      "grad_norm": 0.33173221349716187,
      "learning_rate": 7.736373748609567e-06,
      "loss": 0.2483,
      "step": 7600
    },
    {
      "epoch": 4.232480533926585,
      "grad_norm": 0.30489519238471985,
      "learning_rate": 7.68075639599555e-06,
      "loss": 0.27,
      "step": 7610
    },
    {
      "epoch": 4.238042269187987,
      "grad_norm": 0.718888521194458,
      "learning_rate": 7.625139043381535e-06,
      "loss": 0.3776,
      "step": 7620
    },
    {
      "epoch": 4.243604004449388,
      "grad_norm": 0.4355005621910095,
      "learning_rate": 7.56952169076752e-06,
      "loss": 0.2909,
      "step": 7630
    },
    {
      "epoch": 4.24916573971079,
      "grad_norm": 0.2757309377193451,
      "learning_rate": 7.513904338153505e-06,
      "loss": 0.245,
      "step": 7640
    },
    {
      "epoch": 4.254727474972191,
      "grad_norm": 0.4613988399505615,
      "learning_rate": 7.45828698553949e-06,
      "loss": 0.2207,
      "step": 7650
    },
    {
      "epoch": 4.2602892102335925,
      "grad_norm": 0.32177734375,
      "learning_rate": 7.402669632925473e-06,
      "loss": 0.2587,
      "step": 7660
    },
    {
      "epoch": 4.265850945494995,
      "grad_norm": 0.8950768113136292,
      "learning_rate": 7.3470522803114574e-06,
      "loss": 0.3206,
      "step": 7670
    },
    {
      "epoch": 4.271412680756396,
      "grad_norm": 0.4237464666366577,
      "learning_rate": 7.291434927697442e-06,
      "loss": 0.2195,
      "step": 7680
    },
    {
      "epoch": 4.276974416017797,
      "grad_norm": 0.3934594392776489,
      "learning_rate": 7.235817575083427e-06,
      "loss": 0.246,
      "step": 7690
    },
    {
      "epoch": 4.282536151279199,
      "grad_norm": 0.7227460145950317,
      "learning_rate": 7.18020022246941e-06,
      "loss": 0.2723,
      "step": 7700
    },
    {
      "epoch": 4.2880978865406005,
      "grad_norm": 0.8421201705932617,
      "learning_rate": 7.124582869855395e-06,
      "loss": 0.3774,
      "step": 7710
    },
    {
      "epoch": 4.293659621802002,
      "grad_norm": 0.3561042845249176,
      "learning_rate": 7.0689655172413796e-06,
      "loss": 0.2176,
      "step": 7720
    },
    {
      "epoch": 4.299221357063404,
      "grad_norm": 0.3691193163394928,
      "learning_rate": 7.013348164627364e-06,
      "loss": 0.2703,
      "step": 7730
    },
    {
      "epoch": 4.304783092324805,
      "grad_norm": 0.5697498917579651,
      "learning_rate": 6.957730812013348e-06,
      "loss": 0.2313,
      "step": 7740
    },
    {
      "epoch": 4.310344827586207,
      "grad_norm": 0.944674551486969,
      "learning_rate": 6.902113459399333e-06,
      "loss": 0.2648,
      "step": 7750
    },
    {
      "epoch": 4.3159065628476085,
      "grad_norm": 0.49522337317466736,
      "learning_rate": 6.846496106785318e-06,
      "loss": 0.2735,
      "step": 7760
    },
    {
      "epoch": 4.32146829810901,
      "grad_norm": 0.5834723711013794,
      "learning_rate": 6.7908787541713025e-06,
      "loss": 0.2973,
      "step": 7770
    },
    {
      "epoch": 4.327030033370412,
      "grad_norm": 0.6831200122833252,
      "learning_rate": 6.735261401557286e-06,
      "loss": 0.2838,
      "step": 7780
    },
    {
      "epoch": 4.332591768631813,
      "grad_norm": 0.7581812739372253,
      "learning_rate": 6.67964404894327e-06,
      "loss": 0.3281,
      "step": 7790
    },
    {
      "epoch": 4.338153503893214,
      "grad_norm": 0.26269426941871643,
      "learning_rate": 6.624026696329255e-06,
      "loss": 0.2193,
      "step": 7800
    },
    {
      "epoch": 4.3437152391546165,
      "grad_norm": 0.4852827489376068,
      "learning_rate": 6.56840934371524e-06,
      "loss": 0.2555,
      "step": 7810
    },
    {
      "epoch": 4.349276974416018,
      "grad_norm": 0.6961638331413269,
      "learning_rate": 6.512791991101223e-06,
      "loss": 0.3406,
      "step": 7820
    },
    {
      "epoch": 4.354838709677419,
      "grad_norm": 0.4766453504562378,
      "learning_rate": 6.457174638487208e-06,
      "loss": 0.2511,
      "step": 7830
    },
    {
      "epoch": 4.360400444938821,
      "grad_norm": 0.6446999907493591,
      "learning_rate": 6.4015572858731925e-06,
      "loss": 0.2837,
      "step": 7840
    },
    {
      "epoch": 4.365962180200222,
      "grad_norm": 0.5147639513015747,
      "learning_rate": 6.345939933259177e-06,
      "loss": 0.3151,
      "step": 7850
    },
    {
      "epoch": 4.371523915461624,
      "grad_norm": 0.5402166247367859,
      "learning_rate": 6.290322580645161e-06,
      "loss": 0.2236,
      "step": 7860
    },
    {
      "epoch": 4.377085650723026,
      "grad_norm": 0.6100702285766602,
      "learning_rate": 6.234705228031146e-06,
      "loss": 0.301,
      "step": 7870
    },
    {
      "epoch": 4.382647385984427,
      "grad_norm": 0.485550194978714,
      "learning_rate": 6.179087875417131e-06,
      "loss": 0.2629,
      "step": 7880
    },
    {
      "epoch": 4.388209121245828,
      "grad_norm": 0.4842604398727417,
      "learning_rate": 6.123470522803115e-06,
      "loss": 0.2638,
      "step": 7890
    },
    {
      "epoch": 4.39377085650723,
      "grad_norm": 0.2670387327671051,
      "learning_rate": 6.067853170189099e-06,
      "loss": 0.2641,
      "step": 7900
    },
    {
      "epoch": 4.399332591768632,
      "grad_norm": 0.40720441937446594,
      "learning_rate": 6.012235817575083e-06,
      "loss": 0.2441,
      "step": 7910
    },
    {
      "epoch": 4.404894327030034,
      "grad_norm": 0.7076770067214966,
      "learning_rate": 5.956618464961068e-06,
      "loss": 0.2713,
      "step": 7920
    },
    {
      "epoch": 4.410456062291435,
      "grad_norm": 0.4115968644618988,
      "learning_rate": 5.901001112347052e-06,
      "loss": 0.1987,
      "step": 7930
    },
    {
      "epoch": 4.416017797552836,
      "grad_norm": 0.6296411752700806,
      "learning_rate": 5.845383759733037e-06,
      "loss": 0.2959,
      "step": 7940
    },
    {
      "epoch": 4.421579532814238,
      "grad_norm": 0.6443522572517395,
      "learning_rate": 5.789766407119021e-06,
      "loss": 0.2795,
      "step": 7950
    },
    {
      "epoch": 4.42714126807564,
      "grad_norm": 0.3534716069698334,
      "learning_rate": 5.7341490545050054e-06,
      "loss": 0.2265,
      "step": 7960
    },
    {
      "epoch": 4.432703003337041,
      "grad_norm": 0.9337104558944702,
      "learning_rate": 5.67853170189099e-06,
      "loss": 0.3118,
      "step": 7970
    },
    {
      "epoch": 4.438264738598443,
      "grad_norm": 0.7161141633987427,
      "learning_rate": 5.622914349276975e-06,
      "loss": 0.2659,
      "step": 7980
    },
    {
      "epoch": 4.443826473859844,
      "grad_norm": 0.4799804985523224,
      "learning_rate": 5.56729699666296e-06,
      "loss": 0.2351,
      "step": 7990
    },
    {
      "epoch": 4.4493882091212456,
      "grad_norm": 0.5975654125213623,
      "learning_rate": 5.511679644048944e-06,
      "loss": 0.284,
      "step": 8000
    },
    {
      "epoch": 4.454949944382648,
      "grad_norm": 0.4832107722759247,
      "learning_rate": 5.456062291434928e-06,
      "loss": 0.2318,
      "step": 8010
    },
    {
      "epoch": 4.460511679644049,
      "grad_norm": 0.6336312890052795,
      "learning_rate": 5.400444938820912e-06,
      "loss": 0.319,
      "step": 8020
    },
    {
      "epoch": 4.46607341490545,
      "grad_norm": 0.7506499290466309,
      "learning_rate": 5.344827586206897e-06,
      "loss": 0.2852,
      "step": 8030
    },
    {
      "epoch": 4.471635150166852,
      "grad_norm": 0.42506617307662964,
      "learning_rate": 5.289210233592881e-06,
      "loss": 0.2373,
      "step": 8040
    },
    {
      "epoch": 4.477196885428254,
      "grad_norm": 0.48381924629211426,
      "learning_rate": 5.233592880978866e-06,
      "loss": 0.2613,
      "step": 8050
    },
    {
      "epoch": 4.482758620689655,
      "grad_norm": 0.3925081789493561,
      "learning_rate": 5.17797552836485e-06,
      "loss": 0.2892,
      "step": 8060
    },
    {
      "epoch": 4.488320355951057,
      "grad_norm": 0.5238328576087952,
      "learning_rate": 5.1223581757508344e-06,
      "loss": 0.2993,
      "step": 8070
    },
    {
      "epoch": 4.493882091212458,
      "grad_norm": 0.6146682500839233,
      "learning_rate": 5.066740823136819e-06,
      "loss": 0.2511,
      "step": 8080
    },
    {
      "epoch": 4.499443826473859,
      "grad_norm": 0.4732522964477539,
      "learning_rate": 5.011123470522804e-06,
      "loss": 0.2757,
      "step": 8090
    },
    {
      "epoch": 4.505005561735262,
      "grad_norm": 0.6951645016670227,
      "learning_rate": 4.955506117908788e-06,
      "loss": 0.3408,
      "step": 8100
    },
    {
      "epoch": 4.510567296996663,
      "grad_norm": 0.6897947788238525,
      "learning_rate": 4.899888765294773e-06,
      "loss": 0.2391,
      "step": 8110
    },
    {
      "epoch": 4.516129032258064,
      "grad_norm": 0.4740382730960846,
      "learning_rate": 4.8442714126807566e-06,
      "loss": 0.3488,
      "step": 8120
    },
    {
      "epoch": 4.521690767519466,
      "grad_norm": 0.37633416056632996,
      "learning_rate": 4.788654060066741e-06,
      "loss": 0.2566,
      "step": 8130
    },
    {
      "epoch": 4.527252502780867,
      "grad_norm": 0.47427788376808167,
      "learning_rate": 4.733036707452725e-06,
      "loss": 0.2387,
      "step": 8140
    },
    {
      "epoch": 4.53281423804227,
      "grad_norm": 0.7400880455970764,
      "learning_rate": 4.67741935483871e-06,
      "loss": 0.3092,
      "step": 8150
    },
    {
      "epoch": 4.538375973303671,
      "grad_norm": 0.5256036520004272,
      "learning_rate": 4.621802002224694e-06,
      "loss": 0.2461,
      "step": 8160
    },
    {
      "epoch": 4.543937708565072,
      "grad_norm": 0.7812866568565369,
      "learning_rate": 4.566184649610679e-06,
      "loss": 0.355,
      "step": 8170
    },
    {
      "epoch": 4.549499443826474,
      "grad_norm": 0.5097023248672485,
      "learning_rate": 4.510567296996663e-06,
      "loss": 0.2527,
      "step": 8180
    },
    {
      "epoch": 4.5550611790878754,
      "grad_norm": 0.5203284025192261,
      "learning_rate": 4.454949944382647e-06,
      "loss": 0.2652,
      "step": 8190
    },
    {
      "epoch": 4.560622914349277,
      "grad_norm": 0.5543973445892334,
      "learning_rate": 4.399332591768632e-06,
      "loss": 0.2352,
      "step": 8200
    },
    {
      "epoch": 4.566184649610679,
      "grad_norm": 0.36945024132728577,
      "learning_rate": 4.343715239154617e-06,
      "loss": 0.2713,
      "step": 8210
    },
    {
      "epoch": 4.57174638487208,
      "grad_norm": 0.9508416056632996,
      "learning_rate": 4.288097886540601e-06,
      "loss": 0.31,
      "step": 8220
    },
    {
      "epoch": 4.577308120133481,
      "grad_norm": 0.42252328991889954,
      "learning_rate": 4.2324805339265856e-06,
      "loss": 0.3996,
      "step": 8230
    },
    {
      "epoch": 4.5828698553948835,
      "grad_norm": 0.37024950981140137,
      "learning_rate": 4.1768631813125695e-06,
      "loss": 0.3,
      "step": 8240
    },
    {
      "epoch": 4.588431590656285,
      "grad_norm": 0.4874497354030609,
      "learning_rate": 4.121245828698554e-06,
      "loss": 0.2877,
      "step": 8250
    },
    {
      "epoch": 4.593993325917686,
      "grad_norm": 0.5046600699424744,
      "learning_rate": 4.065628476084538e-06,
      "loss": 0.1822,
      "step": 8260
    },
    {
      "epoch": 4.599555061179088,
      "grad_norm": 0.5045430064201355,
      "learning_rate": 4.010011123470523e-06,
      "loss": 0.2604,
      "step": 8270
    },
    {
      "epoch": 4.605116796440489,
      "grad_norm": 0.8761175870895386,
      "learning_rate": 3.954393770856507e-06,
      "loss": 0.301,
      "step": 8280
    },
    {
      "epoch": 4.6106785317018915,
      "grad_norm": 0.3940417170524597,
      "learning_rate": 3.898776418242492e-06,
      "loss": 0.3184,
      "step": 8290
    },
    {
      "epoch": 4.616240266963293,
      "grad_norm": 0.8316476941108704,
      "learning_rate": 3.843159065628476e-06,
      "loss": 0.2444,
      "step": 8300
    },
    {
      "epoch": 4.621802002224694,
      "grad_norm": 0.731046199798584,
      "learning_rate": 3.7875417130144607e-06,
      "loss": 0.2854,
      "step": 8310
    },
    {
      "epoch": 4.627363737486096,
      "grad_norm": 0.6757203340530396,
      "learning_rate": 3.7319243604004455e-06,
      "loss": 0.2637,
      "step": 8320
    },
    {
      "epoch": 4.632925472747497,
      "grad_norm": 0.7779228091239929,
      "learning_rate": 3.6763070077864294e-06,
      "loss": 0.2363,
      "step": 8330
    },
    {
      "epoch": 4.638487208008899,
      "grad_norm": 0.44866496324539185,
      "learning_rate": 3.620689655172414e-06,
      "loss": 0.298,
      "step": 8340
    },
    {
      "epoch": 4.644048943270301,
      "grad_norm": 0.4447794556617737,
      "learning_rate": 3.5650723025583985e-06,
      "loss": 0.2952,
      "step": 8350
    },
    {
      "epoch": 4.649610678531702,
      "grad_norm": 0.624696671962738,
      "learning_rate": 3.5094549499443833e-06,
      "loss": 0.2585,
      "step": 8360
    },
    {
      "epoch": 4.655172413793103,
      "grad_norm": 0.8924099206924438,
      "learning_rate": 3.453837597330367e-06,
      "loss": 0.2695,
      "step": 8370
    },
    {
      "epoch": 4.660734149054505,
      "grad_norm": 0.660788893699646,
      "learning_rate": 3.398220244716352e-06,
      "loss": 0.2745,
      "step": 8380
    },
    {
      "epoch": 4.666295884315907,
      "grad_norm": 0.28321191668510437,
      "learning_rate": 3.342602892102336e-06,
      "loss": 0.2572,
      "step": 8390
    },
    {
      "epoch": 4.671857619577308,
      "grad_norm": 0.6044611930847168,
      "learning_rate": 3.2869855394883206e-06,
      "loss": 0.3772,
      "step": 8400
    },
    {
      "epoch": 4.67741935483871,
      "grad_norm": 0.4047502875328064,
      "learning_rate": 3.231368186874305e-06,
      "loss": 0.2586,
      "step": 8410
    },
    {
      "epoch": 4.682981090100111,
      "grad_norm": 0.9636850953102112,
      "learning_rate": 3.1757508342602897e-06,
      "loss": 0.2846,
      "step": 8420
    },
    {
      "epoch": 4.6885428253615125,
      "grad_norm": 0.4471805691719055,
      "learning_rate": 3.1201334816462736e-06,
      "loss": 0.2176,
      "step": 8430
    },
    {
      "epoch": 4.694104560622915,
      "grad_norm": 0.3002470135688782,
      "learning_rate": 3.064516129032258e-06,
      "loss": 0.2216,
      "step": 8440
    },
    {
      "epoch": 4.699666295884316,
      "grad_norm": 0.5574405789375305,
      "learning_rate": 3.0088987764182423e-06,
      "loss": 0.2774,
      "step": 8450
    },
    {
      "epoch": 4.705228031145717,
      "grad_norm": 0.5812776684761047,
      "learning_rate": 2.953281423804227e-06,
      "loss": 0.2547,
      "step": 8460
    },
    {
      "epoch": 4.710789766407119,
      "grad_norm": 0.6681963801383972,
      "learning_rate": 2.897664071190212e-06,
      "loss": 0.3127,
      "step": 8470
    },
    {
      "epoch": 4.7163515016685205,
      "grad_norm": 0.649342954158783,
      "learning_rate": 2.842046718576196e-06,
      "loss": 0.2596,
      "step": 8480
    },
    {
      "epoch": 4.721913236929922,
      "grad_norm": 0.4716048538684845,
      "learning_rate": 2.7864293659621805e-06,
      "loss": 0.2933,
      "step": 8490
    },
    {
      "epoch": 4.727474972191324,
      "grad_norm": 0.4885251224040985,
      "learning_rate": 2.730812013348165e-06,
      "loss": 0.2007,
      "step": 8500
    },
    {
      "epoch": 4.733036707452725,
      "grad_norm": 0.7262434363365173,
      "learning_rate": 2.6751946607341492e-06,
      "loss": 0.2476,
      "step": 8510
    },
    {
      "epoch": 4.738598442714126,
      "grad_norm": 0.4303148686885834,
      "learning_rate": 2.6195773081201336e-06,
      "loss": 0.2531,
      "step": 8520
    },
    {
      "epoch": 4.7441601779755285,
      "grad_norm": 3.8740978240966797,
      "learning_rate": 2.5639599555061183e-06,
      "loss": 0.2974,
      "step": 8530
    },
    {
      "epoch": 4.74972191323693,
      "grad_norm": 0.4164228141307831,
      "learning_rate": 2.5083426028921027e-06,
      "loss": 0.2968,
      "step": 8540
    },
    {
      "epoch": 4.755283648498332,
      "grad_norm": 0.3707254230976105,
      "learning_rate": 2.452725250278087e-06,
      "loss": 0.2364,
      "step": 8550
    },
    {
      "epoch": 4.760845383759733,
      "grad_norm": 0.28866255283355713,
      "learning_rate": 2.3971078976640713e-06,
      "loss": 0.2193,
      "step": 8560
    },
    {
      "epoch": 4.766407119021134,
      "grad_norm": 0.3773590326309204,
      "learning_rate": 2.3414905450500557e-06,
      "loss": 0.2623,
      "step": 8570
    },
    {
      "epoch": 4.7719688542825365,
      "grad_norm": 0.49625399708747864,
      "learning_rate": 2.28587319243604e-06,
      "loss": 0.2546,
      "step": 8580
    },
    {
      "epoch": 4.777530589543938,
      "grad_norm": 0.6665811538696289,
      "learning_rate": 2.2302558398220248e-06,
      "loss": 0.2866,
      "step": 8590
    },
    {
      "epoch": 4.783092324805339,
      "grad_norm": 0.40288645029067993,
      "learning_rate": 2.174638487208009e-06,
      "loss": 0.2144,
      "step": 8600
    },
    {
      "epoch": 4.788654060066741,
      "grad_norm": 0.5968329310417175,
      "learning_rate": 2.1190211345939935e-06,
      "loss": 0.2993,
      "step": 8610
    },
    {
      "epoch": 4.794215795328142,
      "grad_norm": 0.5732275247573853,
      "learning_rate": 2.063403781979978e-06,
      "loss": 0.2791,
      "step": 8620
    },
    {
      "epoch": 4.799777530589544,
      "grad_norm": 0.3833272159099579,
      "learning_rate": 2.007786429365962e-06,
      "loss": 0.283,
      "step": 8630
    },
    {
      "epoch": 4.805339265850946,
      "grad_norm": 0.4230549931526184,
      "learning_rate": 1.9521690767519465e-06,
      "loss": 0.2714,
      "step": 8640
    },
    {
      "epoch": 4.810901001112347,
      "grad_norm": 0.453347384929657,
      "learning_rate": 1.896551724137931e-06,
      "loss": 0.3058,
      "step": 8650
    },
    {
      "epoch": 4.816462736373748,
      "grad_norm": 0.7587212920188904,
      "learning_rate": 1.8409343715239156e-06,
      "loss": 0.2686,
      "step": 8660
    },
    {
      "epoch": 4.82202447163515,
      "grad_norm": 0.6285905241966248,
      "learning_rate": 1.7853170189099e-06,
      "loss": 0.3585,
      "step": 8670
    },
    {
      "epoch": 4.827586206896552,
      "grad_norm": 0.6164717078208923,
      "learning_rate": 1.7296996662958843e-06,
      "loss": 0.2586,
      "step": 8680
    },
    {
      "epoch": 4.833147942157954,
      "grad_norm": 0.4914647936820984,
      "learning_rate": 1.6740823136818688e-06,
      "loss": 0.3255,
      "step": 8690
    },
    {
      "epoch": 4.838709677419355,
      "grad_norm": 0.25667428970336914,
      "learning_rate": 1.6184649610678532e-06,
      "loss": 0.3039,
      "step": 8700
    },
    {
      "epoch": 4.844271412680756,
      "grad_norm": 0.6398872137069702,
      "learning_rate": 1.5628476084538375e-06,
      "loss": 0.2065,
      "step": 8710
    },
    {
      "epoch": 4.849833147942158,
      "grad_norm": 0.2942191958427429,
      "learning_rate": 1.5072302558398223e-06,
      "loss": 0.2435,
      "step": 8720
    },
    {
      "epoch": 4.85539488320356,
      "grad_norm": 0.4670126140117645,
      "learning_rate": 1.4516129032258066e-06,
      "loss": 0.2015,
      "step": 8730
    },
    {
      "epoch": 4.860956618464961,
      "grad_norm": 0.6803057193756104,
      "learning_rate": 1.395995550611791e-06,
      "loss": 0.3595,
      "step": 8740
    },
    {
      "epoch": 4.866518353726363,
      "grad_norm": 0.7794216871261597,
      "learning_rate": 1.3403781979977755e-06,
      "loss": 0.3092,
      "step": 8750
    },
    {
      "epoch": 4.872080088987764,
      "grad_norm": 0.4421766996383667,
      "learning_rate": 1.2847608453837598e-06,
      "loss": 0.1734,
      "step": 8760
    },
    {
      "epoch": 4.8776418242491655,
      "grad_norm": 0.6670588254928589,
      "learning_rate": 1.2291434927697442e-06,
      "loss": 0.2661,
      "step": 8770
    },
    {
      "epoch": 4.883203559510568,
      "grad_norm": 0.409371018409729,
      "learning_rate": 1.1735261401557287e-06,
      "loss": 0.205,
      "step": 8780
    },
    {
      "epoch": 4.888765294771969,
      "grad_norm": 0.6322103142738342,
      "learning_rate": 1.117908787541713e-06,
      "loss": 0.245,
      "step": 8790
    },
    {
      "epoch": 4.89432703003337,
      "grad_norm": 0.5659019351005554,
      "learning_rate": 1.0622914349276974e-06,
      "loss": 0.2889,
      "step": 8800
    },
    {
      "epoch": 4.899888765294772,
      "grad_norm": 0.7013320922851562,
      "learning_rate": 1.006674082313682e-06,
      "loss": 0.2406,
      "step": 8810
    },
    {
      "epoch": 4.9054505005561735,
      "grad_norm": 0.3514273762702942,
      "learning_rate": 9.510567296996663e-07,
      "loss": 0.3319,
      "step": 8820
    },
    {
      "epoch": 4.911012235817575,
      "grad_norm": 0.3980136811733246,
      "learning_rate": 8.954393770856507e-07,
      "loss": 0.2434,
      "step": 8830
    },
    {
      "epoch": 4.916573971078977,
      "grad_norm": 0.6420916318893433,
      "learning_rate": 8.398220244716351e-07,
      "loss": 0.2262,
      "step": 8840
    },
    {
      "epoch": 4.922135706340378,
      "grad_norm": 0.3570973873138428,
      "learning_rate": 7.842046718576195e-07,
      "loss": 0.2718,
      "step": 8850
    },
    {
      "epoch": 4.927697441601779,
      "grad_norm": 0.33399391174316406,
      "learning_rate": 7.285873192436041e-07,
      "loss": 0.2639,
      "step": 8860
    },
    {
      "epoch": 4.9332591768631815,
      "grad_norm": 0.6220583915710449,
      "learning_rate": 6.729699666295884e-07,
      "loss": 0.2706,
      "step": 8870
    },
    {
      "epoch": 4.938820912124583,
      "grad_norm": 0.3658657968044281,
      "learning_rate": 6.173526140155729e-07,
      "loss": 0.2244,
      "step": 8880
    },
    {
      "epoch": 4.944382647385984,
      "grad_norm": 0.31179994344711304,
      "learning_rate": 5.617352614015573e-07,
      "loss": 0.2455,
      "step": 8890
    },
    {
      "epoch": 4.949944382647386,
      "grad_norm": 0.6885961890220642,
      "learning_rate": 5.061179087875418e-07,
      "loss": 0.2356,
      "step": 8900
    },
    {
      "epoch": 4.955506117908787,
      "grad_norm": 0.8022910356521606,
      "learning_rate": 4.505005561735261e-07,
      "loss": 0.2947,
      "step": 8910
    },
    {
      "epoch": 4.961067853170189,
      "grad_norm": 0.5338435173034668,
      "learning_rate": 3.948832035595106e-07,
      "loss": 0.283,
      "step": 8920
    },
    {
      "epoch": 4.966629588431591,
      "grad_norm": 0.6666449904441833,
      "learning_rate": 3.39265850945495e-07,
      "loss": 0.2618,
      "step": 8930
    },
    {
      "epoch": 4.972191323692992,
      "grad_norm": 0.656326174736023,
      "learning_rate": 2.8364849833147944e-07,
      "loss": 0.3152,
      "step": 8940
    },
    {
      "epoch": 4.977753058954394,
      "grad_norm": 0.5565280914306641,
      "learning_rate": 2.2803114571746386e-07,
      "loss": 0.2391,
      "step": 8950
    },
    {
      "epoch": 4.983314794215795,
      "grad_norm": 0.3718634843826294,
      "learning_rate": 1.7241379310344828e-07,
      "loss": 0.3129,
      "step": 8960
    },
    {
      "epoch": 4.988876529477197,
      "grad_norm": 0.35782065987586975,
      "learning_rate": 1.1679644048943271e-07,
      "loss": 0.2066,
      "step": 8970
    },
    {
      "epoch": 4.994438264738599,
      "grad_norm": 0.3877120018005371,
      "learning_rate": 6.117908787541713e-08,
      "loss": 0.261,
      "step": 8980
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.7659088969230652,
      "learning_rate": 5.561735261401558e-09,
      "loss": 0.2617,
      "step": 8990
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.2622697651386261,
      "eval_runtime": 7.753,
      "eval_samples_per_second": 206.243,
      "eval_steps_per_second": 25.796,
      "step": 8990
    }
  ],
  "logging_steps": 10,
  "max_steps": 8990,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2433276413214720.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
