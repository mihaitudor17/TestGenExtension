{
  "best_global_step": 3596,
  "best_metric": 0.3001479506492615,
  "best_model_checkpoint": "./model_output/checkpoint-3596",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 3596,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0055617352614015575,
      "grad_norm": 2.5525827407836914,
      "learning_rate": 4.9937430478309235e-05,
      "loss": 2.5411,
      "step": 10
    },
    {
      "epoch": 0.011123470522803115,
      "grad_norm": 1.3268426656723022,
      "learning_rate": 4.9867908787541716e-05,
      "loss": 1.3443,
      "step": 20
    },
    {
      "epoch": 0.01668520578420467,
      "grad_norm": 0.8901060223579407,
      "learning_rate": 4.97983870967742e-05,
      "loss": 0.8849,
      "step": 30
    },
    {
      "epoch": 0.02224694104560623,
      "grad_norm": 0.7148659229278564,
      "learning_rate": 4.972886540600668e-05,
      "loss": 0.9508,
      "step": 40
    },
    {
      "epoch": 0.027808676307007785,
      "grad_norm": 0.9565550684928894,
      "learning_rate": 4.965934371523916e-05,
      "loss": 0.7667,
      "step": 50
    },
    {
      "epoch": 0.03337041156840934,
      "grad_norm": 0.6821409463882446,
      "learning_rate": 4.958982202447164e-05,
      "loss": 0.8245,
      "step": 60
    },
    {
      "epoch": 0.0389321468298109,
      "grad_norm": 0.751246988773346,
      "learning_rate": 4.9520300333704114e-05,
      "loss": 0.6898,
      "step": 70
    },
    {
      "epoch": 0.04449388209121246,
      "grad_norm": 1.2306151390075684,
      "learning_rate": 4.9450778642936595e-05,
      "loss": 0.8993,
      "step": 80
    },
    {
      "epoch": 0.05005561735261402,
      "grad_norm": 0.8846468329429626,
      "learning_rate": 4.938125695216908e-05,
      "loss": 0.8112,
      "step": 90
    },
    {
      "epoch": 0.05561735261401557,
      "grad_norm": 1.423006296157837,
      "learning_rate": 4.931173526140156e-05,
      "loss": 0.813,
      "step": 100
    },
    {
      "epoch": 0.06117908787541713,
      "grad_norm": 1.172096610069275,
      "learning_rate": 4.924221357063404e-05,
      "loss": 0.6418,
      "step": 110
    },
    {
      "epoch": 0.06674082313681869,
      "grad_norm": 1.1444743871688843,
      "learning_rate": 4.9172691879866526e-05,
      "loss": 0.5648,
      "step": 120
    },
    {
      "epoch": 0.07230255839822025,
      "grad_norm": 1.1594178676605225,
      "learning_rate": 4.9103170189099e-05,
      "loss": 0.7546,
      "step": 130
    },
    {
      "epoch": 0.0778642936596218,
      "grad_norm": 1.100389003753662,
      "learning_rate": 4.903364849833148e-05,
      "loss": 0.5728,
      "step": 140
    },
    {
      "epoch": 0.08342602892102335,
      "grad_norm": 1.101913332939148,
      "learning_rate": 4.896412680756396e-05,
      "loss": 0.6871,
      "step": 150
    },
    {
      "epoch": 0.08898776418242492,
      "grad_norm": 5.8635029792785645,
      "learning_rate": 4.889460511679644e-05,
      "loss": 0.6608,
      "step": 160
    },
    {
      "epoch": 0.09454949944382647,
      "grad_norm": 0.7511581182479858,
      "learning_rate": 4.8825083426028924e-05,
      "loss": 0.595,
      "step": 170
    },
    {
      "epoch": 0.10011123470522804,
      "grad_norm": 1.0363221168518066,
      "learning_rate": 4.8755561735261405e-05,
      "loss": 0.6003,
      "step": 180
    },
    {
      "epoch": 0.10567296996662959,
      "grad_norm": 0.815268874168396,
      "learning_rate": 4.8686040044493886e-05,
      "loss": 0.6413,
      "step": 190
    },
    {
      "epoch": 0.11123470522803114,
      "grad_norm": 0.7144020795822144,
      "learning_rate": 4.861651835372637e-05,
      "loss": 0.6068,
      "step": 200
    },
    {
      "epoch": 0.1167964404894327,
      "grad_norm": 0.8381993174552917,
      "learning_rate": 4.854699666295884e-05,
      "loss": 0.6796,
      "step": 210
    },
    {
      "epoch": 0.12235817575083426,
      "grad_norm": 1.1710529327392578,
      "learning_rate": 4.847747497219133e-05,
      "loss": 0.7142,
      "step": 220
    },
    {
      "epoch": 0.12791991101223582,
      "grad_norm": 0.5955579876899719,
      "learning_rate": 4.840795328142381e-05,
      "loss": 0.4454,
      "step": 230
    },
    {
      "epoch": 0.13348164627363737,
      "grad_norm": 0.8910718560218811,
      "learning_rate": 4.8338431590656284e-05,
      "loss": 0.6267,
      "step": 240
    },
    {
      "epoch": 0.13904338153503892,
      "grad_norm": 0.5491893291473389,
      "learning_rate": 4.826890989988877e-05,
      "loss": 0.6276,
      "step": 250
    },
    {
      "epoch": 0.1446051167964405,
      "grad_norm": 1.3676902055740356,
      "learning_rate": 4.819938820912125e-05,
      "loss": 0.61,
      "step": 260
    },
    {
      "epoch": 0.15016685205784205,
      "grad_norm": 1.4296607971191406,
      "learning_rate": 4.8129866518353727e-05,
      "loss": 0.5965,
      "step": 270
    },
    {
      "epoch": 0.1557285873192436,
      "grad_norm": 0.5384398102760315,
      "learning_rate": 4.806034482758621e-05,
      "loss": 0.4753,
      "step": 280
    },
    {
      "epoch": 0.16129032258064516,
      "grad_norm": 1.2348922491073608,
      "learning_rate": 4.799082313681869e-05,
      "loss": 0.5502,
      "step": 290
    },
    {
      "epoch": 0.1668520578420467,
      "grad_norm": 0.6758724451065063,
      "learning_rate": 4.792130144605117e-05,
      "loss": 0.489,
      "step": 300
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 0.5294970870018005,
      "learning_rate": 4.785177975528365e-05,
      "loss": 0.6417,
      "step": 310
    },
    {
      "epoch": 0.17797552836484984,
      "grad_norm": 0.41510841250419617,
      "learning_rate": 4.778225806451613e-05,
      "loss": 0.4415,
      "step": 320
    },
    {
      "epoch": 0.1835372636262514,
      "grad_norm": 1.0183379650115967,
      "learning_rate": 4.771273637374861e-05,
      "loss": 0.5701,
      "step": 330
    },
    {
      "epoch": 0.18909899888765294,
      "grad_norm": 0.41732579469680786,
      "learning_rate": 4.764321468298109e-05,
      "loss": 0.5946,
      "step": 340
    },
    {
      "epoch": 0.1946607341490545,
      "grad_norm": 1.4333125352859497,
      "learning_rate": 4.7573692992213574e-05,
      "loss": 0.5739,
      "step": 350
    },
    {
      "epoch": 0.20022246941045607,
      "grad_norm": 0.7246432900428772,
      "learning_rate": 4.7504171301446055e-05,
      "loss": 0.6378,
      "step": 360
    },
    {
      "epoch": 0.20578420467185762,
      "grad_norm": 0.7695886492729187,
      "learning_rate": 4.7434649610678536e-05,
      "loss": 0.4991,
      "step": 370
    },
    {
      "epoch": 0.21134593993325917,
      "grad_norm": 0.6453182101249695,
      "learning_rate": 4.736512791991101e-05,
      "loss": 0.481,
      "step": 380
    },
    {
      "epoch": 0.21690767519466073,
      "grad_norm": 0.5107723474502563,
      "learning_rate": 4.72956062291435e-05,
      "loss": 0.4822,
      "step": 390
    },
    {
      "epoch": 0.22246941045606228,
      "grad_norm": 1.1564799547195435,
      "learning_rate": 4.722608453837597e-05,
      "loss": 0.4509,
      "step": 400
    },
    {
      "epoch": 0.22803114571746386,
      "grad_norm": 0.57452791929245,
      "learning_rate": 4.715656284760845e-05,
      "loss": 0.5468,
      "step": 410
    },
    {
      "epoch": 0.2335928809788654,
      "grad_norm": 0.4877876341342926,
      "learning_rate": 4.708704115684094e-05,
      "loss": 0.5601,
      "step": 420
    },
    {
      "epoch": 0.23915461624026696,
      "grad_norm": 1.2673227787017822,
      "learning_rate": 4.7017519466073415e-05,
      "loss": 0.5881,
      "step": 430
    },
    {
      "epoch": 0.2447163515016685,
      "grad_norm": 1.1010905504226685,
      "learning_rate": 4.6947997775305896e-05,
      "loss": 0.6815,
      "step": 440
    },
    {
      "epoch": 0.25027808676307006,
      "grad_norm": 1.3056578636169434,
      "learning_rate": 4.6878476084538384e-05,
      "loss": 0.4804,
      "step": 450
    },
    {
      "epoch": 0.25583982202447164,
      "grad_norm": 0.7745890617370605,
      "learning_rate": 4.680895439377086e-05,
      "loss": 0.5771,
      "step": 460
    },
    {
      "epoch": 0.26140155728587317,
      "grad_norm": 1.0737452507019043,
      "learning_rate": 4.673943270300334e-05,
      "loss": 0.5105,
      "step": 470
    },
    {
      "epoch": 0.26696329254727474,
      "grad_norm": 0.7220446467399597,
      "learning_rate": 4.666991101223582e-05,
      "loss": 0.5294,
      "step": 480
    },
    {
      "epoch": 0.2725250278086763,
      "grad_norm": 0.7519826292991638,
      "learning_rate": 4.66003893214683e-05,
      "loss": 0.4721,
      "step": 490
    },
    {
      "epoch": 0.27808676307007785,
      "grad_norm": 0.9228230714797974,
      "learning_rate": 4.653086763070078e-05,
      "loss": 0.7005,
      "step": 500
    },
    {
      "epoch": 0.2836484983314794,
      "grad_norm": 0.818547785282135,
      "learning_rate": 4.646134593993326e-05,
      "loss": 0.635,
      "step": 510
    },
    {
      "epoch": 0.289210233592881,
      "grad_norm": 0.8597416281700134,
      "learning_rate": 4.6391824249165744e-05,
      "loss": 0.5921,
      "step": 520
    },
    {
      "epoch": 0.29477196885428253,
      "grad_norm": 1.319675087928772,
      "learning_rate": 4.6322302558398225e-05,
      "loss": 0.5063,
      "step": 530
    },
    {
      "epoch": 0.3003337041156841,
      "grad_norm": 0.5941510200500488,
      "learning_rate": 4.62527808676307e-05,
      "loss": 0.5013,
      "step": 540
    },
    {
      "epoch": 0.30589543937708563,
      "grad_norm": 0.8028301000595093,
      "learning_rate": 4.6183259176863186e-05,
      "loss": 0.4303,
      "step": 550
    },
    {
      "epoch": 0.3114571746384872,
      "grad_norm": 0.6426131129264832,
      "learning_rate": 4.611373748609567e-05,
      "loss": 0.6085,
      "step": 560
    },
    {
      "epoch": 0.3170189098998888,
      "grad_norm": 0.47726669907569885,
      "learning_rate": 4.604421579532814e-05,
      "loss": 0.3715,
      "step": 570
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 0.5873124003410339,
      "learning_rate": 4.597469410456062e-05,
      "loss": 0.483,
      "step": 580
    },
    {
      "epoch": 0.3281423804226919,
      "grad_norm": 0.7739619612693787,
      "learning_rate": 4.590517241379311e-05,
      "loss": 0.638,
      "step": 590
    },
    {
      "epoch": 0.3337041156840934,
      "grad_norm": 0.3978739380836487,
      "learning_rate": 4.5835650723025584e-05,
      "loss": 0.517,
      "step": 600
    },
    {
      "epoch": 0.339265850945495,
      "grad_norm": 0.8331751823425293,
      "learning_rate": 4.5766129032258065e-05,
      "loss": 0.5766,
      "step": 610
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 0.7002637386322021,
      "learning_rate": 4.5696607341490546e-05,
      "loss": 0.4511,
      "step": 620
    },
    {
      "epoch": 0.3503893214682981,
      "grad_norm": 0.7994442582130432,
      "learning_rate": 4.562708565072303e-05,
      "loss": 0.5056,
      "step": 630
    },
    {
      "epoch": 0.3559510567296997,
      "grad_norm": 0.6874408721923828,
      "learning_rate": 4.555756395995551e-05,
      "loss": 0.4127,
      "step": 640
    },
    {
      "epoch": 0.3615127919911012,
      "grad_norm": 0.5121737122535706,
      "learning_rate": 4.548804226918799e-05,
      "loss": 0.5597,
      "step": 650
    },
    {
      "epoch": 0.3670745272525028,
      "grad_norm": 0.6439671516418457,
      "learning_rate": 4.541852057842047e-05,
      "loss": 0.4209,
      "step": 660
    },
    {
      "epoch": 0.37263626251390436,
      "grad_norm": 0.8372392058372498,
      "learning_rate": 4.534899888765295e-05,
      "loss": 0.4785,
      "step": 670
    },
    {
      "epoch": 0.3781979977753059,
      "grad_norm": 0.3934169411659241,
      "learning_rate": 4.5279477196885425e-05,
      "loss": 0.4603,
      "step": 680
    },
    {
      "epoch": 0.38375973303670746,
      "grad_norm": 0.4571261405944824,
      "learning_rate": 4.520995550611791e-05,
      "loss": 0.402,
      "step": 690
    },
    {
      "epoch": 0.389321468298109,
      "grad_norm": 0.5831238031387329,
      "learning_rate": 4.5140433815350394e-05,
      "loss": 0.4903,
      "step": 700
    },
    {
      "epoch": 0.39488320355951056,
      "grad_norm": 1.0447627305984497,
      "learning_rate": 4.507091212458287e-05,
      "loss": 0.4689,
      "step": 710
    },
    {
      "epoch": 0.40044493882091214,
      "grad_norm": 0.9712090492248535,
      "learning_rate": 4.5001390433815356e-05,
      "loss": 0.5081,
      "step": 720
    },
    {
      "epoch": 0.40600667408231367,
      "grad_norm": 0.797478437423706,
      "learning_rate": 4.493186874304784e-05,
      "loss": 0.4668,
      "step": 730
    },
    {
      "epoch": 0.41156840934371525,
      "grad_norm": 0.34340789914131165,
      "learning_rate": 4.486234705228031e-05,
      "loss": 0.4834,
      "step": 740
    },
    {
      "epoch": 0.41713014460511677,
      "grad_norm": 0.8734432458877563,
      "learning_rate": 4.47928253615128e-05,
      "loss": 0.4784,
      "step": 750
    },
    {
      "epoch": 0.42269187986651835,
      "grad_norm": 0.5256807208061218,
      "learning_rate": 4.472330367074527e-05,
      "loss": 0.4363,
      "step": 760
    },
    {
      "epoch": 0.42825361512791993,
      "grad_norm": 0.5640223622322083,
      "learning_rate": 4.4653781979977754e-05,
      "loss": 0.4608,
      "step": 770
    },
    {
      "epoch": 0.43381535038932145,
      "grad_norm": 0.8311137557029724,
      "learning_rate": 4.4584260289210235e-05,
      "loss": 0.513,
      "step": 780
    },
    {
      "epoch": 0.43937708565072303,
      "grad_norm": 0.6450435519218445,
      "learning_rate": 4.4514738598442716e-05,
      "loss": 0.4227,
      "step": 790
    },
    {
      "epoch": 0.44493882091212456,
      "grad_norm": 0.9171372652053833,
      "learning_rate": 4.44452169076752e-05,
      "loss": 0.5237,
      "step": 800
    },
    {
      "epoch": 0.45050055617352613,
      "grad_norm": 0.8862090706825256,
      "learning_rate": 4.437569521690768e-05,
      "loss": 0.5567,
      "step": 810
    },
    {
      "epoch": 0.4560622914349277,
      "grad_norm": 0.7405511736869812,
      "learning_rate": 4.430617352614016e-05,
      "loss": 0.4165,
      "step": 820
    },
    {
      "epoch": 0.46162402669632924,
      "grad_norm": 0.7511187791824341,
      "learning_rate": 4.423665183537264e-05,
      "loss": 0.4756,
      "step": 830
    },
    {
      "epoch": 0.4671857619577308,
      "grad_norm": 0.47134438157081604,
      "learning_rate": 4.416713014460512e-05,
      "loss": 0.4286,
      "step": 840
    },
    {
      "epoch": 0.4727474972191324,
      "grad_norm": 0.7970263957977295,
      "learning_rate": 4.40976084538376e-05,
      "loss": 0.4611,
      "step": 850
    },
    {
      "epoch": 0.4783092324805339,
      "grad_norm": 0.5984987020492554,
      "learning_rate": 4.402808676307008e-05,
      "loss": 0.4396,
      "step": 860
    },
    {
      "epoch": 0.4838709677419355,
      "grad_norm": 0.9741320013999939,
      "learning_rate": 4.395856507230256e-05,
      "loss": 0.5482,
      "step": 870
    },
    {
      "epoch": 0.489432703003337,
      "grad_norm": 0.8839993476867676,
      "learning_rate": 4.388904338153504e-05,
      "loss": 0.4778,
      "step": 880
    },
    {
      "epoch": 0.4949944382647386,
      "grad_norm": 0.695946216583252,
      "learning_rate": 4.3819521690767525e-05,
      "loss": 0.5128,
      "step": 890
    },
    {
      "epoch": 0.5005561735261401,
      "grad_norm": 1.3090813159942627,
      "learning_rate": 4.375e-05,
      "loss": 0.4636,
      "step": 900
    },
    {
      "epoch": 0.5061179087875417,
      "grad_norm": 0.8040421605110168,
      "learning_rate": 4.368047830923248e-05,
      "loss": 0.3835,
      "step": 910
    },
    {
      "epoch": 0.5116796440489433,
      "grad_norm": 0.549232006072998,
      "learning_rate": 4.361095661846497e-05,
      "loss": 0.4891,
      "step": 920
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 0.45676493644714355,
      "learning_rate": 4.354143492769744e-05,
      "loss": 0.4579,
      "step": 930
    },
    {
      "epoch": 0.5228031145717463,
      "grad_norm": 0.6675621867179871,
      "learning_rate": 4.347191323692992e-05,
      "loss": 0.4197,
      "step": 940
    },
    {
      "epoch": 0.5283648498331479,
      "grad_norm": 0.9498982429504395,
      "learning_rate": 4.3402391546162404e-05,
      "loss": 0.6546,
      "step": 950
    },
    {
      "epoch": 0.5339265850945495,
      "grad_norm": 0.45047032833099365,
      "learning_rate": 4.3332869855394885e-05,
      "loss": 0.5212,
      "step": 960
    },
    {
      "epoch": 0.5394883203559511,
      "grad_norm": 0.5908936858177185,
      "learning_rate": 4.3263348164627366e-05,
      "loss": 0.4393,
      "step": 970
    },
    {
      "epoch": 0.5450500556173526,
      "grad_norm": 0.605823278427124,
      "learning_rate": 4.319382647385985e-05,
      "loss": 0.4102,
      "step": 980
    },
    {
      "epoch": 0.5506117908787542,
      "grad_norm": 0.6224651336669922,
      "learning_rate": 4.312430478309233e-05,
      "loss": 0.4823,
      "step": 990
    },
    {
      "epoch": 0.5561735261401557,
      "grad_norm": 0.7430524826049805,
      "learning_rate": 4.305478309232481e-05,
      "loss": 0.4396,
      "step": 1000
    },
    {
      "epoch": 0.5617352614015573,
      "grad_norm": 0.4521581530570984,
      "learning_rate": 4.298526140155728e-05,
      "loss": 0.3757,
      "step": 1010
    },
    {
      "epoch": 0.5672969966629589,
      "grad_norm": 0.7062059640884399,
      "learning_rate": 4.291573971078977e-05,
      "loss": 0.464,
      "step": 1020
    },
    {
      "epoch": 0.5728587319243604,
      "grad_norm": 0.5695302486419678,
      "learning_rate": 4.284621802002225e-05,
      "loss": 0.4379,
      "step": 1030
    },
    {
      "epoch": 0.578420467185762,
      "grad_norm": 0.8680985569953918,
      "learning_rate": 4.2776696329254726e-05,
      "loss": 0.4664,
      "step": 1040
    },
    {
      "epoch": 0.5839822024471635,
      "grad_norm": 0.5428459644317627,
      "learning_rate": 4.270717463848721e-05,
      "loss": 0.4331,
      "step": 1050
    },
    {
      "epoch": 0.5895439377085651,
      "grad_norm": 0.6196666955947876,
      "learning_rate": 4.2637652947719695e-05,
      "loss": 0.3346,
      "step": 1060
    },
    {
      "epoch": 0.5951056729699666,
      "grad_norm": 0.8636741638183594,
      "learning_rate": 4.256813125695217e-05,
      "loss": 0.4499,
      "step": 1070
    },
    {
      "epoch": 0.6006674082313682,
      "grad_norm": 0.7357936501502991,
      "learning_rate": 4.249860956618465e-05,
      "loss": 0.4014,
      "step": 1080
    },
    {
      "epoch": 0.6062291434927698,
      "grad_norm": 0.43654438853263855,
      "learning_rate": 4.242908787541713e-05,
      "loss": 0.4103,
      "step": 1090
    },
    {
      "epoch": 0.6117908787541713,
      "grad_norm": 1.0056612491607666,
      "learning_rate": 4.235956618464961e-05,
      "loss": 0.448,
      "step": 1100
    },
    {
      "epoch": 0.6173526140155728,
      "grad_norm": 0.5290952324867249,
      "learning_rate": 4.229004449388209e-05,
      "loss": 0.3511,
      "step": 1110
    },
    {
      "epoch": 0.6229143492769744,
      "grad_norm": 0.5175420045852661,
      "learning_rate": 4.2220522803114574e-05,
      "loss": 0.4338,
      "step": 1120
    },
    {
      "epoch": 0.628476084538376,
      "grad_norm": 0.6629083156585693,
      "learning_rate": 4.2151001112347055e-05,
      "loss": 0.3824,
      "step": 1130
    },
    {
      "epoch": 0.6340378197997776,
      "grad_norm": 0.5251221656799316,
      "learning_rate": 4.2081479421579536e-05,
      "loss": 0.3979,
      "step": 1140
    },
    {
      "epoch": 0.639599555061179,
      "grad_norm": 0.6854979991912842,
      "learning_rate": 4.201195773081201e-05,
      "loss": 0.4287,
      "step": 1150
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 0.585934042930603,
      "learning_rate": 4.19424360400445e-05,
      "loss": 0.3968,
      "step": 1160
    },
    {
      "epoch": 0.6507230255839822,
      "grad_norm": 0.3926808834075928,
      "learning_rate": 4.187291434927698e-05,
      "loss": 0.3617,
      "step": 1170
    },
    {
      "epoch": 0.6562847608453838,
      "grad_norm": 0.6477160453796387,
      "learning_rate": 4.180339265850945e-05,
      "loss": 0.3854,
      "step": 1180
    },
    {
      "epoch": 0.6618464961067854,
      "grad_norm": 0.432401567697525,
      "learning_rate": 4.173387096774194e-05,
      "loss": 0.559,
      "step": 1190
    },
    {
      "epoch": 0.6674082313681868,
      "grad_norm": 0.4107978045940399,
      "learning_rate": 4.166434927697442e-05,
      "loss": 0.454,
      "step": 1200
    },
    {
      "epoch": 0.6729699666295884,
      "grad_norm": 0.6200776100158691,
      "learning_rate": 4.1594827586206896e-05,
      "loss": 0.3531,
      "step": 1210
    },
    {
      "epoch": 0.67853170189099,
      "grad_norm": 0.533763587474823,
      "learning_rate": 4.152530589543938e-05,
      "loss": 0.4468,
      "step": 1220
    },
    {
      "epoch": 0.6840934371523916,
      "grad_norm": 1.2759897708892822,
      "learning_rate": 4.145578420467186e-05,
      "loss": 0.3744,
      "step": 1230
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.7593809366226196,
      "learning_rate": 4.138626251390434e-05,
      "loss": 0.3181,
      "step": 1240
    },
    {
      "epoch": 0.6952169076751946,
      "grad_norm": 0.7876800894737244,
      "learning_rate": 4.131674082313682e-05,
      "loss": 0.4989,
      "step": 1250
    },
    {
      "epoch": 0.7007786429365962,
      "grad_norm": 0.8353077173233032,
      "learning_rate": 4.12472191323693e-05,
      "loss": 0.347,
      "step": 1260
    },
    {
      "epoch": 0.7063403781979978,
      "grad_norm": 0.38471782207489014,
      "learning_rate": 4.117769744160178e-05,
      "loss": 0.3238,
      "step": 1270
    },
    {
      "epoch": 0.7119021134593994,
      "grad_norm": 0.4690661132335663,
      "learning_rate": 4.110817575083426e-05,
      "loss": 0.4294,
      "step": 1280
    },
    {
      "epoch": 0.7174638487208009,
      "grad_norm": 0.42152100801467896,
      "learning_rate": 4.103865406006674e-05,
      "loss": 0.5408,
      "step": 1290
    },
    {
      "epoch": 0.7230255839822024,
      "grad_norm": 0.6533157229423523,
      "learning_rate": 4.0969132369299224e-05,
      "loss": 0.384,
      "step": 1300
    },
    {
      "epoch": 0.728587319243604,
      "grad_norm": 0.6049360036849976,
      "learning_rate": 4.0899610678531705e-05,
      "loss": 0.5527,
      "step": 1310
    },
    {
      "epoch": 0.7341490545050056,
      "grad_norm": 1.0990878343582153,
      "learning_rate": 4.0830088987764186e-05,
      "loss": 0.368,
      "step": 1320
    },
    {
      "epoch": 0.7397107897664071,
      "grad_norm": 0.4053933322429657,
      "learning_rate": 4.076056729699667e-05,
      "loss": 0.2853,
      "step": 1330
    },
    {
      "epoch": 0.7452725250278087,
      "grad_norm": 0.5772730112075806,
      "learning_rate": 4.069104560622914e-05,
      "loss": 0.5624,
      "step": 1340
    },
    {
      "epoch": 0.7508342602892102,
      "grad_norm": 0.4764140844345093,
      "learning_rate": 4.062152391546162e-05,
      "loss": 0.343,
      "step": 1350
    },
    {
      "epoch": 0.7563959955506118,
      "grad_norm": 0.5199870467185974,
      "learning_rate": 4.055200222469411e-05,
      "loss": 0.4261,
      "step": 1360
    },
    {
      "epoch": 0.7619577308120133,
      "grad_norm": 0.5221707820892334,
      "learning_rate": 4.0482480533926584e-05,
      "loss": 0.3701,
      "step": 1370
    },
    {
      "epoch": 0.7675194660734149,
      "grad_norm": 0.4399644732475281,
      "learning_rate": 4.0412958843159065e-05,
      "loss": 0.3542,
      "step": 1380
    },
    {
      "epoch": 0.7730812013348165,
      "grad_norm": 0.48110535740852356,
      "learning_rate": 4.034343715239155e-05,
      "loss": 0.5134,
      "step": 1390
    },
    {
      "epoch": 0.778642936596218,
      "grad_norm": 0.6386606097221375,
      "learning_rate": 4.027391546162403e-05,
      "loss": 0.3548,
      "step": 1400
    },
    {
      "epoch": 0.7842046718576196,
      "grad_norm": 0.7605119347572327,
      "learning_rate": 4.020439377085651e-05,
      "loss": 0.4856,
      "step": 1410
    },
    {
      "epoch": 0.7897664071190211,
      "grad_norm": 1.1893503665924072,
      "learning_rate": 4.013487208008899e-05,
      "loss": 0.3321,
      "step": 1420
    },
    {
      "epoch": 0.7953281423804227,
      "grad_norm": 0.46310171484947205,
      "learning_rate": 4.006535038932147e-05,
      "loss": 0.3384,
      "step": 1430
    },
    {
      "epoch": 0.8008898776418243,
      "grad_norm": 0.870482861995697,
      "learning_rate": 3.999582869855395e-05,
      "loss": 0.4825,
      "step": 1440
    },
    {
      "epoch": 0.8064516129032258,
      "grad_norm": 0.48402249813079834,
      "learning_rate": 3.992630700778643e-05,
      "loss": 0.38,
      "step": 1450
    },
    {
      "epoch": 0.8120133481646273,
      "grad_norm": 0.523638904094696,
      "learning_rate": 3.985678531701891e-05,
      "loss": 0.3355,
      "step": 1460
    },
    {
      "epoch": 0.8175750834260289,
      "grad_norm": 0.4753722548484802,
      "learning_rate": 3.9787263626251394e-05,
      "loss": 0.3404,
      "step": 1470
    },
    {
      "epoch": 0.8231368186874305,
      "grad_norm": 0.4069725275039673,
      "learning_rate": 3.971774193548387e-05,
      "loss": 0.4111,
      "step": 1480
    },
    {
      "epoch": 0.8286985539488321,
      "grad_norm": 0.5116335153579712,
      "learning_rate": 3.9648220244716356e-05,
      "loss": 0.3481,
      "step": 1490
    },
    {
      "epoch": 0.8342602892102335,
      "grad_norm": 0.426998496055603,
      "learning_rate": 3.9578698553948837e-05,
      "loss": 0.4016,
      "step": 1500
    },
    {
      "epoch": 0.8398220244716351,
      "grad_norm": 0.7460212707519531,
      "learning_rate": 3.950917686318131e-05,
      "loss": 0.4432,
      "step": 1510
    },
    {
      "epoch": 0.8453837597330367,
      "grad_norm": 0.559238851070404,
      "learning_rate": 3.94396551724138e-05,
      "loss": 0.2723,
      "step": 1520
    },
    {
      "epoch": 0.8509454949944383,
      "grad_norm": 0.42031338810920715,
      "learning_rate": 3.937013348164628e-05,
      "loss": 0.3508,
      "step": 1530
    },
    {
      "epoch": 0.8565072302558399,
      "grad_norm": 0.5390011072158813,
      "learning_rate": 3.9300611790878754e-05,
      "loss": 0.3895,
      "step": 1540
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 0.684197723865509,
      "learning_rate": 3.9231090100111234e-05,
      "loss": 0.4652,
      "step": 1550
    },
    {
      "epoch": 0.8676307007786429,
      "grad_norm": 0.48811376094818115,
      "learning_rate": 3.9161568409343715e-05,
      "loss": 0.4384,
      "step": 1560
    },
    {
      "epoch": 0.8731924360400445,
      "grad_norm": 0.8045117259025574,
      "learning_rate": 3.9092046718576196e-05,
      "loss": 0.4223,
      "step": 1570
    },
    {
      "epoch": 0.8787541713014461,
      "grad_norm": 0.6008856892585754,
      "learning_rate": 3.902252502780868e-05,
      "loss": 0.4092,
      "step": 1580
    },
    {
      "epoch": 0.8843159065628476,
      "grad_norm": 0.6629645824432373,
      "learning_rate": 3.895300333704116e-05,
      "loss": 0.4329,
      "step": 1590
    },
    {
      "epoch": 0.8898776418242491,
      "grad_norm": 0.8826934099197388,
      "learning_rate": 3.888348164627364e-05,
      "loss": 0.4784,
      "step": 1600
    },
    {
      "epoch": 0.8954393770856507,
      "grad_norm": 0.5994570255279541,
      "learning_rate": 3.881395995550612e-05,
      "loss": 0.4477,
      "step": 1610
    },
    {
      "epoch": 0.9010011123470523,
      "grad_norm": 0.5502285957336426,
      "learning_rate": 3.87444382647386e-05,
      "loss": 0.3886,
      "step": 1620
    },
    {
      "epoch": 0.9065628476084538,
      "grad_norm": 0.4776727557182312,
      "learning_rate": 3.867491657397108e-05,
      "loss": 0.4154,
      "step": 1630
    },
    {
      "epoch": 0.9121245828698554,
      "grad_norm": 0.5284346342086792,
      "learning_rate": 3.860539488320356e-05,
      "loss": 0.2822,
      "step": 1640
    },
    {
      "epoch": 0.917686318131257,
      "grad_norm": 0.5803051590919495,
      "learning_rate": 3.853587319243604e-05,
      "loss": 0.3412,
      "step": 1650
    },
    {
      "epoch": 0.9232480533926585,
      "grad_norm": 0.42913445830345154,
      "learning_rate": 3.8466351501668525e-05,
      "loss": 0.3405,
      "step": 1660
    },
    {
      "epoch": 0.92880978865406,
      "grad_norm": 0.5831618905067444,
      "learning_rate": 3.8396829810901006e-05,
      "loss": 0.3626,
      "step": 1670
    },
    {
      "epoch": 0.9343715239154616,
      "grad_norm": 0.4179552495479584,
      "learning_rate": 3.832730812013348e-05,
      "loss": 0.3543,
      "step": 1680
    },
    {
      "epoch": 0.9399332591768632,
      "grad_norm": 0.800932765007019,
      "learning_rate": 3.825778642936597e-05,
      "loss": 0.3532,
      "step": 1690
    },
    {
      "epoch": 0.9454949944382648,
      "grad_norm": 0.595123827457428,
      "learning_rate": 3.818826473859844e-05,
      "loss": 0.4134,
      "step": 1700
    },
    {
      "epoch": 0.9510567296996663,
      "grad_norm": 0.5647664070129395,
      "learning_rate": 3.811874304783092e-05,
      "loss": 0.3146,
      "step": 1710
    },
    {
      "epoch": 0.9566184649610678,
      "grad_norm": 0.4878097474575043,
      "learning_rate": 3.804922135706341e-05,
      "loss": 0.4309,
      "step": 1720
    },
    {
      "epoch": 0.9621802002224694,
      "grad_norm": 0.4822239577770233,
      "learning_rate": 3.7979699666295885e-05,
      "loss": 0.3235,
      "step": 1730
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 0.447329044342041,
      "learning_rate": 3.7910177975528366e-05,
      "loss": 0.3705,
      "step": 1740
    },
    {
      "epoch": 0.9733036707452726,
      "grad_norm": 0.5515149235725403,
      "learning_rate": 3.784065628476085e-05,
      "loss": 0.4426,
      "step": 1750
    },
    {
      "epoch": 0.978865406006674,
      "grad_norm": 0.5133271813392639,
      "learning_rate": 3.777113459399333e-05,
      "loss": 0.3548,
      "step": 1760
    },
    {
      "epoch": 0.9844271412680756,
      "grad_norm": 0.5711859464645386,
      "learning_rate": 3.770161290322581e-05,
      "loss": 0.3608,
      "step": 1770
    },
    {
      "epoch": 0.9899888765294772,
      "grad_norm": 0.7628951668739319,
      "learning_rate": 3.763209121245829e-05,
      "loss": 0.422,
      "step": 1780
    },
    {
      "epoch": 0.9955506117908788,
      "grad_norm": 0.7162138223648071,
      "learning_rate": 3.756256952169077e-05,
      "loss": 0.319,
      "step": 1790
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.34065884351730347,
      "eval_runtime": 7.6853,
      "eval_samples_per_second": 208.059,
      "eval_steps_per_second": 26.024,
      "step": 1798
    },
    {
      "epoch": 1.0011123470522802,
      "grad_norm": 0.3152831494808197,
      "learning_rate": 3.749304783092325e-05,
      "loss": 0.4161,
      "step": 1800
    },
    {
      "epoch": 1.006674082313682,
      "grad_norm": 0.5285692811012268,
      "learning_rate": 3.7423526140155726e-05,
      "loss": 0.3954,
      "step": 1810
    },
    {
      "epoch": 1.0122358175750834,
      "grad_norm": 0.9164868593215942,
      "learning_rate": 3.7354004449388213e-05,
      "loss": 0.4168,
      "step": 1820
    },
    {
      "epoch": 1.0177975528364849,
      "grad_norm": 0.63432377576828,
      "learning_rate": 3.7284482758620694e-05,
      "loss": 0.3651,
      "step": 1830
    },
    {
      "epoch": 1.0233592880978866,
      "grad_norm": 0.5960706472396851,
      "learning_rate": 3.721496106785317e-05,
      "loss": 0.3149,
      "step": 1840
    },
    {
      "epoch": 1.028921023359288,
      "grad_norm": 0.9236274361610413,
      "learning_rate": 3.714543937708565e-05,
      "loss": 0.4841,
      "step": 1850
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 0.8874687552452087,
      "learning_rate": 3.707591768631814e-05,
      "loss": 0.3007,
      "step": 1860
    },
    {
      "epoch": 1.0400444938820912,
      "grad_norm": 0.6550981402397156,
      "learning_rate": 3.700639599555061e-05,
      "loss": 0.3826,
      "step": 1870
    },
    {
      "epoch": 1.0456062291434929,
      "grad_norm": 0.6283860206604004,
      "learning_rate": 3.693687430478309e-05,
      "loss": 0.4589,
      "step": 1880
    },
    {
      "epoch": 1.0511679644048944,
      "grad_norm": 0.8383861780166626,
      "learning_rate": 3.6867352614015573e-05,
      "loss": 0.3929,
      "step": 1890
    },
    {
      "epoch": 1.0567296996662958,
      "grad_norm": 1.0551563501358032,
      "learning_rate": 3.6797830923248054e-05,
      "loss": 0.3366,
      "step": 1900
    },
    {
      "epoch": 1.0622914349276975,
      "grad_norm": 0.7981504201889038,
      "learning_rate": 3.6728309232480535e-05,
      "loss": 0.3839,
      "step": 1910
    },
    {
      "epoch": 1.067853170189099,
      "grad_norm": 0.6106035113334656,
      "learning_rate": 3.6658787541713016e-05,
      "loss": 0.3997,
      "step": 1920
    },
    {
      "epoch": 1.0734149054505004,
      "grad_norm": 0.6412799954414368,
      "learning_rate": 3.65892658509455e-05,
      "loss": 0.381,
      "step": 1930
    },
    {
      "epoch": 1.0789766407119021,
      "grad_norm": 0.5730671286582947,
      "learning_rate": 3.651974416017798e-05,
      "loss": 0.417,
      "step": 1940
    },
    {
      "epoch": 1.0845383759733036,
      "grad_norm": 0.803517758846283,
      "learning_rate": 3.645022246941045e-05,
      "loss": 0.3497,
      "step": 1950
    },
    {
      "epoch": 1.0901001112347053,
      "grad_norm": 0.8822663426399231,
      "learning_rate": 3.638070077864294e-05,
      "loss": 0.4765,
      "step": 1960
    },
    {
      "epoch": 1.0956618464961068,
      "grad_norm": 0.6745765209197998,
      "learning_rate": 3.631117908787542e-05,
      "loss": 0.3745,
      "step": 1970
    },
    {
      "epoch": 1.1012235817575085,
      "grad_norm": 0.5872057676315308,
      "learning_rate": 3.6241657397107895e-05,
      "loss": 0.2802,
      "step": 1980
    },
    {
      "epoch": 1.10678531701891,
      "grad_norm": 0.982037365436554,
      "learning_rate": 3.617213570634038e-05,
      "loss": 0.388,
      "step": 1990
    },
    {
      "epoch": 1.1123470522803114,
      "grad_norm": 0.4529235363006592,
      "learning_rate": 3.6102614015572864e-05,
      "loss": 0.3992,
      "step": 2000
    },
    {
      "epoch": 1.117908787541713,
      "grad_norm": 0.4494197368621826,
      "learning_rate": 3.603309232480534e-05,
      "loss": 0.3173,
      "step": 2010
    },
    {
      "epoch": 1.1234705228031145,
      "grad_norm": 0.6014623045921326,
      "learning_rate": 3.5963570634037826e-05,
      "loss": 0.3475,
      "step": 2020
    },
    {
      "epoch": 1.129032258064516,
      "grad_norm": 0.41498851776123047,
      "learning_rate": 3.58940489432703e-05,
      "loss": 0.2972,
      "step": 2030
    },
    {
      "epoch": 1.1345939933259177,
      "grad_norm": 0.577235758304596,
      "learning_rate": 3.582452725250278e-05,
      "loss": 0.3038,
      "step": 2040
    },
    {
      "epoch": 1.1401557285873192,
      "grad_norm": 0.4034533202648163,
      "learning_rate": 3.575500556173526e-05,
      "loss": 0.4181,
      "step": 2050
    },
    {
      "epoch": 1.1457174638487209,
      "grad_norm": 0.6050820350646973,
      "learning_rate": 3.568548387096774e-05,
      "loss": 0.3584,
      "step": 2060
    },
    {
      "epoch": 1.1512791991101223,
      "grad_norm": 0.44698765873908997,
      "learning_rate": 3.5615962180200224e-05,
      "loss": 0.4012,
      "step": 2070
    },
    {
      "epoch": 1.156840934371524,
      "grad_norm": 0.3616802990436554,
      "learning_rate": 3.5546440489432705e-05,
      "loss": 0.3678,
      "step": 2080
    },
    {
      "epoch": 1.1624026696329255,
      "grad_norm": 0.3789844512939453,
      "learning_rate": 3.5476918798665186e-05,
      "loss": 0.2801,
      "step": 2090
    },
    {
      "epoch": 1.167964404894327,
      "grad_norm": 0.8003667593002319,
      "learning_rate": 3.540739710789767e-05,
      "loss": 0.241,
      "step": 2100
    },
    {
      "epoch": 1.1735261401557286,
      "grad_norm": 0.6376257538795471,
      "learning_rate": 3.533787541713015e-05,
      "loss": 0.3275,
      "step": 2110
    },
    {
      "epoch": 1.1790878754171301,
      "grad_norm": 0.3614793121814728,
      "learning_rate": 3.526835372636263e-05,
      "loss": 0.3582,
      "step": 2120
    },
    {
      "epoch": 1.1846496106785316,
      "grad_norm": 0.572265625,
      "learning_rate": 3.519883203559511e-05,
      "loss": 0.2917,
      "step": 2130
    },
    {
      "epoch": 1.1902113459399333,
      "grad_norm": 0.8907924294471741,
      "learning_rate": 3.512931034482759e-05,
      "loss": 0.4099,
      "step": 2140
    },
    {
      "epoch": 1.1957730812013347,
      "grad_norm": 0.6072726845741272,
      "learning_rate": 3.5059788654060065e-05,
      "loss": 0.2666,
      "step": 2150
    },
    {
      "epoch": 1.2013348164627364,
      "grad_norm": 0.6031574010848999,
      "learning_rate": 3.499026696329255e-05,
      "loss": 0.3088,
      "step": 2160
    },
    {
      "epoch": 1.206896551724138,
      "grad_norm": 0.4473423659801483,
      "learning_rate": 3.4920745272525027e-05,
      "loss": 0.3831,
      "step": 2170
    },
    {
      "epoch": 1.2124582869855396,
      "grad_norm": 0.5695571303367615,
      "learning_rate": 3.485122358175751e-05,
      "loss": 0.288,
      "step": 2180
    },
    {
      "epoch": 1.218020022246941,
      "grad_norm": 0.6912129521369934,
      "learning_rate": 3.4781701890989995e-05,
      "loss": 0.326,
      "step": 2190
    },
    {
      "epoch": 1.2235817575083425,
      "grad_norm": 0.7395942211151123,
      "learning_rate": 3.471218020022247e-05,
      "loss": 0.4397,
      "step": 2200
    },
    {
      "epoch": 1.2291434927697442,
      "grad_norm": 0.6862102746963501,
      "learning_rate": 3.464265850945495e-05,
      "loss": 0.3818,
      "step": 2210
    },
    {
      "epoch": 1.2347052280311457,
      "grad_norm": 0.524557888507843,
      "learning_rate": 3.457313681868743e-05,
      "loss": 0.3173,
      "step": 2220
    },
    {
      "epoch": 1.2402669632925472,
      "grad_norm": 0.6976358890533447,
      "learning_rate": 3.450361512791991e-05,
      "loss": 0.4165,
      "step": 2230
    },
    {
      "epoch": 1.2458286985539488,
      "grad_norm": 0.44882142543792725,
      "learning_rate": 3.443409343715239e-05,
      "loss": 0.2917,
      "step": 2240
    },
    {
      "epoch": 1.2513904338153503,
      "grad_norm": 0.4772804081439972,
      "learning_rate": 3.4364571746384874e-05,
      "loss": 0.3517,
      "step": 2250
    },
    {
      "epoch": 1.256952169076752,
      "grad_norm": 0.7102514505386353,
      "learning_rate": 3.4295050055617355e-05,
      "loss": 0.4052,
      "step": 2260
    },
    {
      "epoch": 1.2625139043381535,
      "grad_norm": 0.393222451210022,
      "learning_rate": 3.4225528364849836e-05,
      "loss": 0.3578,
      "step": 2270
    },
    {
      "epoch": 1.2680756395995552,
      "grad_norm": 0.3036554157733917,
      "learning_rate": 3.415600667408232e-05,
      "loss": 0.3486,
      "step": 2280
    },
    {
      "epoch": 1.2736373748609566,
      "grad_norm": 0.6243816614151001,
      "learning_rate": 3.40864849833148e-05,
      "loss": 0.324,
      "step": 2290
    },
    {
      "epoch": 1.279199110122358,
      "grad_norm": 0.33007171750068665,
      "learning_rate": 3.401696329254728e-05,
      "loss": 0.3627,
      "step": 2300
    },
    {
      "epoch": 1.2847608453837598,
      "grad_norm": 0.35035109519958496,
      "learning_rate": 3.394744160177975e-05,
      "loss": 0.3132,
      "step": 2310
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 0.41482552886009216,
      "learning_rate": 3.3877919911012234e-05,
      "loss": 0.3897,
      "step": 2320
    },
    {
      "epoch": 1.2958843159065627,
      "grad_norm": 0.5588271617889404,
      "learning_rate": 3.380839822024472e-05,
      "loss": 0.3899,
      "step": 2330
    },
    {
      "epoch": 1.3014460511679644,
      "grad_norm": 0.40364983677864075,
      "learning_rate": 3.3738876529477196e-05,
      "loss": 0.3965,
      "step": 2340
    },
    {
      "epoch": 1.3070077864293659,
      "grad_norm": 0.6026041507720947,
      "learning_rate": 3.366935483870968e-05,
      "loss": 0.3615,
      "step": 2350
    },
    {
      "epoch": 1.3125695216907676,
      "grad_norm": 0.6745402216911316,
      "learning_rate": 3.359983314794216e-05,
      "loss": 0.3087,
      "step": 2360
    },
    {
      "epoch": 1.318131256952169,
      "grad_norm": 0.3921054005622864,
      "learning_rate": 3.353031145717464e-05,
      "loss": 0.2911,
      "step": 2370
    },
    {
      "epoch": 1.3236929922135707,
      "grad_norm": 0.7617361545562744,
      "learning_rate": 3.346078976640712e-05,
      "loss": 0.3487,
      "step": 2380
    },
    {
      "epoch": 1.3292547274749722,
      "grad_norm": 0.47120195627212524,
      "learning_rate": 3.33912680756396e-05,
      "loss": 0.3686,
      "step": 2390
    },
    {
      "epoch": 1.3348164627363737,
      "grad_norm": 0.5236061215400696,
      "learning_rate": 3.332174638487208e-05,
      "loss": 0.3555,
      "step": 2400
    },
    {
      "epoch": 1.3403781979977754,
      "grad_norm": 0.6016117930412292,
      "learning_rate": 3.325222469410456e-05,
      "loss": 0.3196,
      "step": 2410
    },
    {
      "epoch": 1.3459399332591768,
      "grad_norm": 0.6376500725746155,
      "learning_rate": 3.318270300333704e-05,
      "loss": 0.3451,
      "step": 2420
    },
    {
      "epoch": 1.3515016685205783,
      "grad_norm": 0.4058801233768463,
      "learning_rate": 3.3113181312569525e-05,
      "loss": 0.2847,
      "step": 2430
    },
    {
      "epoch": 1.35706340378198,
      "grad_norm": 0.40464186668395996,
      "learning_rate": 3.3043659621802006e-05,
      "loss": 0.2935,
      "step": 2440
    },
    {
      "epoch": 1.3626251390433817,
      "grad_norm": 0.4858924448490143,
      "learning_rate": 3.297413793103448e-05,
      "loss": 0.406,
      "step": 2450
    },
    {
      "epoch": 1.3681868743047831,
      "grad_norm": 0.8338244557380676,
      "learning_rate": 3.290461624026697e-05,
      "loss": 0.2927,
      "step": 2460
    },
    {
      "epoch": 1.3737486095661846,
      "grad_norm": 0.7640155553817749,
      "learning_rate": 3.283509454949945e-05,
      "loss": 0.4795,
      "step": 2470
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 0.533825159072876,
      "learning_rate": 3.276557285873192e-05,
      "loss": 0.356,
      "step": 2480
    },
    {
      "epoch": 1.3848720800889878,
      "grad_norm": 0.48709729313850403,
      "learning_rate": 3.269605116796441e-05,
      "loss": 0.4171,
      "step": 2490
    },
    {
      "epoch": 1.3904338153503892,
      "grad_norm": 0.2889058291912079,
      "learning_rate": 3.2626529477196885e-05,
      "loss": 0.3633,
      "step": 2500
    },
    {
      "epoch": 1.395995550611791,
      "grad_norm": 0.7104504108428955,
      "learning_rate": 3.2557007786429365e-05,
      "loss": 0.341,
      "step": 2510
    },
    {
      "epoch": 1.4015572858731924,
      "grad_norm": 0.8131512403488159,
      "learning_rate": 3.2487486095661846e-05,
      "loss": 0.4012,
      "step": 2520
    },
    {
      "epoch": 1.4071190211345939,
      "grad_norm": 0.35165491700172424,
      "learning_rate": 3.241796440489433e-05,
      "loss": 0.3257,
      "step": 2530
    },
    {
      "epoch": 1.4126807563959956,
      "grad_norm": 0.44587668776512146,
      "learning_rate": 3.234844271412681e-05,
      "loss": 0.346,
      "step": 2540
    },
    {
      "epoch": 1.4182424916573972,
      "grad_norm": 0.6354359984397888,
      "learning_rate": 3.227892102335929e-05,
      "loss": 0.4188,
      "step": 2550
    },
    {
      "epoch": 1.4238042269187987,
      "grad_norm": 0.5301926136016846,
      "learning_rate": 3.220939933259177e-05,
      "loss": 0.3883,
      "step": 2560
    },
    {
      "epoch": 1.4293659621802002,
      "grad_norm": 0.69133460521698,
      "learning_rate": 3.213987764182425e-05,
      "loss": 0.3932,
      "step": 2570
    },
    {
      "epoch": 1.4349276974416019,
      "grad_norm": 1.0092809200286865,
      "learning_rate": 3.207035595105673e-05,
      "loss": 0.492,
      "step": 2580
    },
    {
      "epoch": 1.4404894327030033,
      "grad_norm": 0.564856231212616,
      "learning_rate": 3.200083426028921e-05,
      "loss": 0.371,
      "step": 2590
    },
    {
      "epoch": 1.4460511679644048,
      "grad_norm": 0.7629205584526062,
      "learning_rate": 3.1931312569521694e-05,
      "loss": 0.4738,
      "step": 2600
    },
    {
      "epoch": 1.4516129032258065,
      "grad_norm": 0.48135605454444885,
      "learning_rate": 3.1861790878754175e-05,
      "loss": 0.3513,
      "step": 2610
    },
    {
      "epoch": 1.457174638487208,
      "grad_norm": 0.5569141507148743,
      "learning_rate": 3.179226918798665e-05,
      "loss": 0.3002,
      "step": 2620
    },
    {
      "epoch": 1.4627363737486094,
      "grad_norm": 0.5808118581771851,
      "learning_rate": 3.172274749721914e-05,
      "loss": 0.2567,
      "step": 2630
    },
    {
      "epoch": 1.4682981090100111,
      "grad_norm": 0.5520724654197693,
      "learning_rate": 3.165322580645161e-05,
      "loss": 0.2849,
      "step": 2640
    },
    {
      "epoch": 1.4738598442714128,
      "grad_norm": 0.37701037526130676,
      "learning_rate": 3.158370411568409e-05,
      "loss": 0.3746,
      "step": 2650
    },
    {
      "epoch": 1.4794215795328143,
      "grad_norm": 1.0480073690414429,
      "learning_rate": 3.151418242491658e-05,
      "loss": 0.3043,
      "step": 2660
    },
    {
      "epoch": 1.4849833147942157,
      "grad_norm": 0.5904709100723267,
      "learning_rate": 3.1444660734149054e-05,
      "loss": 0.3577,
      "step": 2670
    },
    {
      "epoch": 1.4905450500556174,
      "grad_norm": 0.3596796691417694,
      "learning_rate": 3.1375139043381535e-05,
      "loss": 0.3323,
      "step": 2680
    },
    {
      "epoch": 1.496106785317019,
      "grad_norm": 0.4109443128108978,
      "learning_rate": 3.130561735261402e-05,
      "loss": 0.499,
      "step": 2690
    },
    {
      "epoch": 1.5016685205784204,
      "grad_norm": 0.3976174592971802,
      "learning_rate": 3.12360956618465e-05,
      "loss": 0.3153,
      "step": 2700
    },
    {
      "epoch": 1.507230255839822,
      "grad_norm": 0.3997154235839844,
      "learning_rate": 3.116657397107898e-05,
      "loss": 0.2872,
      "step": 2710
    },
    {
      "epoch": 1.5127919911012235,
      "grad_norm": 0.5338411927223206,
      "learning_rate": 3.109705228031146e-05,
      "loss": 0.4963,
      "step": 2720
    },
    {
      "epoch": 1.518353726362625,
      "grad_norm": 0.6368888020515442,
      "learning_rate": 3.102753058954394e-05,
      "loss": 0.3712,
      "step": 2730
    },
    {
      "epoch": 1.5239154616240267,
      "grad_norm": 1.5893088579177856,
      "learning_rate": 3.095800889877642e-05,
      "loss": 0.2777,
      "step": 2740
    },
    {
      "epoch": 1.5294771968854284,
      "grad_norm": 0.5849891901016235,
      "learning_rate": 3.08884872080089e-05,
      "loss": 0.313,
      "step": 2750
    },
    {
      "epoch": 1.5350389321468298,
      "grad_norm": 0.6830759048461914,
      "learning_rate": 3.081896551724138e-05,
      "loss": 0.4036,
      "step": 2760
    },
    {
      "epoch": 1.5406006674082313,
      "grad_norm": 0.34332314133644104,
      "learning_rate": 3.0749443826473864e-05,
      "loss": 0.3531,
      "step": 2770
    },
    {
      "epoch": 1.546162402669633,
      "grad_norm": 0.7611711025238037,
      "learning_rate": 3.067992213570634e-05,
      "loss": 0.2823,
      "step": 2780
    },
    {
      "epoch": 1.5517241379310345,
      "grad_norm": 0.3790748715400696,
      "learning_rate": 3.0610400444938825e-05,
      "loss": 0.2849,
      "step": 2790
    },
    {
      "epoch": 1.557285873192436,
      "grad_norm": 0.5655596852302551,
      "learning_rate": 3.0540878754171306e-05,
      "loss": 0.354,
      "step": 2800
    },
    {
      "epoch": 1.5628476084538376,
      "grad_norm": 0.8359744548797607,
      "learning_rate": 3.0471357063403784e-05,
      "loss": 0.3293,
      "step": 2810
    },
    {
      "epoch": 1.568409343715239,
      "grad_norm": 0.5426874160766602,
      "learning_rate": 3.040183537263626e-05,
      "loss": 0.3668,
      "step": 2820
    },
    {
      "epoch": 1.5739710789766406,
      "grad_norm": 0.2711050510406494,
      "learning_rate": 3.0332313681868746e-05,
      "loss": 0.3628,
      "step": 2830
    },
    {
      "epoch": 1.5795328142380423,
      "grad_norm": 0.3454471230506897,
      "learning_rate": 3.0262791991101223e-05,
      "loss": 0.2907,
      "step": 2840
    },
    {
      "epoch": 1.585094549499444,
      "grad_norm": 0.49028587341308594,
      "learning_rate": 3.0193270300333704e-05,
      "loss": 0.3103,
      "step": 2850
    },
    {
      "epoch": 1.5906562847608454,
      "grad_norm": 0.4229199290275574,
      "learning_rate": 3.012374860956619e-05,
      "loss": 0.296,
      "step": 2860
    },
    {
      "epoch": 1.5962180200222469,
      "grad_norm": 0.4542057514190674,
      "learning_rate": 3.0054226918798666e-05,
      "loss": 0.3294,
      "step": 2870
    },
    {
      "epoch": 1.6017797552836486,
      "grad_norm": 0.8058445453643799,
      "learning_rate": 2.9984705228031147e-05,
      "loss": 0.3785,
      "step": 2880
    },
    {
      "epoch": 1.60734149054505,
      "grad_norm": 0.6703454852104187,
      "learning_rate": 2.991518353726363e-05,
      "loss": 0.3457,
      "step": 2890
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 0.5811227560043335,
      "learning_rate": 2.984566184649611e-05,
      "loss": 0.3917,
      "step": 2900
    },
    {
      "epoch": 1.6184649610678532,
      "grad_norm": 0.5366581082344055,
      "learning_rate": 2.9776140155728587e-05,
      "loss": 0.299,
      "step": 2910
    },
    {
      "epoch": 1.624026696329255,
      "grad_norm": 0.6845455169677734,
      "learning_rate": 2.9706618464961068e-05,
      "loss": 0.3418,
      "step": 2920
    },
    {
      "epoch": 1.6295884315906561,
      "grad_norm": 0.5612801313400269,
      "learning_rate": 2.9637096774193552e-05,
      "loss": 0.2921,
      "step": 2930
    },
    {
      "epoch": 1.6351501668520578,
      "grad_norm": 0.43656107783317566,
      "learning_rate": 2.956757508342603e-05,
      "loss": 0.2693,
      "step": 2940
    },
    {
      "epoch": 1.6407119021134595,
      "grad_norm": 0.5949623584747314,
      "learning_rate": 2.949805339265851e-05,
      "loss": 0.3849,
      "step": 2950
    },
    {
      "epoch": 1.646273637374861,
      "grad_norm": 0.3570050895214081,
      "learning_rate": 2.9428531701890995e-05,
      "loss": 0.2882,
      "step": 2960
    },
    {
      "epoch": 1.6518353726362625,
      "grad_norm": 0.4204273819923401,
      "learning_rate": 2.9359010011123472e-05,
      "loss": 0.2676,
      "step": 2970
    },
    {
      "epoch": 1.6573971078976641,
      "grad_norm": 0.5754076242446899,
      "learning_rate": 2.928948832035595e-05,
      "loss": 0.3416,
      "step": 2980
    },
    {
      "epoch": 1.6629588431590656,
      "grad_norm": 0.3936227560043335,
      "learning_rate": 2.9219966629588434e-05,
      "loss": 0.4703,
      "step": 2990
    },
    {
      "epoch": 1.668520578420467,
      "grad_norm": 0.7272403836250305,
      "learning_rate": 2.9150444938820915e-05,
      "loss": 0.3196,
      "step": 3000
    },
    {
      "epoch": 1.6740823136818688,
      "grad_norm": 0.4378470480442047,
      "learning_rate": 2.9080923248053393e-05,
      "loss": 0.312,
      "step": 3010
    },
    {
      "epoch": 1.6796440489432705,
      "grad_norm": 0.5083019733428955,
      "learning_rate": 2.9011401557285874e-05,
      "loss": 0.2874,
      "step": 3020
    },
    {
      "epoch": 1.6852057842046717,
      "grad_norm": 0.5261993408203125,
      "learning_rate": 2.8941879866518358e-05,
      "loss": 0.3562,
      "step": 3030
    },
    {
      "epoch": 1.6907675194660734,
      "grad_norm": 0.8859739899635315,
      "learning_rate": 2.8872358175750836e-05,
      "loss": 0.4371,
      "step": 3040
    },
    {
      "epoch": 1.696329254727475,
      "grad_norm": 0.595503568649292,
      "learning_rate": 2.8802836484983313e-05,
      "loss": 0.3551,
      "step": 3050
    },
    {
      "epoch": 1.7018909899888766,
      "grad_norm": 0.3198617100715637,
      "learning_rate": 2.8733314794215798e-05,
      "loss": 0.3182,
      "step": 3060
    },
    {
      "epoch": 1.707452725250278,
      "grad_norm": 1.0404884815216064,
      "learning_rate": 2.866379310344828e-05,
      "loss": 0.3296,
      "step": 3070
    },
    {
      "epoch": 1.7130144605116797,
      "grad_norm": 0.5870556235313416,
      "learning_rate": 2.8594271412680756e-05,
      "loss": 0.3185,
      "step": 3080
    },
    {
      "epoch": 1.7185761957730812,
      "grad_norm": 0.6898844242095947,
      "learning_rate": 2.852474972191324e-05,
      "loss": 0.3762,
      "step": 3090
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 0.5614362359046936,
      "learning_rate": 2.845522803114572e-05,
      "loss": 0.3774,
      "step": 3100
    },
    {
      "epoch": 1.7296996662958843,
      "grad_norm": 0.47699281573295593,
      "learning_rate": 2.83857063403782e-05,
      "loss": 0.3878,
      "step": 3110
    },
    {
      "epoch": 1.735261401557286,
      "grad_norm": 0.6860998868942261,
      "learning_rate": 2.8316184649610677e-05,
      "loss": 0.3354,
      "step": 3120
    },
    {
      "epoch": 1.7408231368186873,
      "grad_norm": 0.5167838335037231,
      "learning_rate": 2.824666295884316e-05,
      "loss": 0.2984,
      "step": 3130
    },
    {
      "epoch": 1.746384872080089,
      "grad_norm": 0.3473338484764099,
      "learning_rate": 2.8177141268075642e-05,
      "loss": 0.3516,
      "step": 3140
    },
    {
      "epoch": 1.7519466073414907,
      "grad_norm": 0.7091608047485352,
      "learning_rate": 2.810761957730812e-05,
      "loss": 0.4513,
      "step": 3150
    },
    {
      "epoch": 1.7575083426028921,
      "grad_norm": 0.5218719244003296,
      "learning_rate": 2.8038097886540604e-05,
      "loss": 0.2852,
      "step": 3160
    },
    {
      "epoch": 1.7630700778642936,
      "grad_norm": 0.7740529179573059,
      "learning_rate": 2.796857619577308e-05,
      "loss": 0.3502,
      "step": 3170
    },
    {
      "epoch": 1.7686318131256953,
      "grad_norm": 0.34125959873199463,
      "learning_rate": 2.7899054505005562e-05,
      "loss": 0.3585,
      "step": 3180
    },
    {
      "epoch": 1.7741935483870968,
      "grad_norm": 0.38549554347991943,
      "learning_rate": 2.7829532814238047e-05,
      "loss": 0.2974,
      "step": 3190
    },
    {
      "epoch": 1.7797552836484982,
      "grad_norm": 0.37255534529685974,
      "learning_rate": 2.7760011123470524e-05,
      "loss": 0.3731,
      "step": 3200
    },
    {
      "epoch": 1.7853170189099,
      "grad_norm": 0.47675544023513794,
      "learning_rate": 2.7690489432703005e-05,
      "loss": 0.289,
      "step": 3210
    },
    {
      "epoch": 1.7908787541713016,
      "grad_norm": 0.7112951278686523,
      "learning_rate": 2.7620967741935483e-05,
      "loss": 0.3208,
      "step": 3220
    },
    {
      "epoch": 1.7964404894327028,
      "grad_norm": 1.1930683851242065,
      "learning_rate": 2.7551446051167967e-05,
      "loss": 0.3504,
      "step": 3230
    },
    {
      "epoch": 1.8020022246941045,
      "grad_norm": 0.9438698887825012,
      "learning_rate": 2.7481924360400445e-05,
      "loss": 0.3711,
      "step": 3240
    },
    {
      "epoch": 1.8075639599555062,
      "grad_norm": 0.3544275462627411,
      "learning_rate": 2.7412402669632926e-05,
      "loss": 0.2646,
      "step": 3250
    },
    {
      "epoch": 1.8131256952169077,
      "grad_norm": 0.30399367213249207,
      "learning_rate": 2.734288097886541e-05,
      "loss": 0.2751,
      "step": 3260
    },
    {
      "epoch": 1.8186874304783092,
      "grad_norm": 0.8758026957511902,
      "learning_rate": 2.7273359288097888e-05,
      "loss": 0.3327,
      "step": 3270
    },
    {
      "epoch": 1.8242491657397109,
      "grad_norm": 0.4002193510532379,
      "learning_rate": 2.720383759733037e-05,
      "loss": 0.37,
      "step": 3280
    },
    {
      "epoch": 1.8298109010011123,
      "grad_norm": 0.6157843470573425,
      "learning_rate": 2.7134315906562853e-05,
      "loss": 0.3288,
      "step": 3290
    },
    {
      "epoch": 1.8353726362625138,
      "grad_norm": 0.5924289226531982,
      "learning_rate": 2.706479421579533e-05,
      "loss": 0.3195,
      "step": 3300
    },
    {
      "epoch": 1.8409343715239155,
      "grad_norm": 0.7921398282051086,
      "learning_rate": 2.6995272525027808e-05,
      "loss": 0.3276,
      "step": 3310
    },
    {
      "epoch": 1.8464961067853172,
      "grad_norm": 0.639105498790741,
      "learning_rate": 2.692575083426029e-05,
      "loss": 0.307,
      "step": 3320
    },
    {
      "epoch": 1.8520578420467184,
      "grad_norm": 0.6746053695678711,
      "learning_rate": 2.6856229143492773e-05,
      "loss": 0.4802,
      "step": 3330
    },
    {
      "epoch": 1.85761957730812,
      "grad_norm": 0.4960697889328003,
      "learning_rate": 2.678670745272525e-05,
      "loss": 0.3632,
      "step": 3340
    },
    {
      "epoch": 1.8631813125695218,
      "grad_norm": 0.8588107824325562,
      "learning_rate": 2.6717185761957732e-05,
      "loss": 0.3601,
      "step": 3350
    },
    {
      "epoch": 1.8687430478309233,
      "grad_norm": 0.9333287477493286,
      "learning_rate": 2.6647664071190216e-05,
      "loss": 0.2629,
      "step": 3360
    },
    {
      "epoch": 1.8743047830923247,
      "grad_norm": 0.4237709641456604,
      "learning_rate": 2.6578142380422694e-05,
      "loss": 0.3564,
      "step": 3370
    },
    {
      "epoch": 1.8798665183537264,
      "grad_norm": 0.671065628528595,
      "learning_rate": 2.650862068965517e-05,
      "loss": 0.3696,
      "step": 3380
    },
    {
      "epoch": 1.885428253615128,
      "grad_norm": 0.5028329491615295,
      "learning_rate": 2.6439098998887656e-05,
      "loss": 0.2869,
      "step": 3390
    },
    {
      "epoch": 1.8909899888765294,
      "grad_norm": 0.29001474380493164,
      "learning_rate": 2.6369577308120137e-05,
      "loss": 0.2817,
      "step": 3400
    },
    {
      "epoch": 1.896551724137931,
      "grad_norm": 0.4172781705856323,
      "learning_rate": 2.6300055617352614e-05,
      "loss": 0.3024,
      "step": 3410
    },
    {
      "epoch": 1.9021134593993327,
      "grad_norm": 0.9998671412467957,
      "learning_rate": 2.6230533926585095e-05,
      "loss": 0.4043,
      "step": 3420
    },
    {
      "epoch": 1.907675194660734,
      "grad_norm": 0.709958016872406,
      "learning_rate": 2.616101223581758e-05,
      "loss": 0.301,
      "step": 3430
    },
    {
      "epoch": 1.9132369299221357,
      "grad_norm": 0.4176965355873108,
      "learning_rate": 2.6091490545050057e-05,
      "loss": 0.3399,
      "step": 3440
    },
    {
      "epoch": 1.9187986651835374,
      "grad_norm": 0.6549745202064514,
      "learning_rate": 2.6021968854282535e-05,
      "loss": 0.2794,
      "step": 3450
    },
    {
      "epoch": 1.9243604004449388,
      "grad_norm": 0.7516363263130188,
      "learning_rate": 2.595244716351502e-05,
      "loss": 0.3745,
      "step": 3460
    },
    {
      "epoch": 1.9299221357063403,
      "grad_norm": 0.6071031093597412,
      "learning_rate": 2.58829254727475e-05,
      "loss": 0.4011,
      "step": 3470
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 0.2907317280769348,
      "learning_rate": 2.5813403781979977e-05,
      "loss": 0.4021,
      "step": 3480
    },
    {
      "epoch": 1.9410456062291435,
      "grad_norm": 0.583739161491394,
      "learning_rate": 2.574388209121246e-05,
      "loss": 0.2971,
      "step": 3490
    },
    {
      "epoch": 1.946607341490545,
      "grad_norm": 0.42933163046836853,
      "learning_rate": 2.5674360400444943e-05,
      "loss": 0.2566,
      "step": 3500
    },
    {
      "epoch": 1.9521690767519466,
      "grad_norm": 0.6476158499717712,
      "learning_rate": 2.560483870967742e-05,
      "loss": 0.3472,
      "step": 3510
    },
    {
      "epoch": 1.9577308120133483,
      "grad_norm": 0.4184496998786926,
      "learning_rate": 2.5535317018909898e-05,
      "loss": 0.2828,
      "step": 3520
    },
    {
      "epoch": 1.9632925472747496,
      "grad_norm": 0.3980056345462799,
      "learning_rate": 2.5465795328142382e-05,
      "loss": 0.3426,
      "step": 3530
    },
    {
      "epoch": 1.9688542825361512,
      "grad_norm": 0.21375124156475067,
      "learning_rate": 2.5396273637374863e-05,
      "loss": 0.3176,
      "step": 3540
    },
    {
      "epoch": 1.974416017797553,
      "grad_norm": 0.3574640154838562,
      "learning_rate": 2.532675194660734e-05,
      "loss": 0.3878,
      "step": 3550
    },
    {
      "epoch": 1.9799777530589544,
      "grad_norm": 0.5985122919082642,
      "learning_rate": 2.5257230255839825e-05,
      "loss": 0.3084,
      "step": 3560
    },
    {
      "epoch": 1.9855394883203559,
      "grad_norm": 0.48497113585472107,
      "learning_rate": 2.5187708565072306e-05,
      "loss": 0.3725,
      "step": 3570
    },
    {
      "epoch": 1.9911012235817576,
      "grad_norm": 0.9051966667175293,
      "learning_rate": 2.5118186874304784e-05,
      "loss": 0.358,
      "step": 3580
    },
    {
      "epoch": 1.996662958843159,
      "grad_norm": 0.8758151531219482,
      "learning_rate": 2.504866518353726e-05,
      "loss": 0.3333,
      "step": 3590
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.3001479506492615,
      "eval_runtime": 7.7046,
      "eval_samples_per_second": 207.539,
      "eval_steps_per_second": 25.959,
      "step": 3596
    }
  ],
  "logging_steps": 10,
  "max_steps": 7192,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 973310565285888.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
